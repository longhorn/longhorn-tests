<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HA on Longhorn Manual Test Cases</title>
    <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/</link>
    <description>Recent content in HA on Longhorn Manual Test Cases</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Backing Image Error Reporting and Retry</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/backing-image-error-reporting-and-retry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/backing-image-error-reporting-and-retry/</guid>
      <description>Backing image with an invalid URL schema  Create a backing image via a invalid download URL. e.g., httpsinvalid://longhorn-backing-image.s3-us-west-1.amazonaws.com/parrot.qcow2, https://longhorn-backing-image.s3-us-west-1.amazonaws.invalid.com/parrot.raw. Wait for the download start. The backing image data source pod, which is used to download the file from the URL, should become Failed then be cleaned up immediately. The corresponding and only entry in the disk file status should be failed. The error message in this entry should explain why the downloading or the pod becomes failed.</description>
    </item>
    
    <item>
      <title>Disk migration in AWS ASG</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/disk-migration-in-aws-asg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/disk-migration-in-aws-asg/</guid>
      <description>Some Longhorn worker nodes in AWS Auto Scaling group is in replacement  Launch a Kubernetes cluster with the nodes in AWS Auto Scaling group. Make sure there is an additional EBS attached to instance with setting Delete on Termination disabled. Deploy Longhorn v1.1.0 on the cluster and Set ReplicaReplenishmentWaitInterval. Make sure it&amp;rsquo;s longer than the time needs for node replacement. Deploy some workloads using Longhorn volumes. Trigger the ASG instance refresh in AWS.</description>
    </item>
    
    <item>
      <title>Longhorn with engine is not deployed on all the nodes</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/partial-engine-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/partial-engine-deployment/</guid>
      <description>Related Issue https://github.com/longhorn/longhorn/issues/2081
Scenarios: Case 1: Test volume operations when some of the engine image DaemonSet pods are miss scheduled  Install Longhorn in a 3-node cluster: node-1, node-2, node-3 Create a volume, vol-1, of 3 replicas Create another volume, vol-2, of 3 replicas Taint node-1 with the taint: key=value:NoSchedule Check that all functions (attach, detach, snapshot, backup, expand, restore, creating DR volume, &amp;hellip; ) are working ok for vol-1  Case 2: Test volume operations when some of the engine image DaemonSet pods are not fully deployed  Continue from case 1 Attach vol-1 to node-1.</description>
    </item>
    
    <item>
      <title>Replica Rebuilding</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/replica-rebuilding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/replica-rebuilding/</guid>
      <description>Create and attach a volume. Write a large amount of data to the volume. Disable disk scheduling and the node scheduling for one replica. Crash the replica progress. Verify  the corresponding replica will become ERROR. the volume will keep robustness Degraded.   Enable the disk scheduling. Verify nothing changes. Enable the node scheduling. Verify.  the failed replica is reused by Longhorn. the rebuilding progress in UI page looks good.</description>
    </item>
    
    <item>
      <title>Single replica node down</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/single-replica-node-down/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/single-replica-node-down/</guid>
      <description>Related Issues https://github.com/longhorn/longhorn/issues/2329 https://github.com/longhorn/longhorn/issues/2309
Default Setting Automatic salvage is enabled.
Node restart/down scenario with Pod Deletion Policy When Node is Down set to default value do-nothing.  Create RWO|RWX volume with replica count = 1 &amp;amp; data locality = enabled|disabled. Create deployment|statefulset for volume. Power down node of volume/replica. The workload pod will get stuck in the unknown state. Volume will fail to attach since volume is not ready (i.e remains faulted, since single replica is on downed node).</description>
    </item>
    
  </channel>
</rss>
