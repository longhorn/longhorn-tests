<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>
      Longhorn Manual Test Cases
    </title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown.min.css">
    <style>
      ol > li { list-style-type: decimal; }
    </style>
  </head>
  <body class="markdown-body" style="display: flex; padding: 1%;">
    
<aside style="width: 30%; padding: 1%; border-right: 1px solid lightgray;">
  <a href="https://longhorn.github.io/longhorn-tests/manual"><h2>Manual Test Cases</h2></a>
  
  <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/">Functional test cases</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/deployment/"> Deployment of Longhorn </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/ui/"> UI </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/volume/"> Volume </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/kubernetes/"> Kubernetes </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/backup/"> Backup </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/node/"> Node </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/scheduling/"> Scheduling </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/upgrade/"> Upgrade </a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/functional-test-cases/monitoring/">Monitoring</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/">Pre-release tests</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/backup-and-restore/">Backup &amp; Restore tests</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/backup-and-restore/dr-volume-live-upgrade-and-rebuild/">#1279 DR volume live upgrade and rebuild</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/backup-and-restore/concurrent-backup/">#1341 concurrent backup test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/backup-and-restore/restore-volume-node-down/">#1355 The node the restore volume attached to is down</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/backup-and-restore/dr-volume-node-rebooted/">#1366 &amp;&amp; #1328 The node the DR volume attached to is rebooted</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/backup-and-restore/google-cloud-s3-interop-backups/">#1404 test backup functionality on google cloud and other s3 interop providers.</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/backup-and-restore/pull-backup-created-by-another-longhorn/">#4637 pull backup created by another Longhorn system</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/basic-operations-parallelism/">Basic operations parallelism</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/basic-operations-parallelism/snapshot-while-writing-data/">Snapshot while writing data in the volume</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/">Cluster Restore</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/restore-to-a-new-cluster/">Restore to a new cluster</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/restore-to-an-old-cluster/">Restore to an old cluster</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/environment/">Environment</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/environment/cluster-using-customized-kubelet-root-directory/">Cluster using customize kubelet root directory</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/environment/k3s-selinux-compatibility/">Compatibility with k3s and SELinux</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/environment/rke2-cis-1.5-profile/">Test Longhorn Deployment on RKE2 with CIS-1.5 profile</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/">HA</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/backing-image-error-reporting-and-retry/">Backing Image Error Reporting and Retry</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/disk-migration-in-aws-asg/">Disk migration in AWS ASG</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/ha-volume-migration/">HA Volume Migration</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/partial-engine-deployment/">Longhorn with engine is not deployed on all the nodes</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/replica-rebuilding/">Replica Rebuilding</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/ha/single-replica-node-down/">Single replica node down</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/">Managed Kubernetes Clusters (EKS, GKE, AKS)</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/aks/">AKS</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/aks/expand-volume/">Expand Volume</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/aks/upgrade-k8s/">Upgrade K8s</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/eks/">EKS</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/eks/add-extra-volume/">Add Extra Volume</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/eks/expand-volume/">Expand Volume</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/eks/upgrade-k8s/">Upgrade K8s</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/gke/">GKE</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/gke/expand-volume/">Expand Volume</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/managed-kubernetes-clusters/gke/upgrade-k8s/">Upgrade K8s</a></li>
  

</ul>

  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/">Node</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/backing-image-on-a-down-node/">Backing Image on a down node</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/degraded-availability/">Degraded availability with added nodes</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/improve-node-failure-handling/">Improve Node Failure Handling By Automatically Force Delete Terminating Pods of StatefulSet/Deployment On Downed Node</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/node-disconnection/">Node disconnection test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/node-drain-deletion/">Node drain and deletion test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/physical-node-down/">Physical node down</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/kubelet-restart-on-a-node/">Test kubelet restart on a node of the cluster</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/node/node-deletion/">Test node deletion</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/resiliency/">Resiliency</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/resiliency/simulated-slow-disk/">#2206 Fix the spinning disk on Longhorn</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/resiliency/pvc_provisioning_with_insufficient_storage/">PVC provisioning with insufficient storage</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/resiliency/test-longhorn-component-recovery/">Test Longhorn components recovery</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/resiliency/timeout/">Test timeout on loss of network connectivity</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/stability/">Stability</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/stability/checksum-enabled-large-volume/">Checksum enabled large volume with multiple rebuilding</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/stability/multiple-installation/">Longhorn installation multiple times</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/stress/backup-listing/">Test backup listing S3/NFS</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/uninstallation/uninstallation-checks/">Uninstallation Checks</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/">Upgrade</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/auto-upgrade-engine/">Automatically Upgrading Longhorn Engine Test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/kubernetes-upgrade-test/">Kubernetes upgrade test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/longhorn-upgrade-test/">Longhorn Upgrade test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/update_csi_components_when_images_change/">Re-deploy CSI components when their images change</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/backing-image-during-upgrade/">Test Backing Image during Longhorn upgrade</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/engine-crash-during-live-upgrade/">Test Engine Crash During Live Upgrade</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-with-customized-storage-class/">Test system upgrade with a new storage class being default</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-with-new-instance-manager/">Test System Upgrade with New Instance Manager</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-conflict-handling/">Upgrade Conflict Handling test</a></li>
  

</ul>

  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/rancher-integration/">Rancher integration test cases</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/rancher-integration/access-lh-gui-using-rancher-ui/">Access Longhorn GUI using Rancher proxy</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/rancher-integration/drain-using-rancher-ui/">Drain using Rancher UI</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/rancher-integration/lh-hardend-rancher/">Longhorn in an hardened cluster</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/rancher-integration/fleet-deploy/">Longhorn using fleet on multiple downstream clusters</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/rancher-integration/upgrade-using-rancher-ui/">Upgrade Kubernetes using Rancher UI</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/rancher-integration/upgrade-using-suc/">Upgrade Kubernetes using SUC</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/">Release specific tests</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.0/">v1.0.0</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.0/new-node-custom-data-directory/">New Node with Custom Data Directory</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.0/suse-sles12sp3/">Operating System specific tests for SUSE SLES12SP3</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.0/suse-sles12sp3/ext4-custom-fs-params-1/">Testing ext4 with custom fs params1 (no 64bit, no metadata_csum)</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.0/suse-sles12sp3/ext4-custom-fs-params-2/">Testing ext4 with custom fs params2 (no metadata_csum)</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.0/suse-sles12sp3/ext4-no-custom-fs-params/">Testing ext4 without custom fs params</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.0/suse-sles12sp3/xfs-after-custom-fs-params/">Testing xfs after custom fs params (xfs should ignore the custom fs params)</a></li>
  

</ul>

  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/">v1.0.1</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/besteffort-recurring-job/">BestEffort Recurring Job Cleanup</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/change-imagepullpolicy/">Change imagePullPolicy to IfNotPresent Test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/dr-volume-latest-backup-deletion/">DR volume related latest backup deletion test</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/nfsv4-enforcement/">NFSv4 Enforcement (No NFSv3 Fallback)</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/priorityclass-default-setting/">Priority Class Default Setting</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/error-fail-remount/">Return an error when fail to remount a volume</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/test-s3-access-style/">Test access style for S3 compatible backupstore</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/test-s3-backupstore/">Test S3 backupstore in a cluster sitting behind a HTTP proxy</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.1/ui-volume-deletion/">Volume Deletion UI Warnings</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.2/">v1.0.2</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.0.2/upgrade-lease-lock/">Upgrade Lease Lock</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/">v1.1.0</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/prometheus_support/">Prometheus Support</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/recurring-backup-job-interruptions/">Recurring backup job interruptions</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/reusing-failed-replica-for-rebuilding/">Reusing failed replica for rebuilding</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/kubelet_volume_metrics/">Support Kubelet Volume Metrics</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/additional-printer-columns/">Test Additional Printer Columns</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/instance-manager-ip-sync/">Test Instance Manager IP Sync</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/iscsi_installation/">Test ISCSI Installation on EKS</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/rwx_feature/">Test Read Write Many Feature</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/uninstallation/">Test uninstallation</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.0/upgrade_with_modified_storageclass/">Upgrade Longhorn with modified Storage Class</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/">v1.1.1</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/csi-sanity-check/">CSI Sanity Check</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/partial-engine-deployment/">Longhorn with engine is not deployed on all the nodes</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/tolerations_priorityclass_setting/">Set Tolerations/PriorityClass For System Components</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/disable_ipv6/">Test Disable IPv6</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/test-file-sync-cancellation/">Test File Sync Cancellation</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/ws-traffic-flood/">Test Frontend Traffic</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/delete-node/">Test Node Delete</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/test-node-selector/">Test Node Selector</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/rwx-mount-ownership-reset/">Test RWX share-mount ownership reset</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/test-service-account-mount/">Test Service Account mount on host</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/snapshot-purge-error-handling/">Test Snapshot Purge Error Handling</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.1/system-upgrade-with-deprecated-cpu-setting/">Test system upgrade with the deprecated CPU setting</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.2/">v1.1.2</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.2/delete-cronjob-for-detached-volumes/">Test CronJob For Volumes That Are Detached For A Long Time</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.2/full-ws-data-tranfer-when-no-updates/">Test Frontend Web-socket Data Transfer When Resource Not Updated</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.1.2/instance-manager-streaming-connection-recovery/">Test Instance Manager Streaming Connection Recovery</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.0/">v1.2.0</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.0/test-backing-image-upload/">Test backing image</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.0/backup-creation-with-old-engine-image/">Test Backup Creation With Old Engine Image</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.0/test-instance-manager-cleanup-during-uninstall/">Test instance manager cleanup during uninstall</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.0/label-driven-recurring-job/">Test Label-driven Recurring Job</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.0/test_version_bump/">Test Version Bump of Kubernetes, API version group, CSI component&rsquo;s dependency version</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.3/">v1.2.3</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.3/test-backing-image-checksum-mismatching/">Test backing image checksum mismatching</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.3/test-backing-image-space-usage/">Test backing image space usage with sparse files</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.2.3/test-scalability-with-backing-image/">Test scalability with backing image</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/">v1.3.0</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/extend_csi_snapshot_support/">Extended CSI snapshot support to Longhorn snapshot</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-storage-network/">Setup and test storage network</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-backing-image-download-to-local/">Test backing image download to local</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-helm-uninstall-different-namespace/">Test Helm uninstall Longhorn in different namespace</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-grpc-proxy/">Test IM Proxy connection metrics</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-instance-manager-npe/">Test instance manager NPE</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-longhorn-manager-npe/">Test longhorn manager NPE caused by backup creation</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-longhorn-manager-starting-scalability/">Test longhorn manager pod starting scalability</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-npe-when-longhorn-ui-deployment-not-exist/">Test NPE when longhorn UI deployment CR not exist</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.0/test-snapshot-purge-retry/">Test snapshot purge retry</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.1/">v1.3.1</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.3.1/test-backing-image-download-to-local/">Test transient error in engine status during eviction</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/">v1.4.0</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-csi-plugin-liveness-probe/">Test CSI plugin liveness probe</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-engine-binary-recovery/">Test engine binary recovery</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-filesystem-trim/">Test filesystem trim</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-helm-install-on-rancher-deployed-windows-cluster/">Test helm on Rancher deployed Windows Cluster</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-system-backup/">Test Longhorn system backup should sync from the remote backup target</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-node-id-change-during-backing-image-creation/">Test Node ID Change During Backing Image Creation</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-online-expansion/">Test Online Expansion</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-replica-scale-down-warning/">Test replica scale-down warning</a></li>
  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.0/test-upgrade-for-migrated-longhorn/">Test upgrade for migrated Longhorn on Rancher</a></li>
  

</ul>

  

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.1/">v1.4.1</a></li>
  
    <ul>

  <li><a href="https://longhorn.github.io/longhorn-tests/manual/release-specific/v1.4.1/test-the-trim-related-option-update-for-old-volumes/">Test the trim related option update for old volumes</a></li>
  

</ul>

  

</ul>

  

</ul>

  
</aside>


<main style="padding: 1%; width: 70%;">
  <h1 id="title"><ol start="3">
<li>Volume</li>
</ol>
</h1>
  <div>
    <article id="content">
       <h3 id="test-cases-for-volume">Test cases for Volume</h3>
<table>
<thead>
<tr>
<th><strong>#</strong></th>
<th><strong>Test Case</strong></th>
<th><strong>Test Instructions</strong></th>
<th><strong>Expected Results</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Check volume Details</td>
<td><strong>Prerequisite:</strong><br><br>*   Longhorn Nodes has node tags<br>*   Node Disks has disk tags<br>*   Backup target is set to NFS server, or S3 compatible target<br><br>1.  Create a workload using Longhorn volume<br>2.  Check volume details page<br>3.  Create volume backup</td>
<td>*   Volume Details<br>    *   <code>State</code> should be <code>Attached</code><br>    *   <code>Health</code> should be healthy<br>    *   <code>Frontend</code> should be <code>Block Device</code><br>    *   <code>Attached Node &amp; Endpoint</code> should be node name that volume is attached to and PATH of the volume device file on that node.<br>    *   <code>Size</code> should match volume size specified in Create Volume step<br>    *   <code>Actual Size</code> should be <code>0Bi</code> (No data has been written to the volume yet)<br>    *   <code>Engine Image</code> should be <code>longhornio/longhorn-engine:&lt;LONGHORN_VERSION&gt;</code><br>    *   <code>Created</code> should indicate time since volume is created.<br>    *   <code>Node Tags</code> should be empty (no node tags has been specified during creation)<br>    *   <code>Disk Tags</code> should be empty (no disk tags has been specified during creation)<br>    *   <code>Last Backup</code> should be empty (no backup has been created)<br>    *   <code>Last Backup At</code> should be empty (no backup has been created)<br>    *   <code>Instance Manager</code> should contain instance manager image name<br>    *   <code>Namespace</code> should match namespace specified in Volume Create step.<br>    *   <code>PVC Name</code> should be empty (no PV has been created for that volume yet)<br>    *   <code>PV Name</code> should be empty (no PV has been created for that volume yet)<br>    *   <code>PV Status</code> should be empty (no PV/PVC has been created for that volume yet)</td>
</tr>
<tr>
<td>2</td>
<td>Filter Volumes</td>
<td>User should be able to filter volumes using the following filters<br><br>*   Name<br>*   Node<br>*   Status (Healthy, In progress, Degraded, Faulted, detached)<br>*   Namespace<br>*   Node redundancy (Yes, Limited, No)<br>*   PV Name<br>*   PVC Name<br>*   Node tag<br>*   Disk tag<br><br>Notes:<br><br>*   Limited node redundancy: at least one healthy replica is running at the same node as another</td>
<td>*   Volume list should match filtering criteria applied.</td>
</tr>
<tr>
<td>3</td>
<td>Delete multiple volumes</td>
<td>*   <strong>Prerequisite:</strong><br>    *   Create multiple volumes<br><br>1.  Select multiple volumes and delete</td>
<td>*   Volumes should be deleted</td>
</tr>
<tr>
<td>4</td>
<td>Attach multiple volumes</td>
<td>*   <strong>Prerequisite:</strong><br>    *   Create multiple volumes<br><br>1.  Select multiple volumes and Attach them to a node</td>
<td>*   All Volumes should be attached to the same node specified in volume attach request.</td>
</tr>
<tr>
<td>5</td>
<td>Attach multiple volumes in maintenance mode</td>
<td>*   <strong>Prerequisite:</strong><br>    *   Create multiple volumes<br><br>1.  Select multiple volumes and Attach them to a node in maintenance mode</td>
<td>*   All Volumes should be attached in maintenance mode to the same node specified in volume attach request.</td>
</tr>
<tr>
<td>6</td>
<td>Detach multiple volumes</td>
<td>*   <strong>Prerequisite:</strong><br>    *   Multiple attached volumes<br>*   Select multiple volumes and detach</td>
<td>*   Volumes should be detached</td>
</tr>
<tr>
<td>7</td>
<td>Backup multiple Volumes</td>
<td>*   <strong>Prerequisite:</strong><br>    *   Longhorn should be configured to point to a backupstore<br>    *   Multiple volumes existed and attached to node/used buy kubernetes workload<br>    *   Write some data to multiple volumes and compute it’s checksum<br>*   Select multiple volumes and Create a backup<br>*   restore volumes backups and check its data checksum</td>
<td>*   Volume backups should be created<br>*   Restored volumes from backup should contain the same data when backup is created</td>
</tr>
<tr>
<td>8</td>
<td>Create PV/PVC for multiple volumes</td>
<td><strong>Prerequisite:</strong><br><br>*   Create multiple volumes<br><br>1.  Select multiple volumes<br>2.  Create a PV, specify filesysem<br>3.  Check PV in Lonhgorn UI and in Kubernetes<br>4.  Create PVC<br>5.  Check PVC in Lonhgorn UI and in Kubernetes<br>6.  Delete PVC<br>7.  Check PV in Lonhgorn UI and in Kubernetes</td>
<td>*   For all selected volumes<br>    *   PV should created<br>    *   PV/PVC status in UI should be <code>Available</code><br>    *   PV <code>spec.csi.fsType</code> should match filesystem specified in PV creation request<br>    *   PV <code>spec.storageClassName</code> should match the setting in <code>Default Longhorn Static StorageClass Name</code><br>    *   PV <code>spec.csi.volumeHandle</code> should be the volume name<br>    *   PV/PVC status in UI should be <code>Bound</code> in Longhorn UI<br>    *   PVC namespace should match namespace specified in PVC creation request<br>    *   After Deleting PVC, PV/PVC status should be <code>Relased</code> in Longhorn UI.</td>
</tr>
<tr>
<td>9</td>
<td>Volume expansion</td>
<td>Check Multiple Volume expansion test cases work for multiple volumes<br><br><a href="https://rancher.atlassian.net/wiki/spaces/LON/pages/354453117/Volume+detail+page">Test Cases in Volume Details page</a></td>
<td>Volume expansion should work for multiple volumes.</td>
</tr>
<tr>
<td>10</td>
<td>Engine Offline Upgrade For Multiple Volumes</td>
<td><strong>Prerequisite:</strong><br><br>*   Volume is consumed by Kubernetes deployment workload<br>*   Volume use old Longhorn Engine<br><br>1.  Write data to volume, compute it’s checksum (checksum#1)<br>2.  Scale down deployment , volume gets detached<br>3.  Upgrade Longhorn engine image to use new deployed engine image<br>4.  Scale up deployment, volume gets attached</td>
<td>*   Volume read/write operations should work before and after engine upgrade.<br>*   Old Engine <code>Reference Count</code> will be decreased by 1<br>*   New Engine <code>Reference Count</code> will be increased by 1</td>
</tr>
<tr>
<td>12</td>
<td>Show System Hidden</td>
<td><strong>Prerequisite</strong>:<br><br>*   Volume is created and attached to a pod.<br><br>1.  Click the volume appearing on volume list page, it takes user to volume.<br>2.  Take snapshot and upgrade the replicas.<br>3.  Under snapshot section, enable option &lsquo;Show System Hidden</td>
<td>Enabling this option will show system created snapshots while rebuilding of replicas.</td>
</tr>
<tr>
<td>13</td>
<td>Event log</td>
<td><strong>Prerequisite</strong>:<br><br>*   Volume is created and attached to a pod.<br><br>1.  Click event log to expand</td>
<td>Verify details appearing in logs.</td>
</tr>
</tbody>
</table>
<h2 id="replica">Replica</h2>
<table>
<thead>
<tr>
<th><strong>#</strong></th>
<th><strong>Test Case</strong></th>
<th><strong>Test Instructions</strong></th>
<th><strong>Expected Results</strong></th>
<th><strong>Automated ? / test name</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Replica list</td>
<td>1.  Create a volume and change the default number of replicas<br>2.  Attach volume to a node<br>3.  Check replica list</td>
<td>*   Number of replicas should match number specified in volume creation request<br>*   All replicas should be <code>Running</code>, and <code>Healthy</code><br>*   Replica info also should contain, <code>Node Name</code>, <code>Replica Instance Manager Name</code>, <code>Replica Path</code></td>
<td>test_volume_update_replica_count</td>
</tr>
<tr>
<td>2</td>
<td>Update volume replica count (increase)</td>
<td>1.  Create a volume<br>2.  Attach volume to a node<br>3.  Increase replica count +1</td>
<td>*   New system hidden snapshot should be created<br>*   A new replica should be created<br>*   New replicas should be <code>Running</code> &amp; <code>Rebuilding</code></td>
<td>test_volume_update_replica_count</td>
</tr>
<tr>
<td>3</td>
<td>Update volume replica count (decrease)</td>
<td>1.  Create a volume<br>2.  Attach volume to a node<br>3.  decrease replica count by +1<br>4.  Delete a replica</td>
<td>*   After decreasing replica count, nothing should happen<br>*   Deleting a replica will not trigger replica rebuild</td>
<td>test_volume_update_replica_count</td>
</tr>
</tbody>
</table>
<h2 id="snapshot">Snapshot</h2>
<table>
<thead>
<tr>
<th><strong>#</strong></th>
<th><strong>Test Case</strong></th>
<th><strong>Test Instructions</strong></th>
<th><strong>Expected Results</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Create Snapshot</td>
<td>1.  Create a workload using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)</td>
<td>*   Volume head should have parent as snapshot#1<br>*   Snapshot should be created</td>
</tr>
<tr>
<td>2</td>
<td>Revert Snapshot</td>
<td>1.  Create a deployment workload with <code>nReplicas = 1</code> using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Write some other data, compute it’s checksum (checksum#2)<br>4.  Create a snapshot (snapshot#1)<br>5.  Scale down deployment <code>nReplicas = 0</code><br>6.  Attach volume in <code>maintenance mode</code><br>7.  Revert to (snapshot#1)<br>8.  Detach volume<br>9.  Scale back deployment <code>nReplicas = 1</code><br>10.  Compute data checksum (checksum#3)</td>
<td>*   Volume head should have parent as snapshot#1<br>*   Volume state should be <code>Detached</code> after scaling down deployment <code>nReplicas = 0</code><br>*   In Volume Details <code>Attached Node</code> should be Node name which volume is attached to, without an <code>Endpoint</code> (block device path)<br>*   Data checksum after revert should match data checksum when taking snapshot <code>checksum#3 == checksum#1</code></td>
</tr>
<tr>
<td>3</td>
<td>Delete Snapshot</td>
<td>1.  Create a workload using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)<br>4.  Repeat steps 2,3 two more times to have (snapshot#2, snapshot#3) with different data files (checksum#2, checksum#3)<br>5.  Write data to volume, compute it’s checksum (checksum#4) → live data<br>6.  Delete (snapshot#2)<br>7.  Revert to (snapshot#3)<br>8.  Revert to (snapshot#1)</td>
<td>*   Snapshot#2 will be deleted, verify in replica /var/lib/rancher/longhorn/replicas/<br>*   After reverting to snapshot#3 verify the data.<br>*   After reverting to snapshot#1 data checksum should match (checksum#1)</td>
</tr>
<tr>
<td>4</td>
<td>Delete Snapshot while rebuilding replicas</td>
<td>1.  Create a workload using Longhorn volume<br>2.  Write data to volume (1GB+), compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)<br>4.  Delete a replica<br>5.  while replica is rebuilding, try to delete (snapshot#1)</td>
<td>*   New system snapshot should be created<br>*   Will <strong>NOT</strong> be able to delete snapshot#1</td>
</tr>
<tr>
<td>5</td>
<td>Snapshot Purge</td>
<td>1.  Create a workload using Longhorn volume<br>2.  Write data to volume (1GB+), compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)<br>4.  Delete a replica<br>5.  After rebuild is complete, delete (snapshot#1)</td>
<td>*   New system snapshot should be created<br>*   Snapshot#1 will be delete<br>*   Snapshot purge process will be triggered<br>*   Only system snapshot should be present<br>*   You will not be able revert to the system snapshot</td>
</tr>
<tr>
<td>6</td>
<td>Create recurring snapshots</td>
<td>1.  Create a deployment workload with <code>nReplicas = 1</code> using Longhorn volume<br>2.  Write data to volume , compute it’s checksum (checksum#1)<br>3.  Create a recurring snapshot <code>every 5 minutes</code>. and set retain count to <code>5</code><br>4.  Wait for 2 recurring snapshots to triggered (snapshot#1, snapshot#2 )<br>5.  Scale down deployment <code>nReplicas = 0</code><br>6.  Attach volume in <code>maintenance mode</code><br>7.  Revert to (snapshot#1)<br>8.  Scale back deployment <code>nReplicas = 1</code><br>9.  Wait for another recurring snapshots to triggered (snapshot#3)<br>10.  Delete (snapshot#1)</td>
<td>*   Snapshots (snapshot#1, snapshot#2) should be created<br>*   Before deleting (snapshot#1), Parent snapshot of (snapshot#3) should be (snapshot#1)<br>*   After deleting (snapshot#1), Parent snapshot of (snapshot#3) should be starting point.<br>*   Only max of <code>5</code> snapshots should be retained<br>*   Oldest snapshot will be removed when number of snapshots created by recurring job exceeds retain count<br>*   only snapshots generated by recurring job is affected by retain count, user can created manual snapshots and it will not be deleted automatically.</td>
</tr>
<tr>
<td>8</td>
<td>Disabling/Deleting recurring snapshots</td>
<td>1.  Create a deployment workload with <code>nReplicas = 1</code> using Longhorn volume<br>2.  Write data to volume , compute it’s checksum (checksum#1)<br>3.  Create a recurring snapshot <code>every 5 minutes</code>. and set retain count to <code>5</code><br>4.  Wait for 2 recurring snapshots to triggered (snapshot#1,snapshot#2 )<br>5.  Delete the recurring snapshots</td>
<td>*   Recurring snapshots will stop after deletion of it.<br>*   Existing snapshots should retain.<br>*   User should be able to take snapshot manually.</td>
</tr>
<tr>
<td>9</td>
<td>Operation with volume created using rancher UI</td>
<td>1.  Create pv/pvc in rancher UI.<br>2.  Deploy a workload with PVC created in rancher UI.<br>3.  Write data to volume, compute it’s checksum (checksum#1)<br>4.  In longhorn UI, create a snapshot.<br>5.  Write data to volume again.<br>6.  Revert to snapshot.<br>7.  Delete the snapshot.</td>
<td>*   User should be able to create snapshot.<br>*   User should to revert to snapshot created verify this by checksum.<br>*   User should be able to delete the snapshot. Verify this in replicas in the nodes.</td>
</tr>
<tr>
<td>10</td>
<td>Delete the last snapshot</td>
<td>1.  Create a workload using Longhorn volume<br>2.  Write data to volume(more than 4k), compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)<br>4.  Repeat steps 2,3 two more times to have (snapshot#2, snapshot#3) with different data files (checksum#2, checksum#3)<br>5.  Write data to volume, compute it’s checksum (checksum#4) → live data<br>6.  Delete (snapshot#3)</td>
<td>*   Data from last snapshot should not get lost.</td>
</tr>
<tr>
<td>11</td>
<td>Multi branch snapshot</td>
<td>1.  Create a workload using Longhorn volume<br>2.  Write data to volume(more than 4k), compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)<br>4.  Repeat steps 2,3 two more times to have (snapshot#2, snapshot#3) with different data files (checksum#2, checksum#3)<br>5.  Write data to volume, compute it’s checksum (checksum#4) → live data<br>6.  Revert to snapshot#2<br>7.  Write data to volume, compute it’s checksum.<br>8.  Repeat steps 2,3 two more times to have (snapshot#4, snapshot#5) with different data files (checksum#5, checksum#6)<br>9.  Revert to snapshot#3</td>
<td>*   Verify the data in any of the replica</td>
</tr>
<tr>
<td>12</td>
<td>Backup from a snapshot</td>
<td>1.  Create a workload using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)<br>4.  Repeat steps 2,3 two more times to have (snapshot#2, snapshot#3) with different data files (checksum#2, checksum#3)<br>5.  Write data to volume, compute it’s checksum (checksum#4) → live data<br>6.  Take backup from a snapshot#2.<br>7.  Restore from the backup taken</td>
<td>Verify the data of the backup, it should match data from snapshot#2</td>
</tr>
</tbody>
</table>
<h2 id="volume-expansion">Volume Expansion</h2>
<table>
<thead>
<tr>
<th><strong>#</strong></th>
<th><strong>Test Case</strong></th>
<th><strong>Test Instructions</strong></th>
<th><strong>Expected Results</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Volume <strong>Online expansion</strong> for attached volume<br><br><strong>(Not Supported for now)</strong></td>
<td>1.  Create multiple 4 volumes, each of size 5 GB, Attach them to nodes<br>2.  Format each volume using one of the following formats (ext 2/3/4 &amp; xfs)<br>3.  Mount volumes to directories on the nodes.<br>4.  Check volume size and used space using <code>df -h</code> command<br>5.  Write 4 GB data file to each volume<br>6.  For each volume, from Operation menu, Click <code>Expand Volume</code>, set size to <code>10 GB</code>, and click <code>OK</code><br>7.  Check volume size and used space using <code>df -h</code> command<br>8.  Add more 4 GB data file to each volume<br>9.  Check volume size and used space using <code>df -h</code> command<br>10.  Check volume size expanded</td>
<td>*   Volumes should be expanded to the new size<br>*   Volume read/write operations should work after size expansion</td>
</tr>
<tr>
<td>2</td>
<td>Volume <strong>Online expansion</strong> for volume consumed by Kubernetes workload<br><br><strong>→ Kubernetes Version: 1.15</strong></td>
<td>1.  Create a <code>2GB</code> volume used by a Kubernetes workload<br>2.  Expand Volume size to <code>10 GB</code><br>3.  In Kubernetes, edit PV/PVC capacity to match new volume size.<br>4.  Check volume size using <code>df -h</code> command from Kubernetes workload<br>5.  Write 8 GB data file to volume, and compute its checksum</td>
<td>*   When resizing, A message indicate that <code>The capacity of related PV and PVC will not be updated</code><br>*   Volumes should be expanded to the new size<br>*   Volume read/write operations should work after size expansion</td>
</tr>
<tr>
<td>3</td>
<td>Volume <strong>Online expansion</strong> for volume consumed by Kubernetes workload<br><br><strong>→ Kubernetes Version: 1.16+</strong></td>
<td><strong>Prerequisite:</strong><br><br>*   PVC is dynamically provisioned by the StorageClass.<br>*   The Kubernetes is version 1.16+ or the feature gate for volume expansion is enabled.<br>*   The StorageClass should support resize, <code>allowVolumeExpansion: true</code> is set in the StorageClass<br><br>1.  Create a <code>2GB</code> volume used by a Kubernetes workload<br>2.  Expand Volume size to <code>10 GB</code><br>3.  Check volume size using <code>df -h</code> command from Kubernetes workload<br>4.  Write 8 GB data file to volume, and compute its checksum</td>
<td>*   When resizing, A message indicate that <code>The capacity of related PV and PVC will not be updated</code><br>*   Volumes should be expanded to the new size<br>*   Volume read/write operations should work after size expansion</td>
</tr>
<tr>
<td>4</td>
<td>Volume Offline expansion<br><br><strong>Kubernetes Version: &lt; 1.16</strong></td>
<td>1.  Create and attach a volume<br>2.  Format and mount the volume. Fill up the volume and get the checksum (checksum#1)<br>3.  Unmount and detach the volume.<br>4.  Expand the volume and wait for the expansion complete.<br>5.  Reattach and remount the volume. Check the checksum and if the filesystem is expanded.<br>6.  Fill up the expanded parts and get the checksum. (checksum#2)<br>7.  Unmount and detach the volume.<br>8.  Launch a workload for it on a different node. Check data checksum</td>
<td>*   Volume size should be expanded<br>*   Volume read/write operations should work after size expansion<br>*   After expansion, data checksum should match checksum#1<br>*   Final data checksum should match checksum#2</td>
</tr>
<tr>
<td>5</td>
<td>Volume expansion with revert and backup</td>
<td>1.  Create and attach a volume.<br>2.  Format and mount the volume. Fill up the volume and get the checksum. (checksum#1)<br>3.  Create the 1st snapshot and backup. (snapshot#1 &amp; backup#1)<br>4.  Expand the volume. Fill up the expanded part and get the checksum (checksum#2)<br>5.  Create the 2nd snapshot and backup. (snapshot#2 &amp; backup#2)<br>6.  Check if the backup volume size is expanded.<br>7.  Restore backup#2 to a volume and check its data<br>8.  Clean up then refill the volume. Get the checksum. (checksum#3)<br>9.  Create the 3rd snapshot and backup. (snapshot#3 &amp; backup#3)<br>10.  Revert to the 2nd snapshot. Check the checksum.<br>11.  Revert to the 1st snapshot. Check the checksum and if we can still use the expanded part.</td>
<td>*   Volume should be expanded<br>*   backup#2 size should be expanded and match volume new expanded size<br>*   Restored volume data from backup#2 should match checksum#2<br>*   After reverting to snapshot#1, data checksum should match checksum#1<br>*   After reverting to snapshot#1 expanded size should be usable.<br>*   Volume read/write operations should work after expansion and revert.</td>
</tr>
</tbody>
</table>
<h2 id="rwx-volume-native-support-starting-with-v110">RWX Volume native support starting with v1.1.0</h2>
<h3 id="prerequisite">Prerequisite:</h3>
<ol>
<li>Longhorn is deployed in a cluster having 4 nodes (1 etcd/control plane and 3 worker)</li>
<li>NFS-Common is installed on the nodes.</li>
</ol>
<table>
<thead>
<tr>
<th><strong>#</strong></th>
<th><strong>Test Scenario</strong></th>
<th><strong>Test Steps</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Create StatefulSet/Deployment with single pod with volume attached in RWX mode</td>
<td>1.  Create a StatefulSet/Deployment with 1 pod.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Verify that a PVC, ShareManger pod, CRD and volume in Longhorn get created.<br>4.  Verify there is directory with the name of PVC exists in the ShareManager mount point i.e. <code>export</code><br>5.  Write some data in the pod and verify the same data reflects in the ShareManager.<br>6.  Verify the longhorn volume, it should reflect the correct size.</td>
</tr>
<tr>
<td>2</td>
<td>Create StatefulSet/Deployment with more than 1 pod with volume attached in RWX mode.</td>
<td>1.  Create a StatefulSet/Deployment with multiple pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Verify that one volume per pod in Longhorn gets created.<br>4.  Verify there is directory with the name of PVC exists in the ShareManager mount point i.e. <code>export</code><br>5.  Verify that Longhorn UI shows all the pods name attached to the volume.<br>6.  Write some data in all the pod and verify all the data reflects in the ShareManager.<br>7.  Verify the longhorn volume, it should reflect the correct size.</td>
</tr>
<tr>
<td>3</td>
<td>Create StatefulSet/Deployment with the existing PVC of a RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 1 pod.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Verify that a PVC, ShareManger pod, CRD and volume in Longhorn get created.<br>4.  Write some data in the pod and verify the same data reflects in the ShareManager.<br>5.  Create another StatefulSet/Deployment using the above created PVC.<br>6.  Write some data in the new pod, the same should be reflected in the ShareManager pod.<br>7.  Verify the longhorn volume, it should reflect the correct size.</td>
</tr>
<tr>
<td>4</td>
<td>Scale up StatefulSet/Deployment with one pod attached with volume in RWX mode.</td>
<td>1.  Create a StatefulSet/Deployment with 1 pod.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod and verify the same data reflects in the ShareManager.<br>4.  Scale up the StatefulSet/Deployment.<br>5.  Verify a new volume gets created.<br>6.  Write some data in the new pod, the same should be reflected in the ShareManager pod.<br>7.  Verify the longhorn volume, it should reflect the correct size.</td>
</tr>
<tr>
<td>5</td>
<td>Scale down StatefulSet/Deployment attached with volume in RWX mode to zero.</td>
<td>1.  Create a StatefulSet/Deployment with 1 pod.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod and verify the same data reflects in the ShareManager.<br>4.  Scale down the StatefulSet/Deployment to zero<br>5.  Verify the ShareManager pod gets deleted.<br>6.  Verify the volume should be in detached state.<br>7.  Create a new StatefulSet/Deployment with the existing PVC with different mount point.<br>8.  Verify the ShareManager should get created and volume should become attached.<br>9.  Verify the data.<br>10.  Delete the newly created StatefulSet/Deployment.<br>11.  Verify the ShareManager pod gets deleted again.<br>12.  Scale up the first StatefulSet/Deployment.<br>13.  Verify the ShareManager should get created and volume should become attached.<br>14.  Verify the data.</td>
</tr>
<tr>
<td>6</td>
<td>Delete the Workload StatefulSet/Deployment attached with RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 1 pod.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod and verify the same data reflects in the ShareManager.<br>4.  Delete the workload.<br>5.  Verify the ShareManager pod gets deleted but the CRD should not be deleted.<br>6.  Verify the volume should be in detached state.<br>7.  Create another StatefulSet with existing PVC.<br>8.  Verify the ShareManager should get created and volume should become attached.<br>9.  Verify the data.</td>
</tr>
<tr>
<td>7</td>
<td>Take snapshot and backup of a RWX volume in Longhorn.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Take a snapshot and a backup.<br>5.  Write some more data into the pod.<br>6.  Revert to snapshot 1 and verify the data.</td>
</tr>
<tr>
<td>8</td>
<td>Restore a backup taken from a RWX volume in Longhorn.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Take a backup of a RWX volume.<br>5.  Restore from the backup and attach the volume to a pod.<br>6.  Verify the data and the volume should be read write once.</td>
</tr>
<tr>
<td>9</td>
<td>Create DR volume of a RWX volume in Longhorn.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Take a backup of the volume.<br>5.  Create a DR volume of the backup.<br>6.  Write more data in the pods and take more backups.<br>7.  Verify the DR volume is getting synced with latest backup.<br>8.  Activate the DR volume and verify the data.</td>
</tr>
<tr>
<td>10</td>
<td>Expand the RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Expand the volume.<br>5.  Verify that user is able to write data in the expanded volume.</td>
</tr>
<tr>
<td>11</td>
<td>Recurring Backup/Snapshot with RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Schedule a recurring backup/Snapshot.<br>5.  Verify the recurring jobs are getting created and is taking backup/snapshot successfully.</td>
</tr>
<tr>
<td>12</td>
<td>Deletion of the replica of a Longhorn RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Delete one of the replica and verify that the rebuild of replica is working fine.</td>
</tr>
<tr>
<td>13</td>
<td>Parallel writing</td>
<td>1.  Write data in multiple pods attached to the same volume at the same time.</td>
</tr>
<tr>
<td>14</td>
<td>Data locality with RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Enable <code>Data-locality</code><br>5.  Disable <code>Node soft anti-affinity</code>.<br>6.  Disable the node where the volume is attached for some time.<br>7.  Wait for replica to be rebuilt on another node.<br>8.  Enable the node scheduling and verify a replica gets rebuilt on the attached node.</td>
</tr>
<tr>
<td>15</td>
<td>Node eviction with RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Do a node eviction and verify the data.</td>
</tr>
<tr>
<td>16</td>
<td>Auto salvage feature on an RWX volume.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Crash all the replicas and verify the auto-salvage works fine.</td>
</tr>
<tr>
<td>17</td>
<td>RWX volume with <code>Allow Recurring Job While Volume Is Detached</code> enabled.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Set a recurring backup and scale down all the pods.<br>5.  Verify the volume get attached at scheduled time and backup/snapshot get created.</td>
</tr>
<tr>
<td>18</td>
<td>RWX volume with Toleration.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Set some Toleration.<br>5.  Verify the ShareManager pods have the toleration and annotation updated.</td>
</tr>
<tr>
<td>19</td>
<td>Detach/Delete operation on an RWX volume.</td>
<td>1.  Detach action on the Longhorn UI should not work on RWX volume.<br>2.  On deletion of the RWX volume, the ShareManager CRDs should also get deleted.</td>
</tr>
<tr>
<td>20</td>
<td>Crash instance e manager of the RWX volume</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Crash the instance manager.<br>5.  On crashing the IM, the ShareManager pods should be immediately redeployed.<br>6.  Based on the setting <code>Automatically Delete Workload Pod when The Volume Is Detached Unexpectedly</code>, the workload pods will get redeployed.<br>7.  On recreating on workload pods, the volume should get attached successfully.<br>8.  If <code>Automatically Delete Workload Pod when The Volume Is Detached Unexpectedly</code> is disabled, user should see I/O error on the mounted point.</td>
</tr>
<tr>
<td>21</td>
<td>Reboot the ShareManager and workload node</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Reboot the ShareManager node.<br>5.  The ShareManager pod should move to another node.<br>6.  As the instance e manager is on the same node and based on setting <code>Automatically Delete Workload Pod when The Volume Is Detached Unexpectedly</code>, the workload should be redeployed and volume should be available to user.<br>7.  Reboot the workload node.<br>8.  On restart on the node, pods should get attached to the volume. Verify the data.</td>
</tr>
<tr>
<td>22</td>
<td>Power down the ShareManager and workload node.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Power down the ShareManager node.<br>5.  The ShareManager pod should move to another node.<br>6.  As the instance manager is on the same node and based on the setting <code>Automatically Delete Workload Pod when The Volume Is Detached Unexpectedly</code>, the workload should be redeployed and volume should be available to user.<br>7.  Power down the workload node.<br>8.  The workload pods should move to another node based on <code>Pod Deletion Policy When Node is Down</code> setting.<br>9.  Once the pods are up, they should get attached to the volume. Verify the data.</td>
</tr>
<tr>
<td>23</td>
<td>Kill the nfs process in the ShareManager</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Kill the NFS server in the ShareManager pod.<br>5.  The NFS server should retry to come up.<br>6.  Volume should continue to accessible.</td>
</tr>
<tr>
<td>24</td>
<td>Delete the ShareManager CRD.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Delete the ShareManager CRD.<br>5.  A new ShareManager CRD should be created.</td>
</tr>
<tr>
<td>25</td>
<td>Delete the ShareManager pod.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Delete the ShareManager pod.<br>5.  A new ShareManager pod should be immediately created.</td>
</tr>
<tr>
<td>26</td>
<td>Drain the ShareManager node.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Drain the ShareManager pod node.<br>5.  The volume should get detached first, then the shareManager pod should move to another node and Volume should get reattached.</td>
</tr>
<tr>
<td>27</td>
<td>Disk full on the ShareManager node.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod and make the disk almost full.<br>4.  Verify the RWX volume is not failed.<br>5.  Verify the creation of snapshot/backup.<br>6.  Try to write more data, and the it should error out <code>no space left</code>.</td>
</tr>
<tr>
<td>28</td>
<td>Scheduling failure with RWX volume.</td>
<td>1.  Disable 1 node.<br>2.  Create a StatefulSet/Deployment with 2 pods.<br>3.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>4.  Verify the RWX volume gets created with degraded state.<br>5.  Write some data in the pod.<br>6.  Enable the node and the volume should become healthy.</td>
</tr>
<tr>
<td>29</td>
<td>Add a node in the cluster.</td>
<td>1.  Add a node in the cluster.<br>2.  Create multiple statefulSet/deployment with RWX volume.<br>3.  Verify that the ShareManager pod is able to scheduled on the new node.</td>
</tr>
<tr>
<td>30</td>
<td>Delete a node from the cluster.</td>
<td>1.  Create a StatefulSet/Deployment with 2 pods.<br>2.  Attach a volume with RWX mode using longhorn class and selecting the option <code>read write many</code>.<br>3.  Write some data in the pod.<br>4.  Delete the ShareManager node from the cluster.<br>5.  Verify the ShareManager pod move to new node and volume continues to be accessible.</td>
</tr>
<tr>
<td>31</td>
<td>RWX with Linux/SLES OS</td>
<td></td>
</tr>
<tr>
<td>32</td>
<td>RWX with K3s set up</td>
<td></td>
</tr>
<tr>
<td>33</td>
<td>RWX in Air gap set up.</td>
<td></td>
</tr>
<tr>
<td>34</td>
<td>RWX in PSP enabled set up.</td>
<td></td>
</tr>
</tbody>
</table>

    </article>
  <a href="https://github.com/longhorn/longhorn-tests/edit/master/docs/content/manual/functional-test-cases/volume.md" target="_blank" title="Edit on Github" style="font-size:smaller;float:right;padding-right:3%">[Edit]</a>
  </div>

    
    
  </body>
</html>
