---
title: 5. Kubernetes
---

### Dynamic provisioning with StorageClass

1.  Can create and use volume using StorageClass
    
2.  Can create a new StorageClass use new parameters and it will take effect on the volume created by the storage class.
    
3.  If the PV reclaim policy is delete, once PVC and PV are deleted, Longhorn volume should be deleted.
    

### Static provisioning using Longhorn created PV/PVC

1.  PVC can be used by the new workload
    
2.  Delete the PVC will not result in PV deletion
    
3.  Delete the PV will not result in Longhorn volume deletion and data loss.
    

### Test cases using kubectl

| **#**    | **Test Case** | **Test Instructions** | **Expected Results** | **Automated ? / test name** |
| --- | --- | --- | --- | --- |
| 1   | Disable Volume Expansion for volumes dynamically provisioned by a new StorageClass<br><br>  <br><br>[StorageClass example manifest](https://github.com/longhorn/longhorn/blob/master/examples/storageclass.yaml) | 1.  Create a new StorageClass with `allowVolumeExpansion: false`<br>2.  Create a PVC with using the new StorageClass | *   New Storage class should be created<br>*   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound`<br>*   Volume expansion feature should be disabled for all Volumes using the new Storage Class |     |
| 2   | Number of volume replicas volumes dynamically provisioned by a new StorageClass | 1.  Create a new StorageClass, update`numberOfReplicas` parameter<br>2.  Create a PVC with using the new StorageClass | *   New Storage class should be created<br>*   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound`<br>*   Volume number of replicas should match `numberOfReplicas` specified in storagecalss parameter |     |
| 3   | StorageClass `frombackup` parameter | **Prerequisite:**<br><br>*   Longhorn setting is set for Backup Target and Backup Target Credential Secret<br>*   Backup store should contain a previous volume backup<br>*   volume data checksum should be know at the time of volume backups (checksum#1)<br><br>1.  Create a StorageClass, and set `frombackup` parameter to volume backup URL in the backup store<br>2.  Create a PVC using the new StorageClass, and it’s size should be the original volume size<br>3.  Attach the new Volume to a node and check it’s data checksum | *   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound`<br>*   Restore from backup process should be triggered<br>*   New volume should contain data restored from the backup, data checksum should match (checksum#1) | test\_storage\_class\_from\_backup |
| 4   | StorageClass `diskSelector` parameter | **Prerequisite:**<br><br>*   Longhorn Disks should have tags<br><br>1.  Create a new StorageClass, set `diskSelector` parameter<br>2.  Create a PVC with using the new StorageClass | *   New Storage class should be created<br>*   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound`, volume replicas should only scheduled to Disks with tags that match `diskSelector` parameter tags |     |
| 5   | StorageClass `nodeSelector` parameter | **Prerequisite:**<br><br>*   Longhorn Node should have tags<br><br>1.  Create a new StorageClass, set `nodeSelector` parameter<br>2.  Create a PVC with using the new StorageClass | *   New Storage class should be created<br>*   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound`, volume replicas should only scheduled to Nodes with tags that match `nodeSelector` parameter tags |     |
| 6   | StorageClass `recurringJobs` parameter | 1.  Create a new StorageClass, set `recurringJobs` parameter<br>2.  Create a PVC with using the new StorageClass<br>3.  Create a pod that consumes the created PVC<br>4.  Check Volume recurring jobs | *   New Storage class should be created<br>*   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound` and attached to the pod<br>*   Volume should have recurring snapshots and backups matches ones specified in `recurringJobs` StorageClass parameter |  test\_statefulset\_recurring\_backup |
| 7   | StorageClass with `reclaimPolicy` parameter set to `Delete` | 1.  Create a new StorageClass, set `reclaimPolicy` parameter to `Delete`<br>2.  Create a PVC with using the new StorageClass<br>3.  Delete the PVC | *   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound`<br>*   Deleting PVC would trigger Volume delete |     |
| 8   | StorageClass with `reclaimPolicy` parameter set to `Retain` | 1.  Create a new StorageClass, set `reclaimPolicy` parameter to `Retain`<br>2.  Create a PVC with using the new StorageClass<br>3.  Delete PVC<br>4.  Delete PV | *   Volume should be dynamically provisioned, it’s PV/PVC should be `Bound`<br>*   Deleting PVC and PV will not delete longhorn volume. | test\_kubernetes\_status |
| 9   | Static provisioning using `Default Longhorn Static StorageClass Name` Setting | 1.  Update `Default Longhorn Static StorageClass Name` setting, set a new StorageClass Name, StorageClass doesn’t have to exist or be created.<br>2.  Create a Volume<br>3.  From Longhorn, Create a PV/PVC for the volume<br>4.  Check created PV `persistentVolumeReclaimPolicy: Retain`<br>5.  Create a pod consuming created PVC<br>6.  Delete the pod<br>7.  Delete PV<br>8.  Delete PVC | *   Volume should be created<br>*   Volume PV should be created using new StorageClass Name defined in `Default Longhorn Static StorageClass Name` setting<br>*   PVC should be consumed by the pod, volume should be accessible in the pod, write/read operations should work normally.<br>*   Deleting PV/PVC will not trigger volume delete. |  test\_pvc\_creation\_with\_default\_sc\_set |


### Additional Tests to be executed from Rancher

| **#**    | **Scenario** | **Steps** | **Expected Results** |
| --- | --- | --- | --- |
| 1   | Storage Class: Create a Longhorn storage class | **Pre condition:**<br><br>*   Longhorn is deployed in the cluster<br><br>**Steps:**<br><br>1.  Go to cluster → Storage → Storage Classes<br>2.  Click on Add class<br>3.  Select Provisioner **Longhorn**<br>4.  Give in other required parameters including replica count.<br>5.  Click on **Save**.<br>6.  Verify **test-1** storage class is created<br>7.  Go to Cluster → Project (default) → Workloads<br>8.  Deploy a workload<br>9.  In the Volumes section → Add a New Volume Claim → Use a Storage Class to provision a new persistent volume → Select **test-1** from Storage class dropdown.<br>10.  Enter capacity and Name. Click on Define<br>11.  Enter Mount Point.<br>12.  Click on create workload<br>13.  Verify workload is created successfully.<br>14.  Volume gets attached to the pod in the workload<br>15.  Navigate to Longhorn UI.<br>16.  Verify user is able to view the volume attached to the workload in the UI<br>17.  Navigate to volume details page of the volume and Verify the replica count mentioned in Step 4 is available | *   Longhorn storage class should be created<br>*   Workload should be deployed with the volume mounted from the storage class<br>*   Verify volume is available on the Longhorn UI.<br>*   Verify the replica count is as mentioned during storage class creation. |
| 2   | Persistent Volume: Create a PV | **Pre condition:**<br><br>*   Longhorn is deployed in the cluster<br><br>**Steps:**<br><br>1.  Create a Volume in Longhorn UI `test-volume`<br>2.  Go to cluster → Storage → Persistent Volumes<br>3.  Click on Add PV<br>4.  Select Volume Plugin **Longhorn**<br>5.  Give in other required parameters including replica count.<br>6.  Give in Volume Plugin - `test-volume` which an existing volume in longhorn<br>7.  Click on **Save**.<br>8.  Verify **test-1** PV is created<br>9.  Go to Cluster → Project (default) → Workloads<br>10.  Deploy a workload<br>11.  In the Volumes section → Add a New Volume Claim → Use an existing persistent volume → Select **test-1** from PV dropdown.<br>12.  Click on Define<br>13.  Enter Mount Point.<br>14.  Click on create workload<br>15.  Verify workload is created successfully.<br>16.  Volume gets attached to the pod in the workload<br>17.  Navigate to Longhorn UI.<br>18.  Verify user is able to view the volume attached to the workload in the UI<br>19.  Navigate to volume details page of the volume and Verify the replica count mentioned in Step 4 is available | *   Longhorn PV should be created<br>*   Workload should be deployed with the volume mounted from the PV<br>*   Verify volume is available on the Longhorn UI.<br>*   Verify the replica count is as mentioned during storage class creation. |
| 3   | Create Storage class in Rancher; From Longhorn create volumes from this storage class. | **Pre condition:**<br><br>*   Longhorn is deployed in the cluster<br><br>**Steps:**<br><br>1.  Go to cluster → Storage → Storage Classes<br>2.  Click on Add class<br>3.  Select Provisioner **Longhorn**<br>4.  Give in other required parameters including replica count.<br>5.  Click on **Save**.<br>6.  Verify **test-1** storage class is created<br>7.  Go to Longhorn UI<br>8.  In the Settings page for “Default Longhorn Static StorageClass Name”, give in the value: “test-1”<br>9.  Go to Volumes page, click on create volume.<br>10.  Create a volume name : v1<br>11.  Verify v1 is created<br>12.  using kubectl -<br>13.  kubectl get pv <volume-name> -o yaml<br>14.  Verify “storageClassName:” ---> test-1 | *   Longhorn storage class should be created<br>*   Value of Default Longhorn Static StorageClass Name should be changed in the settings page<br>*   volume should be created in longhorn UI<br>*   “storageClassName:” value should be **test-1** |
| 4   | Create Storage Class using backup URL | 1.  Create volume and PV/PVC/POD in Longhorn<br>2.  Write `test_data` into pod<br>3.  Create a snapshot and back it up. Get the backup URL<br>4.  Create a new StorageClass `longhorn-from-backup` in rancher and set backup URL.<br>5.  Use `longhorn-from-backup` to create a new PVC<br>6.  Wait for the volume to be created and complete the restoration.<br>7.  Create the pod using the PVC. Verify the data |     |
| 5   | Create Storage class - by using different values for the input list of paramters | **Pre condition:**<br><br>*   Longhorn is deployed in the cluster<br><br>**Steps:**<br><br>1.  Go to cluster → Storage → Storage Classes<br>2.  Click on Add class<br>3.  Select Provisioner **Longhorn**<br>4.  Give in other required parameters.<br>5.  Click on **Save**.<br>6.  Use this storage class to create a PVC and deploy in a workload.<br>7.  Verify the parameters of the volume created. | Volume parameters should match the storage class paramaters. |
| 6   | StorageClass with `reclaimPolicy` parameter set to `Delete` - PVC from storage class | **Pre conditions:**<br><br>*   Create PVC from “Longhorn” storage class in rancher.<br>*   It will have a dynamic PV bound<br><br>**Steps**:<br><br>1.  'Delete PVC from Rancher<br>2.  Verify PVC is deleted<br>3.  Verify PV bound to this PVC is deleted - Rancher → Cluster → Storage → PV<br>4.  Verify the volume(Dynamic PV) in Longhorn is deleted |     |
| 7   | Volume/PV/PVC created in Longhorn | **Pre conditions:**<br><br>*   Create volume, PV, PVC in longhorn<br><br>**Steps:**<br><br>1.  'Delete PVC from Rancher<br>2.  Verify PVC is deleted<br>3.  PV will NOT. be deleted but be in “released” state in Rancher UI<br>4.  Verify Volume does not get deleted |     |
| 8   | StorageClass with `reclaimPolicy` parameter set to `Retain` - PVC from storage class | **Pre conditions:**<br><br>*   Create PVC from “Longhorn” storage class in rancher.<br>*   It will have a dynamic PV bound<br><br>**Steps**:<br><br>1.  'Delete PVC from Rancher<br>2.  Verify PVC is deleted<br>3.  Verify PV bound to this PVC is NOT deleted - Rancher → Cluster → Storage → PV<br>4.  Verify the volume(Dynamic PV) in Longhorn is NOT deleted |   |
| 9   | StorageClass with `reclaimPolicy` parameter set to `Retain` - Volume/PV/PVC created in Longhorn | **Pre conditions:**<br><br>*   Create volume, PV, PVC in longhorn<br><br>**Steps:**<br><br>1.  'Delete PVC from Rancher<br>2.  Verify PVC is deleted<br>3.  PV will NOT. be deleted but be in “released” state in Rancher UI<br>4.  Verify Volume does not get deleted |     |
| 10  | Power down node | 1.  Power down<br>2.  Replica migrates<br>3.  Power back on<br>4.  Verify if the replicas in the node have been deleted | *   When a node is powered down, the replica is rebuilt on the 4th wrker node.<br>*   When the node is powered back on, and the replica on the powered down node is not available in Longhorn UI anymore, there is no data in `/var/lib/longhorn/replicas` folder in the powered on node. |
| 11  | Power down node with. Node tag/disk tag | 1.  Add a node tag/disk tag<br>2.  Power down<br>3.  Replica cannot migrate<br>4.  Power back on<br>5.  Replica should get rebuilt on this node | *   When a node is powered down, the replica is rebuilt on the 4th wrker node.<br>*   When the node is powered back on, and the replica on the powered down node is not available in Longhorn UI anymore, there is no data in `/var/lib/longhorn/replicas` folder in the powered on node.<br>*   The new replica is rebuilt on a node which has a tag. |
| 12  | Drain a node | 1.  Drain use case — drain a worker node <br>2.  Check if the State of the node reflects in the Longhorn UI —> Node<br>3.  Verify if replica is rebuilt on another node? <br>4.  Verify if the pod migrates<br>5.  And the volume get migrated | All the components should be successfully drained. |
| 13  | kubectl - force drain | Using kubectl - force drain a node where the pod with the volume attached is available<br><br>Have snapshots before<br><br>Verify data after pod migrates | Volume attaches on the new pod<br><br>2 of the 3 replicas are in “Stopped” state - Caused replica rebuild. |
| 14  | Cordon a node | 1.  Cordon state - cordon a worker node |     |
| 15  | Delete node where the pods/workload exists<br><br>**workload type: deployment** | Verify the pods migrate to another node and verify the volume also re attaches on the pod on the other node | *   Create a workload with volume attached on n1<br>*   write data to volume<br>*   Delete node n1<br>*   The workload gets reattached to another node n2.<br>*   The volume gets attached after a minute<br>*   The volume is accessible.<br>*   data is accessible |
| 16  | Power down node where the pods/workload exists<br><br>**workload type: deployment** | Verify the pods migrate to another node and verify the volume also re attaches on the pod on the other node | host A → Pod a – Unknown – > Not able to unmount<br><br>host b → pod b - Creating – fails to attach here |
| 17  | Delete node where the pods/workload exists<br><br>**workload type: stateful set** | *   Create a workload, scale - 2 with volume attached on n1<br>*   write data to volume<br>*   Delete node n1, and n2 | *   The workload gets reattached to another node n3 and n4.<br>*   The volume gets attached after sometime<br>*   The volume is accessible.<br>*   data is accessible |
| 18  | Power down node where the pods/workload exists<br><br>**workload type: stateful set** | *   Create a workload, attach to a volume.<br>*   Write some data<br>*   Power down the node where the pod is running. | *   The pod should get recreated on another node.<br>*   The volume should get reattached.<br>*   The mount point should be accessible to read and write. |
| 19  | Delete worker node one by one |     | *   The volume should get reattach to healthy node. |     |     |
| 20  | Upgrade cluster - drain set - false | 1.  In Rancher - upgrade a cluster by changing the max-pods value<br>2.  The cluster will go into “Updating” state<br>3.  Verify upgrade completes successfully | Upgrade should finish successfully |
| 21  | Upgrade cluster - drain set - true | 1.  In Rancher - upgrade a cluster by changing the max-pods value<br>2.  The cluster will go into “Updating” state<br>3.  Verify upgrade completes successfully | Upgrade should finish successfully |
