---
title: 6. Backup
---

Automation Tests
----------------

| **#**    | **Test name** | **Description** | **tag** |
| --- | --- | --- | --- |
| 1   | test\_backup | Test basic backup<br><br>Setup:<br><br>1.  Create a volume and attach to the current node<br>2.  Run the test for all the available backupstores.<br><br>Steps:<br><br>1.  Create a backup of volume<br>2.  Restore the backup to a new volume<br>3.  Attach the new volume and make sure the data is the same as the old one<br>4.  Detach the volume and delete the backup.<br>5.  Wait for the restored volume's `lastBackup` to be cleaned (due to remove the backup)<br>6.  Delete the volume | Backup |
| 2   | test\_backup\_labels | Test that the proper Labels are applied when creating a Backup manually.<br><br>1.  Create a volume<br>2.  Run the following steps on all backupstores<br>3.  Create a backup with some random labels<br>4.  Get backup from backupstore, verify the labels are set on the backups | Backup |
| 3   | test\_deleting\_backup\_volume | Test deleting backup volumes<br><br>1.  Create volume and create backup<br>2.  Delete the backup and make sure it's gone in the backupstore | Backup |
| 4   | test\_listing\_backup\_volume | Test listing backup volumes<br><br>1.  Create three volumes: `volume1/2/3`<br>2.  Setup NFS backupstore since we can manipulate the content easily<br>3.  Create snapshots for all three volumes<br>4.  Rename `volume1`'s `volume.cfg` to `volume.cfg.tmp` in backupstore<br>5.  List backup volumes. Make sure `volume1` errors out but found other two<br>6.  Restore `volume1`'s `volume.cfg`.<br>7.  Make sure now backup volume `volume1` can be found and deleted<br>8.  Delete backups for `volume2/3`, make sure they cannot be found later | Backup |
| 5   | test\_ha\_backup\_deletion\_recovery | \[HA\] Test deleting the restored snapshot and rebuild<br><br>Backupstore: all<br><br>1.  Create volume and attach it to the current node.<br>2.  Write `data` to the volume and create snapshot `snap2`<br>3.  Backup `snap2` to create a backup.<br>4.  Create volume `res_volume` from the backup. Check volume `data`.<br>5.  Check snapshot chain, make sure `backup_snapshot` exists.<br>6.  Delete the `backup_snapshot` and purge snapshots.<br>7.  After purge complete, delete one replica to verify rebuild works. | Backup |
| 6   | test\_backup\_kubernetes\_status | Test that Backups have KubernetesStatus stored properly when there is an associated PersistentVolumeClaim and Pod.<br><br>1.  Setup a random backupstore<br>2.  Set settings Longhorn Static StorageClass to `longhorn-static-test`<br>3.  Create a volume and PV/PVC. Verify the StorageClass of PVC<br>4.  Create a Pod using the PVC.<br>5.  Check volume's Kubernetes status to reflect PV/PVC/Pod correctly.<br>6.  Create a backup for the volume.<br>7.  Verify the labels of created backup reflect PV/PVC/Pod status.<br>8.  Restore the backup to a volume. Wait for restoration to complete.<br>9.  Check the volume's Kubernetes Status<br>    1.  Make sure the `lastPodRefAt` and `lastPVCRefAt` is snapshot created time<br>        <br>10.  Delete the backup and restored volume.<br>11.  Delete PV/PVC/Pod.<br>12.  Verify volume's Kubernetes Status updated to reflect history data.<br>13.  Attach the volume and create another backup. Verify the labels<br>14.  Verify the volume's Kubernetes status.<br>15.  Restore the previous backup to a new volume. Wait for restoration.<br>16.  Verify the restored volume's Kubernetes status.<br>    1.  Make sure `lastPodRefAt` and `lastPVCRefAt` matched volume on step 12 | Backup |
| 7   | test\_restore\_inc | Test restore from disaster recovery volume (incremental restore)<br><br>Run test against all the backupstores<br><br>1.  Create a volume and attach to the current node<br>2.  Generate `data0`, write to the volume, make a backup `backup0`<br>3.  Create three DR(standby) volumes from the backup: `sb_volume0/1/2`<br>4.  Wait for all three DR volumes to finish the initial restoration<br>5.  Verify DR volumes's `lastBackup` is `backup0`<br>6.  Verify snapshot/pv/pvc/change backup target are not allowed as long as the DR volume exists<br>7.  Activate standby `sb_volume0` and attach it to check the volume data<br>8.  Generate `data1` and write to the original volume and create `backup1`<br>9.  Make sure `sb_volume1`'s `lastBackup` field has been updated to `backup1`<br>10.  Wait for `sb_volume1` to finish incremental restoration then activate<br>11.  Attach and check `sb_volume1`'s data<br>12.  Generate `data2` and write to the original volume and create `backup2`<br>13.  Make sure `sb_volume2`'s `lastBackup` field has been updated to `backup1`<br>14.  Wait for `sb_volume2` to finish incremental restoration then activate<br>15.  Attach and check `sb_volume2`'s data<br>16.  Create PV, PVC and Pod to use `sb_volume2`, check PV/PVC/POD are good | Backup: Disaster Recovery |
| 8   | test\_recurring\_job | Test recurring job<br><br>1.  Setup a random backupstore<br>2.  Create a volume.<br>3.  Create two jobs 1 job 1: snapshot every one minute, retain 2 1 job 2: backup every two minutes, retain 1<br>4.  Attach the volume.<br>5.  Sleep for 5 minutes<br>6.  Verify we have 4 snapshots total<br>    1.  2 snapshots, 1 backup, 1 volume-head<br>        <br>7.  Update jobs to replace the backup job<br>    1.  New backup job run every one minute, retain 2<br>        <br>8.  Sleep for 5 minutes.<br>9.  We should have 6 snapshots<br>    1.  2 from job\_snap, 1 from job\_backup, 2 from job\_backup2, 1 volume-head<br>        <br>10.  Make sure we have no more than 5 backups.<br>    1.  old backup job may have at most 1 backups<br>        <br>    2.  new backup job may have at most 3 backups<br>        <br>11.  Make sure we have no more than 2 backups in progress | Backup: Recurring Job |
| 9   | test\_recurring\_job\_in\_storageclass | Test create volume with StorageClass contains recurring jobs<br><br>1.  Create a StorageClass with recurring jobs<br>2.  Create a StatefulSet with PVC template and StorageClass<br>3.  Verify the recurring jobs run correctly. | Backup: Recurring Job<br><br>Kubernetes |
| 10  | test\_recurring\_job\_in\_volume\_creation | Test create volume with recurring jobs<br><br>1.  Create volume with recurring jobs though Longhorn API<br>2.  Verify the recurring jobs run correctly | Backup: Recurring Job |
| 11  | test\_recurring\_job\_kubernetes\_status | Test RecurringJob properly backs up the KubernetesStatus<br><br>1.  Setup a random backupstore.<br>2.  Create a volume.<br>3.  Create a PV from the volume, and verify the PV status.<br>4.  Create a backup recurring job to run every 2 minutes.<br>5.  Verify the recurring job runs correctly.<br>6.  Verify the backup contains the Kubernetes Status labels | Backup: Recurring Job<br><br>Volume: Kubernetes Status |
| 12  | test\_recurring\_job\_labels | Test a RecurringJob with labels<br><br>1.  Set a random backupstore<br>2.  Create a backup recurring job with labels<br>3.  Verify the recurring jobs runs correctly.<br>4.  Verify the labels on the backup is correct | Backup: Recurring Job |
| 13  | test\_recurring\_jobs\_maximum\_retain | Test recurring jobs' maximum retain<br><br>1.  Create two jobs, with retain 30 and 21.<br>2.  Try to apply the jobs to a volume. It should fail.<br>3.  Reduce retain to 30 and 20.<br>4.  Now the jobs can be applied the volume | Backup: Recurring Job |

Backup create operations test cases
-----------------------------------

|**#**| **Test Case** | **Test Instructions** | **Expected Results** |
|-----| --- | --- | --- |
| 1   | Create backup from existing snapshot | **Prerequisite:**<br><br>*   Backup target is set to NFS server, or S3 compatible target.<br><br>1.  Create a workload using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a snapshot (snapshot#1)<br>4.  Create a backup from (snapshot#1)<br>5.  Restore backup to a different volume<br>6.  Attach volume to a node and check it’s data, and compute it’s checksum | *   Backup should be created<br>*   Restored volume data checksum should match (checksum#1) |
| 2   | Create volume backup for a volume attached to a node | **Prerequisite:**<br><br>*   Backup target is set to NFS server, or S3 compatible target.<br><br>1.  Create a volume, attach it to a node<br>2.  Format volume using ext4/xfs filesystem and mount it to a directory on the node<br>3.  Write data to volume, compute it’s checksum (checksum#1)<br>4.  Create a backup<br>5.  Restore backup to a different volume<br>6.  Attach volume to a node and check it’s data, and compute it’s checksum<br>7.  Check volume backup labels | *   Backup should be created<br>*   Restored volume data checksum should match (checksum#1)<br>*   backup should have no backup labels |
| 3   | Create volume backup used by Kubernetes workload | **Prerequisite:**<br><br>*   Backup target is set to NFS server, or S3 compatible target.<br><br>1.  Create a deployment workload with `nReplicas = 1` using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a backup<br>4.  Check backup labels<br>5.  Scale down deployment `nReplicas = 0`<br>6.  Delete Longhorn volume<br>7.  Restore backup to a volume with the same deleted volume name<br>8.  Scale back deployment `nReplicas = 1`<br>9.  Check volume data checksum | *   Backup labels should contain the following information about workload that was using the volume at time of backup.<br>    *   Namespace<br>        <br>    *   PV Name<br>        <br>    *   PVC Name<br>        <br>    *   PV Status<br>        <br>    *   Workloads Status<br>        <br>        *   Pod Name  <br>            Workload Name  <br>            Workload Type  <br>            Pod Status<br>            <br>*   After volume restore, data checksum should match (checksum#1) |
| 4   | Create volume backup with customized labels | **Prerequisite:**<br><br>*   Backup target is set to NFS server, or S3 compatible target.<br><br>1.  Create a volume, attach it to a node<br>2.  Create a backup, add customized labels  <br>    key: `K1` value: `V1`<br>3.  Check volume backup labels | *   Backup should be created with customized labels |
| 5   | Create recurring backups | 1.  Create a deployment workload with `nReplicas = 1` using Longhorn volume<br>2.  Write data to volume , compute it’s checksum (checksum#1)<br>3.  Create a recurring backup `every 5 minutes`. and set retain count to `5`<br>4.  add customized labels key: `K1` value: `V1`<br>5.  Wait for recurring backup to triggered (backup#1, backup#2 )<br>6.  Scale down deployment `nReplicas = 0`<br>7.  Delete the volume.<br>8.  Restore backup to a volume with the same deleted volume name<br>9.  Scale back deployment `nReplicas = 1`<br>10.  Check volume data checksum | *   backups should be created with Kubernetes status labels and customized labels<br>*   After volume restore, data checksum should match (checksum#1)<br>*   after restoring the backup recurring backups should continue to be created |
| 6   | Backup created using Longhorn behind proxy | **Prerequisite:**<br><br>*   Setup a Proxy on an instance (Optional: use squid)<br>*   Create a single node cluster in EC2<br>*   Deploy Longhorn<br><br>1.  Block outgoing traffic except for the proxy instance.<br>2.  Create AWS secret in longhorn.<br>3.  In UI Settings page, set backupstore target and backupstore credential secret<br>4.  Create a volume, attach it to a node, format the volume, and mount it to a directory.<br>5.  Write some data to the volume, and create a backup. | *   Ensure backup is created |
| 7   | Backup created in a backup store supports Virtual Hosted Style | 1.  Create an OSS bucket in Alibaba Cloud(Aliyun)<br>2.  Create a secret without `VIRTUAL_HOSTED_STYLE` for the OSS bucket.<br>3.  Set backup target and the secret in Longhorn UI. |     |
| 8   | Backup created in a backup store supports both Virtual Hosted style and traditional | 1.  Create an S3 bucket in AWS.<br>2.  Create a secret without `VIRTUAL_HOSTED_STYLE` for the S3 bucket.<br>3.  Set backup target and the secret in Longhorn UI.<br>4.  Verify backup list/create/delete/restore work fine without the configuration. |     |

Backup restore operations test cases
------------------------------------

|  **#**   | **Test Case** | **Test Instructions** | **Expected Results** |
| --- | --- | --- | --- |
| 1   | Filter backup using backup name | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br><br>1.  Filter backups by volume name | *   volumes should be filtered using full/partial volume names |
| 2   | Restore last backup with different name | **Prerequisite:**<br><br>*   Create a Volume, attach it to a node, write some data (300MB+), compute it’s checksum and create a backup (repeat for 3 times).<br>*   Volume now has multiple backups (backup#1, backup#2, backup#3) respectively.<br><br>1.  Restore latest volume backup using **different** name than it’s original<br>2.  After restore complete, attach the volume to a node, and check data checksum | *   New Volume should be created and attached to a node in maintenance mode<br>*   Restore process should be triggered restoring latest backup content to the volume<br>*   After restore is completed, volume is detached from the node<br>*   data checksum should match data checksum for (backup#3) |
| 3   | Restore specific with different name | **Prerequisite:**<br><br>*   Create a Volume, attach it to a node, write some data (300MB+), compute it’s checksum and create a backup (repeat for 3 times).<br>*   Volume now has multiple backups (backup#1, backup#2, backup#3) respectively.<br><br>1.  Restore restore the second backup (backup#2) using **different** name than it’s original<br>2.  After restore complete, attach the volume to a node, and check data checksum | *   New Volume should be created and attached to a node in maintenance mode<br>*   Restore process should be triggered restoring latest backup content to the volume<br>*   After restore is completed, volume is detached from the node<br>*   data checksum should match data checksum for (backup#2) |
| 4   | Volume backup URL | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br><br>1.  get backup URL | *   Backup URL should point to a link to backup on configured backupstore |
| 5   | Restore backup with different number of replicas | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br><br>1.  Restore a backup and set different number of replicas | *   Restored volume replica count should match the number in restore backup request |
| 6   | Restore backup with Different Node tags | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br>*   Longhorn Nodes should have Node Tags<br><br>1.  Restore a backup and set node tags | *   Restored volume replicas should scheduled only to nodes have Node Tags match Tags specified in restore backup request |
| 7   | Restore backup with Different Disk Tags | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br>*   Longhorn Nodes Disks should have Disk Tags<br><br>1.  Restore a backup and set disk tags | *   Restored volume replicas should scheduled only to disks have Disk Tags match Tags specified in restore backup request |
| 8   | Restore backup with both Node and Disk Tags | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br>*   Longhorn Nodes should have Node Tags<br>*   Longhorn Nodes Disks should have Disk Tags<br><br>1.  Restore a backup and set both Node and Disk tags | *   Restored volume replicas should scheduled only to nodes that have both Node and Disk tags specified in restore backup request. |
| 9   | Restore last backup with same previous name (Volume already exists) | **Prerequisite:**<br><br>*   Create a Volume, attach it to a node, write some data (300MB+), compute it’s checksum and create a backup (repeat for 3 times).<br>*   Volume now has multiple backups (backup#1, backup#2, backup#3) respectively.<br><br>1.  Restore latest volume backup using **same** original volume name | *   Volume can’t be restored |
| 10  | Restore last backup with same previous name | **Prerequisite:**<br><br>*   Create a Volume, attach it to a node, write some data (300MB+), compute it’s checksum and create a backup (repeat for 3 times).<br>*   Volume now has multiple backups (backup#1, backup#2, backup#3) respectively.<br>*   Detach and delete volume<br><br>1.  Restore latest volume backup using **same** original volume name<br>2.  After restore complete, attach the volume to a node, and check data checksum | *   New Volume with same old name should be created and attached to a node in maintenance mode<br>*   Restore process should be triggered restoring latest backup content to the volume<br>*   After restore is completed, volume is detached from the node<br>*   data checksum should match data checksum for (backup#3) |
| 11  | Restore volume used by Kubernetes workload with same previous name | **Prerequisite:**<br><br>*   Create a deployment workload using a Longhorn volume, write some data (300MB+), compute it’s checksum and create a backup (repeat for 3 times).<br>*   Volume now has multiple backups (backup#1, backup#2, backup#3) respectively.<br>*   Scale down the deployment to zero<br>*   Delete volume<br><br>1.  Restore latest volume backup using **same** original volume name<br>2.  After restore complete, scale up the deployment | *   New Volume with same old name should be created and attached to a node in maintenance mode<br>*   Restore process should be triggered restoring latest backup content to the volume<br>*   After restore is completed, volume is detached from the node<br>*   Old `PV/PVC , Namespace & Attached To` information should be restored<br>*   Volume should be accessible from the deployment pod<br>*   Data checksum should match data checksum for (backup#3) |
| 12  | Restore volume used by Kubernetes workload with different name | **Prerequisite:**<br><br>*   Create a deployment workload using a Longhorn volume, write some data (300MB+), compute it’s checksum and create a backup (repeat for 3 times).<br>*   Volume now has multiple backups (backup#1, backup#2, backup#3) respectively.<br>*   Scale down the deployment to zero<br>*   Delete volume<br><br>1.  Restore latest volume backup using **different** name than its original<br>2.  After restore complete<br>    1.  Delete old PVC<br>        <br>    2.  Create a new PV for volume<br>        <br>    3.  Create a new PVC with same old PVC name<br>        <br>3.  scale up the deployment | *   New Volume with same old name should be created and attached to a node in maintenance mode<br>*   Restore process should be triggered restoring latest backup content to the volume<br>*   After restore is completed, volume is detached from the node<br>*   Old `Namespace & Attached To` information should be restored<br>*   `PV/PVC` information should be empty after restore completed  <br>    old PV `spec.csi.volumeHandle`will not match the new volume name<br>*   After New PV/PVC is created, deployment pod should be able to claim the new PVC and access volume with new name.<br>*   Data checksum should match data checksum for (backup#3) |
| 13  | Restore last backup (batch operation) | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br><br>1.  select multiple volumes, restore the latest backup for all of them | *   New volumes with same old volume names should be created, attached to nodes and restore process should be triggered<br>*   `PV/PVC` information should be restored for volumes that had PV/PVC created<br>*   `Namespace & Attached To` information should be restored for volumes that had been used by kubnernetes workload at the time of backup |
| 14  | Delete All Volume Backups | **Prerequisite:**<br><br>*   One or more backup is created for multiple volume.<br><br>1.  Delete All backups for a volume<br>2.  Check backupstore, and confirm backups has been deleted | *   Backups should not be delete from Longhorn UI, and also from backupstore. |
| 15  | Restore backup created using Longhorn behind proxy. | **Prerequisite:**<br><br>*   Setup a Proxy on an instance (Optional: use squid)<br>*   Create a single node cluster in EC2<br>*   Deploy Longhorn<br><br>1.  Block outgoing traffic except for the proxy instance.<br>2.  Create AWS secret in longhorn as follows:<br>3.  In UI Settings page, set backupstore target and backupstore credential secret<br>4.  Create a volume, attach it to a node, format the volume, and mount it to a directory.<br>5.  Write some data to the volume, and create a backup.<br>6.  Wait for backup to complete, and the try to restore the backup to a volume with different name. | *   Volume should get restored successfully. |

Disaster Recovery test cases
----------------------------

**Tests Prerequisite**

*   One Kubernetes cluster.
    
*   Backup Target set to internal Minio or NFS

| **Test Case** | **Test Instructions** | **Expected Results** |
| --- | --- | --- |
| Last Backup #1 | *   Create a new volume<br>*   Attach the volume<br>*   Create a backup of the volume | *   Volume's LastBackup and LastBackupAt should be updated<br>*   Backups can be seen from \`volume->backups\` in the volume list page, action menu<br>*   Backups can be seen from \`volume->backups\` in the volume detail page, action menu |
| Last Backup #2 | \[follow Last Backup #1\]<br><br>*   Create another backup | *   Volume's LastBackup and LastBackupAt should be updated<br>*   Backups can be seen from \`volume->backups\` in the volume list page, action menu<br>*   Backups can be seen from \`volume->backups\` in the volume detail page, action menu |
| Last Backup #3 | \[follow Last Backup #2\]<br><br>*   Delete the last backup in the backup list | *   Volume's LastBackup and LastBackupAt should be updated to empty<br>*   Backups can be seen from \`volume->backups\` in the volume list page, action menu<br>*   Backups can be seen from \`volume->backups\` in the volume detail page, action menu |
| Last Backup #4 | \[follow Last Backup #3\]<br><br>*   Create a new backup for the volume | *   Volume's LastBackup and LastBackupAt should be updated to the last backup<br>*   Backups can be seen from \`volume->backups\` in the volume list page, action menu<br>*   Backups can be seen from \`volume->backups\` in the volume detail page, action menu |
| DR volume #1 | *   Create volume X<br>*   Attach the volume X<br>*   Create a backup of X<br>*   Backup Volume list page, click \`Create Disaster Recovery Volume\` from volume dropdown<br>*   Create the DR volume Xdr<br>*   Attach the volume to any node | *   DR volume should be successfully created and attached<br>*   DR volume.LastBackup should be updated<br>*   Cannot create backup with Xdr.<br>*   Cannot create snapshot with Xdr.<br>*   Cannot change backup target when DR volume exists with tooltip 'Disaster Recovery volume'<br>*   DR icon shows next to the volume name |
| DR volume #2 | \[Follow #1\]<br><br>*   Format volume X on the attached node<br>*   Mount the volume on the node, write a empty file to it<br>*   Make a backup of Volume X | *   DR volume's last backup should be updated automatically<br>*   DR volume.LastBackup should be different from DR volume's controller\[0\].LastRestoredBackup temporarily (it's restoring the last backup)<br>*   During the restoration, DR volume cannot be activated.<br>*   Eventually, DR volume.LastBackup should equal to controller\[0\].LastRestoredBackup. |
| DR volume #3 | \[Follow #2\]<br><br>*   Activate the volume Xdr | *   Volume Xdr should be detached automatically |
| DR volume #4 | \[Follow #3\]<br><br>*   Attach the volume to a node<br>*   Mount the volume to a local directory<br>*   Check the file | *   Mount should be successful<br>*   File should exist |
| DR volume #5 | *   Create volume Y<br>*   Attach the volume Y<br>*   Create a backup of Y<br>*   Backup Volume list page, click \`Create Disaster Recovery Volume\` from volume dropdown<br>*   Create two DR volumes Ydr1 and Ydr2.<br>*   Mount the volume Y on the node<br>*   Write a file of 10Mb into it, use \`/dev/urandom\` to generate the file<br>*   Calculate the checksum of the file<br>*   Make a Backup<br>*   Attach Ydr1 and Ydr2 to any nodes | *   DR volume's last backup should be updated automatically<br>*   DR volume.LastBackup should be different from DR volume's controller\[0\].LastRestoredBackup temporarily (it's restoring the last backup)<br>*   During the restoration, DR volume cannot be activated.<br>*   Eventually, DR volume.LastBackup should equal to controller\[0\].LastRestoredBackup. |
| DR volume #6 | \[follow #5\]<br><br>*   In the directory mounted volume Y, write a new file of 100Mb.<br>*   Record the checksum of the file<br>*   Create a backup of volume Y<br>*   Wait for restoration of volume Ydr1 and Ydr2 to complete<br>*   Activate Ydr1<br>*   Attach it to one node and verify the content | *   DR volume's last backup should be updated automatically<br>*   Eventually, DR volume.LastBackup should equal to controller\[0\].LastRestoredBackup.<br>*   Ydr1 should have the same file checksum of volume Y |
| DR volume #7 | \[follow #6\]<br><br>*   In the directory mounted volume Y, remove all the files. Write a file of 50Mb<br>*   Record the checksum of the file<br>*   Create a backup of volume Y<br>*   Activate Ydr2<br>*   Attach it to one node and verify the content | *   Both Ydr1 and Ydr2 volume's last backup should be updated automatically<br>*   Eventually, Ydr2's volume.LastBackup should equal to controller\[0\].LastRestoredBackup.<br>*   Ydr2 should have the same file checksum of volume Y |
| DR volume #8 | *   Create volume Z<br>*   Attach the volume Z<br>*   Create a backup (z1) of Z<br>*   Backup Volume list page, click \`Create Disaster Recovery Volume\` from volume dropdown<br>*   Create a DR volume Zdr<br>*   Mount the volume Z on the node<br>*   Write a file of 10Mb into it<br>*   Make a Backup (z2)<br>*   Attach Zdr to any node<br>*   Confirm that Zdr complete the restoration (by observing the last restored backup to z2)<br>*   Delete the backup z2 from the backup list<br>*   Create a backup z3<br>*   Delete all the files before. Write another file of 10Mb into Z, use \`/dev/urandom\` to generate the file. Record the checksum<br>*   Confirm that Zdr complete the restoration (by observing the last restored backup to z3)<br>*   Activate Zdr and attach it<br>*   Verify the file content | *   File content checksum with Zdr should be the same as Z |

  

**Tests Prerequisite**

*   Two Kubernetes clusters, **cluster A** and **cluster B**
    
*   Backup Target set to Amazon S3

| **Test Case** | **Test Instructions** | **Expected Results** |
| --- | --- | --- |
| Backup Poll Interval #1 | *   Change the setting.BackupPoolInterval to -1 | Change shouldn't be allowed |
| Backup Poll Interval #2 | *   Change the setting.BackupPoolInterval to 0 | Change should be allowed |
| DR volume across the cluster #1 | Cluster A<br><br>*   Create volume XA<br>*   Attach the volume XA<br>*   Create a backup of XA<br><br>Cluster B<br><br>*   Backup Volume list page, click \`Create Disaster Recovery Volume\` from volume dropdown<br>*   Create the DR volume XB (which should be the same name as XA)<br>*   Attach the volume to any node | *   DR volume should be successfully created and attached<br>*   DR volume.LastBackup should be updated, after settings.BackupPollInterval passed.<br>*   Cannot create backup with XB<br>*   Cannot create snapshot with XB.<br>*   DR icon shows next to the volume name |
| DR volume across the cluster #2 | \[Follow #1\]  <br>Cluster A<br><br>*   Format volume XA on the attached node<br>*   Mount the volume on the node, write a empty file to it<br>*   Make a backup of Volume XA | Cluster B<br><br>*   DR volume's last backup should be updated automatically, after settings.BackupPollInterval passed.<br>*   DR volume.LastBackup should be different from DR volume's controller\[0\].LastRestoredBackup temporarily (it's restoring the last backup)<br>*   During the restoration, DR volume cannot be activated.<br>*   Eventually, DR volume.LastBackup should equal to controller\[0\].LastRestoredBackup. |
| DR volume across the cluster #3 | \[Follow #2\]<br><br>*   Activate the volume XB | *   Volume XB should be detached automatically |
| DR volume across the cluster #4 | \[Follow #3\]  <br>Cluster B:<br><br>*   Attach the volume XB to a node<br>*   Mount the volume XB to a local directory<br>*   Check the file on XB | *   Mount should be successful<br>*   File should exist |
| DR volume across the cluster #5 | Cluster A:<br><br>*   Create volume Y<br>*   Attach the volume Y<br>*   Create a backup of Y<br><br>Cluster B:<br><br>*   Backup Volume list page, click \`Create Disaster Recovery Volume\` from volume dropdown<br>*   Create two DR volumes Ydr1 and Ydr2.<br>*   Attach the volume Y to any node<br>*   Mount the volume Y on the node<br>*   Write a file of 10Mb into it, use \`/dev/urandom\` to generate the file<br>*   Calculate the checksum of the file<br>*   Make a Backup<br>*   Attach Ydr1 and Ydr2 to any nodes | *   DR volume's last backup should be updated automatically, after settings.BackupPollInterval passed.<br>*   DR volume.LastBackup should be different from DR volume's controller\[0\].LastRestoredBackup temporarily (it's restoring the last backup)<br>*   During the restoration, DR volume cannot be activated.<br>*   Eventually, DR volume.LastBackup should equal to controller\[0\].LastRestoredBackup. |
| DR volume across the cluster #6 | \[follow #5\]  <br>Cluster A:<br><br>*   In the directory mounted volume Y, write a new file of 100Mb.<br>*   Record the checksum of the file<br>*   Create a backup of volume Y<br><br>Cluster B:<br><br>*   Wait for restoration of volume Ydr1 and Ydr2 to complete<br>*   Activate Ydr1<br>*   Attach it to one node and verify the content | *   DR volume's last backup should be updated automatically, after settings.BackupPollInterval passed.<br>*   Eventually, DR volume.LastBackup should equal to controller\[0\].LastRestoredBackup.<br>*   Ydr1 should have the same file checksum of volume Y |
| DR volume across the cluster #7 | \[follow #6\]  <br>Cluster A<br><br>*   In the directory mounted volume Y, remove all the files. Write a file of 50Mb<br>*   Record the checksum of the file<br><br>Cluster B<br><br>*   Change setting.BackupPollInterval to longer e.g. 1h<br><br>Cluster A<br><br>*   Create a backup of volume Y<br><br>Cluster B  <br>\[DO NOT CLICK BACKUP PAGE, which will update last backup as a side effect\]<br><br>*   Before Ydr2's last backup updated, activate Ydr2 | *   YBdr2's last backup should be immediately updated to the last backup of volume Y<br>*   Activate should fail due to restoration is in progress | When user clicks on “activate DRV”, restoration happens<br><br>And the volume goes into detached state |
| DR volume across the cluster #8 | Cluster A<br><br>*   Create volume Z<br>*   Attach the volume Z<br>*   Create a backup of Z<br><br>Cluster B<br><br>*   Backup Volume list page, click \`Create Disaster Recovery Volume\` from volume dropdown<br>*   Create DR volumes Zdr1, Zdr2 and Zdr3<br>*   Attach the volume Zdr1, Zdr2 and Zdr3 to any node<br>*   Change setting.BackupPollInterval to appropriate interval for multiple backups e.g. 15min<br>*   Make sure LastBackup of Zdr is consistent with that of Z<br><br>Cluster A<br><br>*   Create multiple backups for volume Z before Zdr's last backup updated. For each backup, write or modify at least one file then record the checksum.<br><br>Cluster B<br><br>*   Wait for restoration of volume Zdr1 to complete<br>*   Activate Zdr1<br>*   Attach it to one node and verify the content | *   Zdr1's last backup should be updated after settings.BackupPollInterval passed.<br>*   Zdr1 should have the same files with the the same checksums of volume Z |
| DR volume across the cluster #9 | \[follow #8\]  <br>Cluster A<br><br>*   Delete the latest backup of Volume Z | *   Last backup of Zdr2 and Zdr3 should be empty after settings.BackupPollInterval passed. Field controller\[0\].LastRestoredBackup and controller\[0\].RequestedBackupRestore should retain. |
| DR volume across the cluster #10 | \[follow #9\]  <br>Cluster B<br><br>*   Activate Zdr2<br>*   Attach it to one node and verify the content | *   Zdr2 should have the same files with the the same checksums of volume Z |     |
| DR volume across the cluster #11 | \[follow #10\]  <br>Cluster A<br><br>*   Create one more backup with at least one file modified.<br><br>Cluster B<br><br>*   Wait for restoration of volume Zdr3 to complete<br>*   Activate Zdr3<br>*   Attach it to one node and verify the content | *   Zdr3 should have the same files with the the same checksums of volume Z |

**Additional tests**
--------------------

| **#**    | **Scenario** | **Steps** | **Expected result** |
| --- | --- | --- | --- |
| 1   | Create backup from existing snapshot when multiple snapshots exist | 1.  Create a workload using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a snapshot S1<br>4.  Write data to volume, compute it’s checksum (checksum#2)<br>5.  Create a snapshot S2<br>6.  Create a backup from (snapshot#2)<br>7.  Restore backup to a different volume<br>8.  Attach volume to a node and check it’s data, and compute it’s checksum | Verify the checksum of the restored volume is same as checksum#2 |
| 2   | Create backups, after deleting snapshots | 1.  Create a workload using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a snapshot S1<br>4.  Write data to volume, compute it’s checksum (checksum#2)<br>5.  Create a snapshot S2<br>6.  Write data to volume, compute it’s checksum (checksum#3)<br>7.  Create a snapshot S3<br>8.  Delete S2<br>9.  Create a backup b1 from S3<br>10.  Restore backup to a different volume<br>11.  Attach volume to a node and check it’s data, and compute it’s checksum | Verify the checksum of the restored volume is same as checksum#3 |
| 3   | Backup from Snapshots | 1.  Create a workload using Longhorn volume<br>2.  Write data to volume, compute it’s checksum (checksum#1)<br>3.  Create a snapshot S1<br>4.  Write data to volume, compute it’s checksum (checksum#2)<br>5.  Create a snapshot S2<br>6.  Create a backup b1 from snapshot S2<br>7.  Restore backup to a different volume<br>8.  Attach volume to a node and check it’s data, and compute it’s checksum | Verify the checksum of the restored volume is same as checksum#2 |
| 4   | Manual and recurring snapshots count - recurring backups should not delete any manual backups taken | 1.  Enable recurring backups on a volume - every minute, retain count = 5<br>2.  After 2 minutes, after 2 recurring backups have been taken, create a couple of manual backups on the volume.<br>3.  Verify the volumes in the backup page for volume.<br>4.  After 5 minutes, verify 2 manual backups and 5 recurring backups are available in the backup page<br>5.  After 6th minute, verify one of the recurring backups - the oldest one is removed and new one is available in the backup page. | Verify recurring backups should not delete any manual backups taken |     |
| 5   | Restore with invalid node tag/disk tag | Volume v1 - with backups - b1, b2, b3 exist<br><br>1.  Restore from b1 - specify an invalid node tag and click on OK<br>2.  Verify volume is NOT restored and an error is seen - `specified node tag <name> does not exist`<br>3.  Restore from b1 - specify an invalid disk tag and click on OK<br>4.  Verify volume is NOT restored and an error is seen - `specified disk tag <name> does not exist` | Volume should NOT be restored.<br><br>Error should be seen on the UI |     |
| 6   | Use Volume backup URL in a storage class | 1.  Get backup URL from a backup created for a volume.<br>2.  Use the URL StorageClass `fromBackup`<br>3.  Create a PVC from the storage class and attach to volume on a workload<br>4.  workload should be deployed successfully/ |
| 7   | Recurring snapshots/backups of volume in “Detached” mode | 1.  Create a volume/PV/PVC<br>2.  Deploy it to a workload.<br>3.  Enable recurring backups for every minute<br>4.  Verify recurring backups happen on the volume.<br>5.  From the longhorn UI, detach the volume.<br>6.  Verify the Recurring snapshots/backups do not happen |     |     |
| 8   | Disabling recurring backups | Precondition:<br><br>*   Volume is created and deployed to a workload<br><br>Steps:<br><br>1.  Enable recurring backups ex - every minute<br>2.  Wait for a couple of minutes. 2 backups should be available for the volume.<br>3.  Disable recurring backups. for this volume<br>4.  Verify that the recurring backups should stop happening for the volume | *   Recurring backups should be STOPPED for the volume. |
| 9   | Backup corruption in S3/nfs backup store - Rename config file for the volume | **Pre condition:**<br><br>*   Volume v1, v2 exists<br>*   v1 has backups - b1, b2, b3 and v2 has backups - b4,b5<br><br>**Steps:**<br><br>1.  Rename config file for the v1 in S3 volume.cfg file to volume.cfg.tmp<br>2.  Verify that the backup list does not list the backups for that volume<br>3.  Verify an error message is displayed on the UI<br>4.  Verify user is able to list the backups of v2 | *   User should be able to see an error message in the UI when it failed to fetch the backups for the backup for volume v1<br>*   User should be able to list the backups of volume v2 |     |
| 10  | Delete a volume backup when it is corrupted in S3/nfs backup store | **Pre condition:**<br><br>*   Volume v1, v2 exists<br>*   v1 has backups - b1, b2, b3 and v2 has backups - b4,b5<br><br>**Steps:**<br><br>1.  Rename config file for the v1 volume.cfg file to volume.cfg.tmp<br>2.  Verify that the backup list does not list the backups for that volume<br>3.  Verify an error message is displayed on the UI<br>4.  Verify user is able to delete the backup of v1 from the backup page | *   User should be able to delete the corrupted backup for volume v1 by clicking on delete all backups.<br>*   User should be able to list the backups of volume v2 |     |
| 11  | Backup corruption in S3/nfs backup store - Rename config file of the | **Pre condition:**<br><br>*   Volume v1, v2 exists<br>*   v1 has backups - b1, b2, b3 and v2 has backups - b4,b5<br><br>**Steps:**<br><br>1.  Rename the backup b1.cfg to b1.cfg.tmp<br>2.  Verify the backup page lists the volumes v1 and v2<br>3.  Verify backup list page for v1 is able to fetch all the backups except the b1 - b1 SHOULD NOT be listed<br>4.  verify user is able to restore from b2 and b3<br>5.  Verify the data after restoration is correct<br>6.  Verify user is able to list b4 and b5 for volume v2 also. | *   User should be able to list b2 and b3.<br>*   User should be able to restore from b2 and b3<br>*   User should be able to see an error for b1 - b1 SHOULD NOT be listed<br>*   User should be able to list the backups of volume v2 |     |
| 12  | Backup corruption in S3/nfs backup store - Edit data of a backup | **Pre condition:**<br><br>*   Volume v1, v2 exists<br>*   v1 has backups - b1, b2, b3 and v2 has backups - b4,b5<br><br>**Steps:**<br><br>1.  Edit data (remove some checksum value) of back up b1 and upload to S3<br>2.  Verify the backup page lists the volumes v1 and v2 and all the backups<br>3.  Verify user is able to restore from b1<br>4.  Verify the restored data is not the same as the original data (check the checksums)<br>5.  Take b4, b5 for `v1`<br>6.  User should be able to restore from b4 and b5 | User should be able to list b1<br><br>User should be able to restore from b1<br><br>Other backups for v1 - b2 and b3 should be available<br><br>Backups for v2 - b4 and b5 should be available |     |
| 13  | Delete all backups and create backups for same volumes | 1.  Create vol-1, use it to a workload and write data to the volume<br>2.  Take backups b1, b2<br>3.  Delete all backups for the volume<br>4.  verify volume is deleted from the S3 backup store and the Longhorn UI in backup page.<br>5.  Take a backup for volume vol-1 b3<br>6.  Verify b3 is saved in S3 and is available in abckup list page for the volume vol-1 |     |
| 14  | Delete Backup verify blocks deleted from backupstore | 1.  Create a volume, attach to a pod and write into it.<br>2.  Set up a S3 backup store.<br>3.  Take a backup. Wait for it to complete.<br>4.  Check the size of backup in backup store.<br>5.  Delete the backup.<br>6.  Check the size in the backup storage. It is same as earlier.<br>7.  Blocks should be deleted. |     |     |

Additional UI test cases
------------------------

| **#**    | **Scenario** | **Steps** | **Expected Results** |
| --- | --- | --- | --- |
| 1   | Column sort | 1.  Navigate to Backup page<br>2.  Verify column sort works for all the columns | Column sorting should. work |
| 2   | Column sort | 1.  Navigate to Backup page<br>2.  Click on a volume v1<br>3.  User will be navigate to Backup/v1 page<br>4.  Verify column sort works for all the columns | Column sorting should. work |
| 3   | Workload Pod status | 1.  Navigate to Backup page<br>2.  Click on a volume v1<br>3.  User will be navigate to Backup/v1 page<br>4.  In the workload/Pod column, click on a pod for a backup<br>5.  Verify a window pops up with the pod details | Pod details should be available |
| 4   | Labels | 1.  Navigate to Backup page<br>2.  Click on a volume v1<br>3.  User will be navigate to Backup/v1 page<br>4.  For a backup click on the labels icon<br>5.  Verify labels should be present for the backup | 1.  Related labels should be available for the backup |

CSI Snapshot Support Test cases
----------------------
The setup requirements:

1.  Deploy the snapshotter crds [https://github.com/kubernetes-csi/external-snapshotter/tree/release-4.0/client/config/crd](https://github.com/kubernetes-csi/external-snapshotter/tree/release-4.0/client/config/crd)
2.  Deploy the snapshot controller [https://github.com/kubernetes-csi/external-snapshotter/tree/release-4.0/deploy/kubernetes/snapshot-controller](https://github.com/kubernetes-csi/external-snapshotter/tree/release-4.0/deploy/kubernetes/snapshot-controller)
3.  Deploy the volumeSnapshotClass.<br><pre>kind: VolumeSnapshotClass<br>apiVersion:<br> snapshot.storage.k8s.io/v1beta1<br>metadata:<br>  name: longhorn<br>driver: driver.longhorn.io<br>deletionPolicy: Delete

|**#**| **Test Scenario** | **Test Steps** | **Expected Results** |
| --- | --- | --- | --- |
| 1   | Create a snapshot using `VolumeSnapshot` | 1.  Create a volume test-vol and write into it.<br>    1.  Compute the md5sum<br>        <br>2.  Create the below `VolumeSnapshot` object<br> <pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshot<br>metadata:<br>  name: test<br>vol-snapshot<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  source:<br>    persistentVolumeClaimName: test-vol</pre>| 1.  A longhorn snapshot should be created.<br>2.  A backup of that snapshot should be available on the backup store.<br>3.  A `volumesnapshotContent` should also get created referring to `test-snapshot-pvc` |
| 2   | Restore a backup from a snapshot | 1.  Create a volume and take backup following the steps from test scenario 1.<br>2.  Create a `PVC` where datasource is referring to the `VolumeSnapshot`<br><pre>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: test-vol-restore<br>spec:<br>  storageClassName: longhorn<br>  dataSource:<br>    name: test-vol-snapshot<br>    kind: VolumeSnapshot<br>    apiGroup: snapshot.storage.k8s.io<br>  accessModes:<br>    - ReadWriteOnce<br>  resources:<br>    requests:<br>      storage: 2Gi</pre>3.  Attach the `PVC` to a pod.<br>4.  Verify the data | 1.  The PVC should be created successfully.<br>2.  A volume should be created bound to the PVC created.<br>3.  The data should be the same as created in test scenario 1 |
| 3   | Restore a backup from longhorn. | 1.  Create a volume and attach it to a pod.  <br>    Compute the md5sum of the data.<br>2.  Take a backup in the longhorn.<br>3.  Create the below `VolumeSnapshotterContent` <br> Change the snapshotHandle to point to the backup to restore<br><pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshotContent<br>metadata:<br>  name: test-existing-backup<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  driver: driver.longhorn.io<br>  deletionPolicy: Delete<br>  source:<br>    # NOTE: change this to point to an existing backup on the backupstore<br>    snapshotHandle: bs://test-vol<br>backup-625159fb469e492e<br>  volumeSnapshotRef:<br>    name: test-snapshot-existing-backup<br>    namespace: default</pre>4.  Create the below `VolumeSnapshot` referring to the above `VolumeSnapshotContent`<br><pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshot<br>metadata:<br>  name: test-snapshot-existing-backup<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  source:<br>    volumeSnapshotContentName: test-existing-backup</pre>5.  Create the below `PVC` referring to the above `VolumeSnapshot`<br><pre>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: test-restore-existing-backup<br>spec:<br>  storageClassName: longhorn<br>  dataSource:<br>    name: test-snapshot-existing-backup<br>    kind: VolumeSnapshot<br>    apiGroup: snapshot.storage.k8s.io<br>  accessModes:<br>    - ReadWriteOnce<br>  resources:<br>    requests:<br>      storage: 2Gi</pre>6.  Attach to a pod, verify the data.  <br>    Compute md5sum of the data. | 1.  The `VolumeSnapshotterContent` should reflect the size of the backup volume.<br>2.  The data should be intact, compare the md5sum of step 1 and step 6. |
| 4   | Delete the backup with `DeletionPolicy` as delete | 1.  Repeat the steps from test scenario 1.<br>2.  Delete the `VolumeSnapshot` using `kubectl delete volumesnapshots test-snapshot-pvc` | 1.  The `VolumeSnapshot` should be deleted.<br>2.  By default the `DeletionPolicy` is delete, so the `VolumeSnapshotContent` should be deleted.<br>3.  Verify in the backup store, the backup should be deleted. |
| 5   | Delete the backup with `DeletionPolicy` as retain | 1.  Create a `VolumeSnapshotClass` class with `deletionPolicy` as Retain<br><pre>kind: VolumeSnapshotClass<br>apiVersion: snapshot.storage.k8s.io/v1beta1<br>metadata:<br>  name: longhorn<br>driver: driver.longhorn.io<br>deletionPolicy: Retain</pre>2.  Repeat the steps from test scenario 1.<br>3.  Delete the `VolumeSnapshot` using `kubectl delete volumesnapshots test-snapshot-pvc` | 1.  The `VolumeSnapshot` should be deleted.<br>2.  `VolumeSnapshotContent` should NOT be deleted.<br>3.  Verify in the backup store, the backup should NOT be deleted. |
| 6   | Take a backup from longhorn of a snapshot created by csi snapshotter. | 1.  Create a volume test-vol and write into it.<br>    1.  Compute the md5sum<br>        <br>2.  Create the below `VolumeSnapshot` object<br><pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshot<br>metadata:<br>  name: test-snapshot-pvc<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  source:<br>    persistentVolumeClaimName: test-vol</pre>3.  Go to longhorn UI and click on the snapshot created and take another backup | 1.  On creating a `VolumeSnapshot`, a backup should be created in the backup store.<br>2.  On creating another backup from longhorn UI, one more backup should be created in backup store. |
| 7   | Delete the `csi plugin` while a backup is in progress. | 1.  Create a volume and write into it.  <br>    Compute the md5sum of the data.<br>2.  Create the below `VolumeSnapshot` object<br><pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshot<br>metadata:<br> <br>name: test-snapshot-pvc<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  source:<br>    persistentVolumeClaimName: test-vol</pre>3.  While the backup is in progress, delete the `csi plugin` | On deleting `csi plugin` , a new pod of `csi plugin` should get created and the backup should continue to complete. |
| 8   | Take a backup using csi snapshotter with backup store as NFS server. |     |     |
| 9   | Restore from NFS backup store. |     |     |
| 10  | Delete from NFS backup store. |     |     |
| 11  | Parallel backups using csi snapshotter | 1.  Create a volume and write into it.  <br>    Compute the md5sum of the data.<br>2.  Create two `VolumeSnapshot` object with different names<br><pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshot<br>metadata:<br>  name: test-snapshot-pvc<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  source:<br>    persistentVolumeClaimName: test-vol</pre>3.  `kubectl apply -f volumeSnapshot` together.<br>4.  Verify two parallel backups creation is triggered. | 1.  Parallel backup creation should start<br>2.  Data should be intact.<br>3.  Verify after restoring the data |
| 12  | Parallel deletion using csi snapshotter | 1.  Create multiple backups using csi snapshotter with `Deletionpolicy`is `Delete`<br>2.  Delete two or more `volumeSnapshot` at once<br>3.  Verify the backup store | 1.  All the backup pertaining to deleted `volumesnapshot` should get deleted. |
| 13  | Take backup and delete the `VolumeSnapshot` when the backup is in progress. | 1.  Create a `volumesnapshot`<br>2.  Delete the same `volumesnapshot` when it is progress<br>3.  Take another `volumesnapshot`<br>4.  Let it get completed and verify the data. | 1.  The backup doesn’t get created after the step 2<br>2.  The backup data should be intact. |
| 14  | Backup on a backup store with `VIRTUAL_HOSTED_STYLE` |     |     |
| 15  | Backup with invalid Backupstore | 1.  Give invalid backupstore details in the setting of longhorn.<br>2.  Create a volume, write into it.<br>3.  Create a `volumesnapshot`<br>4.  Verify the longhorn UI | 1.  No backup should get triggered.<br>2.  No snapshot should appear on the longhorn UI. |
| 16  | Restore from longhorn backup volume where there are multiple backups | 1.  Create a volume and attach it to a pod.  <br>    Compute the md5sum of the data.<br>2.  Take a backup in the longhorn.<br>3.  Write more in the volume and take backup.<br>4.  Create the `VolumeSnapshotterContent`, the snapshotHandle should point to the 2nd backup to restore.<br>5.  Create the referring `volumesnapshot`<br>6.  Verify the data |     |
| 17  | Restore with invalid backup name | 1.  Create a volume and attach it to a pod.  <br>    Compute the md5sum of the data.<br>2.  Create the `VolumeSnapshotterContent`, the snapshotHandle should point to an invalid backup to restore.<br>3.  Create the referring `volumesnapshot`<br>4.  Create the PVC and attach to a pod. | 1.  The `volumesnapshot and volumesnapshotcontent` should show False status in `ReadytoUse`.<br>2.  Pvc should fail to attach to pod, it should not create the volume in longhorn. |
| 18  | Create a DR volume with the backup created using CSI snapshotter. | 1.  Give valid backupstore details in the setting of longhorn.<br>2.  Create a volume, write into it.<br>3.  Create a `volumesnapshot`<br>4.  Create a DR volume of the backup which got created in step3.<br>5.  Write more data into it.<br>6.  Take backup using `volumesnaphot`<br>7.  Activate the DR volume | The DR volume should have the latest data updated. |
| 19  | Same #uid from a prior snapshot -  <br>with longhorn snapshot still present, but the backup deleted. | 1.  Create a volume, write into it. Compute the md5sum.<br>2.  Create a `volumesnapshot` like below<br><pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshot<br>metadata:<br>  name: test-snapshot-existing-backup<br>  uid: # copy uid from a prior snapshot, that you created, since the uid is how the longhorn snapshot will be named.<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  source:<br>    persistentVolumeClaimName: test-vol</pre>3.  After the backup is completed, delete the snapshot from longhorn UI.<br>4.  Create a `volumesnapshot` | 1.  A new snapshot gets created overriding the uid given in the metadata.<br>2.  A new backup gets created. |
| 20  | Same #uid from a prior snapshot -  <br>with backup still present but longhorn snapshot deleted | 1.  Create a volume, write into it. Compute the md5sum.<br>2.  Create a `volumesnapshot` like below<br><pre>apiVersion: snapshot.storage.k8s.io/v1beta1<br>kind: VolumeSnapshot<br>metadata:<br>  name: test-snapshot-existing-backup<br>  uid: # copy uid from a prior snapshot, that you created, since the uid is how the longhorn snapshot will be named.<br>spec:<br>  volumeSnapshotClassName: longhorn<br>  source:<br>    persistentVolumeClaimName: test-vol</pre>3.  After the backup is completed, delete the backup from backup store.<br>4.  Create a `volumesnapshot` | 1.  A new snapshot gets created overriding the uid given in the metadata.<br>2.  A new backup gets created. |
