<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>tests.test_tagging API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tests.test_tagging</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pytest
import random
import string

from common import client, node_default_tags, volume_name # NOQA
from common import RETRY_COUNTS, RETRY_INTERVAL, SIZE
from common import check_volume_replicas, cleanup_volume, \
    generate_volume_name, get_self_host_id, get_update_disks, set_node_tags, \
    wait_for_volume_delete, wait_for_volume_detached, \
    wait_for_volume_healthy, wait_scheduling_failure
from time import sleep


def generate_tag_name():
    return &#34;tag/&#34; + &#34;&#34;.join(random.choice(string.ascii_lowercase +
                                          string.digits) for _ in range(6))


def generate_unordered_tag_names():
    unsorted = []
    is_sorted = []
    while unsorted == is_sorted:
        unsorted = []
        for _ in range(3):
            unsorted.append(generate_tag_name())
        is_sorted = sorted(unsorted)
    return unsorted, is_sorted


def test_tag_basic(client):  # NOQA
    &#34;&#34;&#34;
    Test that applying Tags to Nodes/Disks and retrieving them work as
    expected. Ensures that Tags are properly validated when updated.

    1. Generate tags and apply to the disk and nodes
    2. Make sure the tags are applied
    3. Try to apply invalid tags to the disk and node. Action will fail.
    &#34;&#34;&#34;
    host_id = get_self_host_id()
    node = client.by_id_node(host_id)
    disks = get_update_disks(node.disks)
    assert len(node.disks) == 1
    assert node.disks[list(node.disks)[0]].tags is None
    assert node.tags is None

    unsorted_disk, sorted_disk = generate_unordered_tag_names()
    unsorted_node, sorted_node = generate_unordered_tag_names()
    update_disks = get_update_disks(node.disks)
    update_disks[list(update_disks)[0]].tags = unsorted_disk
    node = node.diskUpdate(disks=update_disks)
    disks = get_update_disks(node.disks)
    assert disks[list(disks)[0]].tags == sorted_disk

    node = set_node_tags(client, node, unsorted_node)
    assert node.tags == sorted_node

    improper_tag_cases = [
        [&#34;&#34;],   # Empty string
        [&#34; &#34;],  # Whitespace
        [&#34;/&#34;],  # Leading /
        [&#34;,&#34;],  # Illegal character
    ]
    for tags in improper_tag_cases:
        with pytest.raises(Exception) as e:
            set_node_tags(client, node, tags)
        assert &#34;at least one error encountered while validating tags&#34; in \
               str(e.value)
        with pytest.raises(Exception) as e:
            update_disks = get_update_disks(node.disks)
            update_disks[list(update_disks)[0]].tags = tags
            node.diskUpdate(disks=update_disks)
        assert &#34;at least one error encountered while validating tags&#34; in \
               str(e.value)

    update_disks = get_update_disks(node.disks)
    update_disks[list(update_disks)[0]].tags = []
    node = node.diskUpdate(disks=update_disks)
    disks = get_update_disks(node.disks)
    assert node.disks[list(node.disks)[0]].tags is None

    node = set_node_tags(client, node)
    assert node.tags is None


def test_tag_scheduling(client, node_default_tags):  # NOQA
    &#34;&#34;&#34;
    Test success scheduling with tags

    Case 1:
    Don&#39;t specify any tags, replica should be scheduled to 3 disks.

    Case 2:
    Use disk tags to select two nodes for all replicas.

    Case 3:
    Use node tags to select two nodes for all replicas.

    Case 4:
    Combine node and disk tags to schedule all replicas on one node.
    &#34;&#34;&#34;
    host_id = get_self_host_id()
    tag_specs = [
        # Select all Nodes.
        {
            &#34;disk&#34;: [],
            &#34;expected&#34;: 3,
            &#34;node&#34;: []
        },
        # Selector works with AND on Disk Tags.
        {
            &#34;disk&#34;: [&#34;ssd&#34;, &#34;nvme&#34;],
            &#34;expected&#34;: 2,
            &#34;node&#34;: []
        },
        # Selector works with AND on Node Tags.
        {
            &#34;disk&#34;: [],
            &#34;expected&#34;: 2,
            &#34;node&#34;: [&#34;main&#34;, &#34;storage&#34;]
        },
        # Selector works based on combined Disk AND Node selector.
        {
            &#34;disk&#34;: [&#34;ssd&#34;, &#34;nvme&#34;],
            &#34;expected&#34;: 1,
            &#34;node&#34;: [&#34;storage&#34;, &#34;main&#34;]
        }
    ]
    for specs in tag_specs:
        volume_name = generate_volume_name()  # NOQA
        client.create_volume(name=volume_name, size=SIZE, numberOfReplicas=3,
                             diskSelector=specs[&#34;disk&#34;],
                             nodeSelector=specs[&#34;node&#34;])
        volume = wait_for_volume_detached(client, volume_name)
        assert volume.diskSelector == specs[&#34;disk&#34;]
        assert volume.nodeSelector == specs[&#34;node&#34;]

        volume.attach(hostId=host_id)
        volume = wait_for_volume_healthy(client, volume_name)
        assert len(volume.replicas) == 3
        check_volume_replicas(volume, specs, node_default_tags)

        cleanup_volume(client, volume)


def test_tag_scheduling_failure(client, node_default_tags):  # NOQA
    &#34;&#34;&#34;
    Test that scheduling fails if no Nodes/Disks with the requested Tags are
    available.

    Case 1:
    Validate that if specifying nonexist tags in volume, API call will fail.

    Case 2:

    1. Specify existing but no node or disk can unsatisfied tags.
    2. Validate the volume will failed the scheduling
    &#34;&#34;&#34;
    invalid_tag_cases = [
        # Only one Disk Tag exists.
        {
            &#34;disk&#34;: [&#34;doesnotexist&#34;, &#34;ssd&#34;],
            &#34;node&#34;: []
        },
        # Only one Node Tag exists.
        {
            &#34;disk&#34;: [],
            &#34;node&#34;: [&#34;doesnotexist&#34;, &#34;main&#34;]
        }
    ]
    for tags in invalid_tag_cases:
        volume_name = generate_volume_name()  # NOQA
        with pytest.raises(Exception) as e:
            client.create_volume(name=volume_name, size=SIZE,
                                 numberOfReplicas=3,
                                 diskSelector=tags[&#34;disk&#34;],
                                 nodeSelector=tags[&#34;node&#34;])
        assert &#34;does not exist&#34; in str(e.value)

    unsatisfied_tag_cases = [
        {
            &#34;disk&#34;: [],
            &#34;node&#34;: [&#34;main&#34;, &#34;fallback&#34;]
        },
        {
            &#34;disk&#34;: [&#34;ssd&#34;, &#34;m2&#34;],
            &#34;node&#34;: []
        }
    ]
    for tags in unsatisfied_tag_cases:
        volume_name = generate_volume_name()
        client.create_volume(name=volume_name, size=SIZE, numberOfReplicas=3,
                             diskSelector=tags[&#34;disk&#34;],
                             nodeSelector=tags[&#34;node&#34;])
        volume = wait_for_volume_detached(client, volume_name)
        assert volume.diskSelector == tags[&#34;disk&#34;]
        assert volume.nodeSelector == tags[&#34;node&#34;]
        wait_scheduling_failure(client, volume_name)

        client.delete(volume)
        wait_for_volume_delete(client, volume.name)
        volumes = client.list_volume()
        assert len(volumes) == 0


def test_tag_scheduling_on_update(client, node_default_tags, volume_name):  # NOQA
    &#34;&#34;&#34;
    Test that Replicas get scheduled if a Node/Disk disks updated with the
    proper Tags.

    1. Create volume with tags that can not be satisfied
    2. Wait for volume to fail scheduling
    3. Update the node and disk with extra tags to satisify the volume
    4. Verify now volume has been scheduled
    5. Attach the volume and check the replicas has been scheduled properly
    &#34;&#34;&#34;
    tag_spec = {
        &#34;disk&#34;: [&#34;ssd&#34;, &#34;m2&#34;],
        &#34;expected&#34;: 1,
        &#34;node&#34;: [&#34;main&#34;, &#34;fallback&#34;]
    }
    client.create_volume(name=volume_name, size=SIZE, numberOfReplicas=3,
                         diskSelector=tag_spec[&#34;disk&#34;],
                         nodeSelector=tag_spec[&#34;node&#34;])
    volume = wait_for_volume_detached(client, volume_name)
    assert volume.diskSelector == tag_spec[&#34;disk&#34;]
    assert volume.nodeSelector == tag_spec[&#34;node&#34;]

    wait_scheduling_failure(client, volume_name)

    host_id = get_self_host_id()
    node = client.by_id_node(host_id)
    update_disks = get_update_disks(node.disks)
    update_disks[list(update_disks)[0]].tags = tag_spec[&#34;disk&#34;]
    node = node.diskUpdate(disks=update_disks)
    set_node_tags(client, node, tag_spec[&#34;node&#34;])
    scheduled = False
    for i in range(RETRY_COUNTS):
        v = client.by_id_volume(volume_name)
        if v.conditions.scheduled.status == &#34;True&#34;:
            scheduled = True
        if scheduled:
            break
        sleep(RETRY_INTERVAL)
    assert scheduled

    volume.attach(hostId=host_id)
    volume = wait_for_volume_healthy(client, volume_name)
    nodes = client.list_node()
    node_mapping = {node.id: {
        &#34;disk&#34;: node.disks[list(node.disks)[0]].tags,
        &#34;node&#34;: node.tags
    } for node in nodes}
    assert len(volume.replicas) == 3
    check_volume_replicas(volume, tag_spec, node_mapping)

    cleanup_volume(client, volume)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tests.test_tagging.generate_tag_name"><code class="name flex">
<span>def <span class="ident">generate_tag_name</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_tag_name():
    return &#34;tag/&#34; + &#34;&#34;.join(random.choice(string.ascii_lowercase +
                                          string.digits) for _ in range(6))</code></pre>
</details>
</dd>
<dt id="tests.test_tagging.generate_unordered_tag_names"><code class="name flex">
<span>def <span class="ident">generate_unordered_tag_names</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_unordered_tag_names():
    unsorted = []
    is_sorted = []
    while unsorted == is_sorted:
        unsorted = []
        for _ in range(3):
            unsorted.append(generate_tag_name())
        is_sorted = sorted(unsorted)
    return unsorted, is_sorted</code></pre>
</details>
</dd>
<dt id="tests.test_tagging.test_tag_basic"><code class="name flex">
<span>def <span class="ident">test_tag_basic</span></span>(<span>client)</span>
</code></dt>
<dd>
<section class="desc"><p>Test that applying Tags to Nodes/Disks and retrieving them work as
expected. Ensures that Tags are properly validated when updated.</p>
<ol>
<li>Generate tags and apply to the disk and nodes</li>
<li>Make sure the tags are applied</li>
<li>Try to apply invalid tags to the disk and node. Action will fail.</li>
</ol></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_tag_basic(client):  # NOQA
    &#34;&#34;&#34;
    Test that applying Tags to Nodes/Disks and retrieving them work as
    expected. Ensures that Tags are properly validated when updated.

    1. Generate tags and apply to the disk and nodes
    2. Make sure the tags are applied
    3. Try to apply invalid tags to the disk and node. Action will fail.
    &#34;&#34;&#34;
    host_id = get_self_host_id()
    node = client.by_id_node(host_id)
    disks = get_update_disks(node.disks)
    assert len(node.disks) == 1
    assert node.disks[list(node.disks)[0]].tags is None
    assert node.tags is None

    unsorted_disk, sorted_disk = generate_unordered_tag_names()
    unsorted_node, sorted_node = generate_unordered_tag_names()
    update_disks = get_update_disks(node.disks)
    update_disks[list(update_disks)[0]].tags = unsorted_disk
    node = node.diskUpdate(disks=update_disks)
    disks = get_update_disks(node.disks)
    assert disks[list(disks)[0]].tags == sorted_disk

    node = set_node_tags(client, node, unsorted_node)
    assert node.tags == sorted_node

    improper_tag_cases = [
        [&#34;&#34;],   # Empty string
        [&#34; &#34;],  # Whitespace
        [&#34;/&#34;],  # Leading /
        [&#34;,&#34;],  # Illegal character
    ]
    for tags in improper_tag_cases:
        with pytest.raises(Exception) as e:
            set_node_tags(client, node, tags)
        assert &#34;at least one error encountered while validating tags&#34; in \
               str(e.value)
        with pytest.raises(Exception) as e:
            update_disks = get_update_disks(node.disks)
            update_disks[list(update_disks)[0]].tags = tags
            node.diskUpdate(disks=update_disks)
        assert &#34;at least one error encountered while validating tags&#34; in \
               str(e.value)

    update_disks = get_update_disks(node.disks)
    update_disks[list(update_disks)[0]].tags = []
    node = node.diskUpdate(disks=update_disks)
    disks = get_update_disks(node.disks)
    assert node.disks[list(node.disks)[0]].tags is None

    node = set_node_tags(client, node)
    assert node.tags is None</code></pre>
</details>
</dd>
<dt id="tests.test_tagging.test_tag_scheduling"><code class="name flex">
<span>def <span class="ident">test_tag_scheduling</span></span>(<span>client, node_default_tags)</span>
</code></dt>
<dd>
<section class="desc"><p>Test success scheduling with tags</p>
<p>Case 1:
Don't specify any tags, replica should be scheduled to 3 disks.</p>
<p>Case 2:
Use disk tags to select two nodes for all replicas.</p>
<p>Case 3:
Use node tags to select two nodes for all replicas.</p>
<p>Case 4:
Combine node and disk tags to schedule all replicas on one node.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_tag_scheduling(client, node_default_tags):  # NOQA
    &#34;&#34;&#34;
    Test success scheduling with tags

    Case 1:
    Don&#39;t specify any tags, replica should be scheduled to 3 disks.

    Case 2:
    Use disk tags to select two nodes for all replicas.

    Case 3:
    Use node tags to select two nodes for all replicas.

    Case 4:
    Combine node and disk tags to schedule all replicas on one node.
    &#34;&#34;&#34;
    host_id = get_self_host_id()
    tag_specs = [
        # Select all Nodes.
        {
            &#34;disk&#34;: [],
            &#34;expected&#34;: 3,
            &#34;node&#34;: []
        },
        # Selector works with AND on Disk Tags.
        {
            &#34;disk&#34;: [&#34;ssd&#34;, &#34;nvme&#34;],
            &#34;expected&#34;: 2,
            &#34;node&#34;: []
        },
        # Selector works with AND on Node Tags.
        {
            &#34;disk&#34;: [],
            &#34;expected&#34;: 2,
            &#34;node&#34;: [&#34;main&#34;, &#34;storage&#34;]
        },
        # Selector works based on combined Disk AND Node selector.
        {
            &#34;disk&#34;: [&#34;ssd&#34;, &#34;nvme&#34;],
            &#34;expected&#34;: 1,
            &#34;node&#34;: [&#34;storage&#34;, &#34;main&#34;]
        }
    ]
    for specs in tag_specs:
        volume_name = generate_volume_name()  # NOQA
        client.create_volume(name=volume_name, size=SIZE, numberOfReplicas=3,
                             diskSelector=specs[&#34;disk&#34;],
                             nodeSelector=specs[&#34;node&#34;])
        volume = wait_for_volume_detached(client, volume_name)
        assert volume.diskSelector == specs[&#34;disk&#34;]
        assert volume.nodeSelector == specs[&#34;node&#34;]

        volume.attach(hostId=host_id)
        volume = wait_for_volume_healthy(client, volume_name)
        assert len(volume.replicas) == 3
        check_volume_replicas(volume, specs, node_default_tags)

        cleanup_volume(client, volume)</code></pre>
</details>
</dd>
<dt id="tests.test_tagging.test_tag_scheduling_failure"><code class="name flex">
<span>def <span class="ident">test_tag_scheduling_failure</span></span>(<span>client, node_default_tags)</span>
</code></dt>
<dd>
<section class="desc"><p>Test that scheduling fails if no Nodes/Disks with the requested Tags are
available.</p>
<p>Case 1:
Validate that if specifying nonexist tags in volume, API call will fail.</p>
<p>Case 2:</p>
<ol>
<li>Specify existing but no node or disk can unsatisfied tags.</li>
<li>Validate the volume will failed the scheduling</li>
</ol></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_tag_scheduling_failure(client, node_default_tags):  # NOQA
    &#34;&#34;&#34;
    Test that scheduling fails if no Nodes/Disks with the requested Tags are
    available.

    Case 1:
    Validate that if specifying nonexist tags in volume, API call will fail.

    Case 2:

    1. Specify existing but no node or disk can unsatisfied tags.
    2. Validate the volume will failed the scheduling
    &#34;&#34;&#34;
    invalid_tag_cases = [
        # Only one Disk Tag exists.
        {
            &#34;disk&#34;: [&#34;doesnotexist&#34;, &#34;ssd&#34;],
            &#34;node&#34;: []
        },
        # Only one Node Tag exists.
        {
            &#34;disk&#34;: [],
            &#34;node&#34;: [&#34;doesnotexist&#34;, &#34;main&#34;]
        }
    ]
    for tags in invalid_tag_cases:
        volume_name = generate_volume_name()  # NOQA
        with pytest.raises(Exception) as e:
            client.create_volume(name=volume_name, size=SIZE,
                                 numberOfReplicas=3,
                                 diskSelector=tags[&#34;disk&#34;],
                                 nodeSelector=tags[&#34;node&#34;])
        assert &#34;does not exist&#34; in str(e.value)

    unsatisfied_tag_cases = [
        {
            &#34;disk&#34;: [],
            &#34;node&#34;: [&#34;main&#34;, &#34;fallback&#34;]
        },
        {
            &#34;disk&#34;: [&#34;ssd&#34;, &#34;m2&#34;],
            &#34;node&#34;: []
        }
    ]
    for tags in unsatisfied_tag_cases:
        volume_name = generate_volume_name()
        client.create_volume(name=volume_name, size=SIZE, numberOfReplicas=3,
                             diskSelector=tags[&#34;disk&#34;],
                             nodeSelector=tags[&#34;node&#34;])
        volume = wait_for_volume_detached(client, volume_name)
        assert volume.diskSelector == tags[&#34;disk&#34;]
        assert volume.nodeSelector == tags[&#34;node&#34;]
        wait_scheduling_failure(client, volume_name)

        client.delete(volume)
        wait_for_volume_delete(client, volume.name)
        volumes = client.list_volume()
        assert len(volumes) == 0</code></pre>
</details>
</dd>
<dt id="tests.test_tagging.test_tag_scheduling_on_update"><code class="name flex">
<span>def <span class="ident">test_tag_scheduling_on_update</span></span>(<span>client, node_default_tags, volume_name)</span>
</code></dt>
<dd>
<section class="desc"><p>Test that Replicas get scheduled if a Node/Disk disks updated with the
proper Tags.</p>
<ol>
<li>Create volume with tags that can not be satisfied</li>
<li>Wait for volume to fail scheduling</li>
<li>Update the node and disk with extra tags to satisify the volume</li>
<li>Verify now volume has been scheduled</li>
<li>Attach the volume and check the replicas has been scheduled properly</li>
</ol></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_tag_scheduling_on_update(client, node_default_tags, volume_name):  # NOQA
    &#34;&#34;&#34;
    Test that Replicas get scheduled if a Node/Disk disks updated with the
    proper Tags.

    1. Create volume with tags that can not be satisfied
    2. Wait for volume to fail scheduling
    3. Update the node and disk with extra tags to satisify the volume
    4. Verify now volume has been scheduled
    5. Attach the volume and check the replicas has been scheduled properly
    &#34;&#34;&#34;
    tag_spec = {
        &#34;disk&#34;: [&#34;ssd&#34;, &#34;m2&#34;],
        &#34;expected&#34;: 1,
        &#34;node&#34;: [&#34;main&#34;, &#34;fallback&#34;]
    }
    client.create_volume(name=volume_name, size=SIZE, numberOfReplicas=3,
                         diskSelector=tag_spec[&#34;disk&#34;],
                         nodeSelector=tag_spec[&#34;node&#34;])
    volume = wait_for_volume_detached(client, volume_name)
    assert volume.diskSelector == tag_spec[&#34;disk&#34;]
    assert volume.nodeSelector == tag_spec[&#34;node&#34;]

    wait_scheduling_failure(client, volume_name)

    host_id = get_self_host_id()
    node = client.by_id_node(host_id)
    update_disks = get_update_disks(node.disks)
    update_disks[list(update_disks)[0]].tags = tag_spec[&#34;disk&#34;]
    node = node.diskUpdate(disks=update_disks)
    set_node_tags(client, node, tag_spec[&#34;node&#34;])
    scheduled = False
    for i in range(RETRY_COUNTS):
        v = client.by_id_volume(volume_name)
        if v.conditions.scheduled.status == &#34;True&#34;:
            scheduled = True
        if scheduled:
            break
        sleep(RETRY_INTERVAL)
    assert scheduled

    volume.attach(hostId=host_id)
    volume = wait_for_volume_healthy(client, volume_name)
    nodes = client.list_node()
    node_mapping = {node.id: {
        &#34;disk&#34;: node.disks[list(node.disks)[0]].tags,
        &#34;node&#34;: node.tags
    } for node in nodes}
    assert len(volume.replicas) == 3
    check_volume_replicas(volume, tag_spec, node_mapping)

    cleanup_volume(client, volume)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tests" href="index.html">tests</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tests.test_tagging.generate_tag_name" href="#tests.test_tagging.generate_tag_name">generate_tag_name</a></code></li>
<li><code><a title="tests.test_tagging.generate_unordered_tag_names" href="#tests.test_tagging.generate_unordered_tag_names">generate_unordered_tag_names</a></code></li>
<li><code><a title="tests.test_tagging.test_tag_basic" href="#tests.test_tagging.test_tag_basic">test_tag_basic</a></code></li>
<li><code><a title="tests.test_tagging.test_tag_scheduling" href="#tests.test_tagging.test_tag_scheduling">test_tag_scheduling</a></code></li>
<li><code><a title="tests.test_tagging.test_tag_scheduling_failure" href="#tests.test_tagging.test_tag_scheduling_failure">test_tag_scheduling_failure</a></code></li>
<li><code><a title="tests.test_tagging.test_tag_scheduling_on_update" href="#tests.test_tagging.test_tag_scheduling_on_update">test_tag_scheduling_on_update</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>