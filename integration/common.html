<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>tests.common API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tests.common</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tests.common.activate_standby_volume"><code class="name flex">
<span>def <span class="ident">activate_standby_volume</span></span>(<span>client, volume_name, frontend='blockdev')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def activate_standby_volume(client, volume_name,
                            frontend=VOLUME_FRONTEND_BLOCKDEV):
    volume = client.by_id_volume(volume_name)
    assert volume.standby is True
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(volume_name)
        engines = volume.controllers
        if len(engines) != 1 or \
                (volume.lastBackup != &#34;&#34; and
                 engines[0].lastRestoredBackup != volume.lastBackup):
            time.sleep(RETRY_INTERVAL)
            continue
        activated = False
        try:
            volume.activate(frontend=frontend)
            activated = True
            break
        except Exception as e:
            assert &#34;hasn&#39;t finished incremental restored&#34; \
                   in str(e.error.message)
            time.sleep(RETRY_INTERVAL)
        if activated:
            break
    volume = client.by_id_volume(volume_name)
    assert volume.standby is False
    assert volume.frontend == VOLUME_FRONTEND_BLOCKDEV

    wait_for_volume_detached(client, volume_name)

    volume = client.by_id_volume(volume_name)
    engine = get_volume_engine(volume)
    assert engine.lastRestoredBackup == &#34;&#34;
    assert engine.requestedBackupRestore == &#34;&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.apps_api"><code class="name flex">
<span>def <span class="ident">apps_api</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def apps_api(request):
    &#34;&#34;&#34;
    Create a new AppsV1API instance.
    Returns:
        A new AppsV1API Instance.
    &#34;&#34;&#34;
    c = Configuration()
    c.assert_hostname = False
    Configuration.set_default(c)
    k8sconfig.load_incluster_config()
    apps_api = k8sclient.AppsV1Api()

    return apps_api</code></pre>
</details>
<div class="desc"><p>Create a new AppsV1API instance.</p>
<h2 id="returns">Returns</h2>
<p>A new AppsV1API Instance.</p></div>
</dd>
<dt id="tests.common.assert_backup_state"><code class="name flex">
<span>def <span class="ident">assert_backup_state</span></span>(<span>b_actual, b_expected)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assert_backup_state(b_actual, b_expected):
    assert b_expected.name == b_actual.name
    assert b_expected.url == b_actual.url
    assert b_expected.snapshotName == b_actual.snapshotName
    assert b_expected.snapshotCreated == b_actual.snapshotCreated
    assert b_expected.created == b_actual.created
    assert b_expected.volumeName == b_actual.volumeName
    assert b_expected.volumeSize == b_actual.volumeSize
    assert b_expected.volumeCreated == b_actual.volumeCreated
    assert b_expected.messages == b_actual.messages is None</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.assert_from_assert_error_check_threads"><code class="name flex">
<span>def <span class="ident">assert_from_assert_error_check_threads</span></span>(<span>thrd_list)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assert_from_assert_error_check_threads(thrd_list):
    &#34;&#34;&#34;
        Check all threads in thrd_list are done and their status

        Parameters:
            thrd_list: thread list created by create_assert_error_check_thread.
    &#34;&#34;&#34;
    assert isinstance(thrd_list, list), &#34;thrd_list is not a list&#34;

    err_list = []
    for t in thrd_list:
        try:
            t.join()
        except AssertionError as e:
            print(e)
            err_list.append(e)
    if err_list:
        assert False, err_list</code></pre>
</details>
<div class="desc"><p>Check all threads in thrd_list are done and their status</p>
<h2 id="parameters">Parameters</h2>
<p>thrd_list: thread list created by create_assert_error_check_thread.</p></div>
</dd>
<dt id="tests.common.backing_image_feature_supported"><code class="name flex">
<span>def <span class="ident">backing_image_feature_supported</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def backing_image_feature_supported(client):
    if hasattr(client.by_id_schema(&#34;backingImage&#34;), &#34;id&#34;):
        return True
    else:
        return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.batch_v1_api"><code class="name flex">
<span>def <span class="ident">batch_v1_api</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def batch_v1_api(request):
    &#34;&#34;&#34;
    Create a new BatchV1Api instance.
    Returns:
        A new BatchV1Api Instance.
    &#34;&#34;&#34;
    c = Configuration()
    c.assert_hostname = False
    Configuration.set_default(c)
    k8sconfig.load_incluster_config()
    api = k8sclient.BatchV1Api()

    return api</code></pre>
</details>
<div class="desc"><p>Create a new BatchV1Api instance.</p>
<h2 id="returns">Returns</h2>
<p>A new BatchV1Api Instance.</p></div>
</dd>
<dt id="tests.common.check_all_support_bundle_managers_deleted"><code class="name flex">
<span>def <span class="ident">check_all_support_bundle_managers_deleted</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_all_support_bundle_managers_deleted():
    apps_api = get_apps_api_client()
    deployments = get_all_support_bundle_manager_deployments(apps_api)
    for support_bundle_manager in deployments:
        wait_delete_deployment(apps_api, support_bundle_manager.metadata.name,
                               namespace=LONGHORN_NAMESPACE)

    assert len(get_all_support_bundle_manager_deployments(apps_api)) == 0</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_backing_image_disk_map_status"><code class="name flex">
<span>def <span class="ident">check_backing_image_disk_map_status</span></span>(<span>client, bi_name, expect_cnt, expect_disk_state)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_backing_image_disk_map_status(client, bi_name, expect_cnt, expect_disk_state): # NOQA
    # Number of expect_cnt should equal to number of disk map
    # that have expect_disk_state

    for i in range(RETRY_COUNTS):
        backing_image = client.by_id_backing_image(bi_name)

        count = 0
        for disk_id, status in iter(backing_image.diskFileStatusMap.items()):
            if status.state == expect_disk_state:
                count = count + 1

        if expect_cnt == count:
            break
        time.sleep(RETRY_INTERVAL)

    assert expect_cnt == count</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_backing_image_eviction_failed"><code class="name flex">
<span>def <span class="ident">check_backing_image_eviction_failed</span></span>(<span>name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_backing_image_eviction_failed(name): # NOQA
    core_client = get_core_api_client()
    selector = &#34;involvedObject.kind=BackingImage,involvedObject.name=&#34; + name
    check = False

    for i in range(RETRY_COUNTS_LONG):
        events = core_client.list_namespaced_event(
            namespace=LONGHORN_NAMESPACE,
            field_selector=selector,
        ).items
        if len(events) == 0:
            continue

        for j in range(len(events)):
            if (events[j].reason == FAILED_DELETING_REASONE and
                    BACKINGIMAGE_FAILED_EVICT_MSG in events[j].message):
                check = True
                break

        if check:
            break

        time.sleep(RETRY_INTERVAL)

    assert check</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_backing_image_single_copy_disk_eviction"><code class="name flex">
<span>def <span class="ident">check_backing_image_single_copy_disk_eviction</span></span>(<span>client, bi_name, old_disk_id)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_backing_image_single_copy_disk_eviction(client, bi_name, old_disk_id): # NOQA
    for i in range(RETRY_COUNTS):
        backing_image = client.by_id_backing_image(bi_name)
        current_disk_id = next(iter(backing_image.diskFileStatusMap))
        if current_disk_id != old_disk_id:
            break

        time.sleep(RETRY_INTERVAL)

    assert current_disk_id != old_disk_id</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_backing_image_single_copy_node_eviction"><code class="name flex">
<span>def <span class="ident">check_backing_image_single_copy_node_eviction</span></span>(<span>client, bi_name, old_node)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_backing_image_single_copy_node_eviction(client, bi_name, old_node): # NOQA
    for i in range(RETRY_COUNTS):
        backing_image = client.by_id_backing_image(bi_name)
        current_disk_id = next(iter(backing_image.diskFileStatusMap))
        current_node = get_node_by_disk_id(client, current_disk_id)
        if current_node.name != old_node.name:
            break

        time.sleep(RETRY_INTERVAL)

    assert current_node.name != old_node.name</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_block_device_size"><code class="name flex">
<span>def <span class="ident">check_block_device_size</span></span>(<span>volume, size)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_block_device_size(volume, size):
    dev = get_volume_endpoint(volume)
    # BLKGETSIZE64, result is bytes as unsigned 64-bit integer (uint64)
    req = 0x80081272
    buf = &#39; &#39; * 8
    with open(dev) as dev:
        buf = fcntl.ioctl(dev.fileno(), req, buf)
    device_size = struct.unpack(&#39;L&#39;, buf)[0]
    assert device_size == size</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_csi"><code class="name flex">
<span>def <span class="ident">check_csi</span></span>(<span>core_api)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_csi(core_api):
    using_csi = CSI_UNKNOWN

    has_attacher = False
    has_provisioner = False
    has_csi_plugin = False

    pod_running = True

    try:
        longhorn_pod_list = core_api.list_namespaced_pod(&#39;longhorn-system&#39;)
        for item in longhorn_pod_list.items:
            if item.status.phase != &#34;Running&#34;:
                pod_running = False

            labels = item.metadata.labels
            if not labels:
                pass
            elif labels.get(&#39;app&#39;, &#39;&#39;) == &#39;csi-attacher&#39;:
                has_attacher = True
            elif labels.get(&#39;app&#39;, &#39;&#39;) == &#39;csi-provisioner&#39;:
                has_provisioner = True
            elif labels.get(&#39;app&#39;, &#39;&#39;) == &#39;longhorn-csi-plugin&#39;:
                has_csi_plugin = True

        if has_attacher and has_provisioner and has_csi_plugin and pod_running:
            using_csi = CSI_TRUE
        elif not has_attacher and not has_provisioner \
                and not has_csi_plugin and not pod_running:
            using_csi = CSI_FALSE

    except ApiException as e:
        if (e.status == 404):
            using_csi = CSI_FALSE

    assert using_csi != CSI_UNKNOWN

    return True if using_csi == CSI_TRUE else False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_csi_expansion"><code class="name flex">
<span>def <span class="ident">check_csi_expansion</span></span>(<span>core_api)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_csi_expansion(core_api):
    csi_expansion_enabled = False
    has_csi_resizer = False
    pod_running = True

    try:
        longhorn_pod_list = core_api.list_namespaced_pod(&#39;longhorn-system&#39;)
        for item in longhorn_pod_list.items:
            if item.status.phase != &#34;Running&#34;:
                pod_running = False

            labels = item.metadata.labels
            if not labels:
                pass
            elif labels.get(&#39;app&#39;, &#39;&#39;) == &#39;csi-resizer&#39;:
                has_csi_resizer = True
        if has_csi_resizer and pod_running:
            csi_expansion_enabled = True

    except ApiException:
        pass

    return csi_expansion_enabled</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_device_data"><code class="name flex">
<span>def <span class="ident">check_device_data</span></span>(<span>dev, data, check_checksum=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_device_data(dev, data, check_checksum=True):
    r_data = dev_read(dev, data[&#39;pos&#39;], data[&#39;len&#39;])
    assert r_data == bytes(data[&#39;content&#39;], encoding=&#39;utf8&#39;)
    if check_checksum:
        r_checksum = get_device_checksum(dev)
        assert r_checksum == data[&#39;checksum&#39;]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_longhorn"><code class="name flex">
<span>def <span class="ident">check_longhorn</span></span>(<span>core_api)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_longhorn(core_api):
    ready = False
    has_engine_image = False
    has_driver_deployer = False
    has_manager = False
    has_ui = False
    has_instance_manager = False

    pod_running = True

    for i in range(RETRY_COUNTS):
        print(f&#34;wait for Longhorn components ready ... ({i})&#34;)
        try:
            longhorn_pod_list = core_api.list_namespaced_pod(&#39;longhorn-system&#39;)
            for item in longhorn_pod_list.items:
                labels = item.metadata.labels

                if not labels:
                    pass
                elif labels.get(&#39;longhorn.io/component&#39;, &#39;&#39;) == &#39;engine-image&#39;\
                        and item.status.phase == &#34;Running&#34;:
                    has_engine_image = True
                elif labels.get(&#39;app&#39;, &#39;&#39;) == &#39;longhorn-driver-deployer&#39; \
                        and item.status.phase == &#34;Running&#34;:
                    has_driver_deployer = True
                elif labels.get(&#39;app&#39;, &#39;&#39;) == &#39;longhorn-manager&#39; \
                        and item.status.phase == &#34;Running&#34;:
                    has_manager = True
                elif labels.get(&#39;app&#39;, &#39;&#39;) == &#39;longhorn-ui&#39; \
                        and item.status.phase == &#34;Running&#34;:
                    has_ui = True
                elif labels.get(&#39;longhorn.io/component&#39;, &#39;&#39;) == \
                        &#39;instance-manager&#39; \
                        and item.status.phase == &#34;Running&#34;:
                    has_instance_manager = True

            if has_engine_image and has_driver_deployer and has_manager and \
                    has_ui and has_instance_manager and pod_running:
                ready = True
                break
            else:
                for item in longhorn_pod_list.items:
                    print(f&#34;{item.metadata.name}    {item.status.phase}&#34;)

        except ApiException as e:
            if (e.status == 404):
                ready = False

        time.sleep(RETRY_INTERVAL)

    assert ready, &#34;Failed to wait for Longhorn components ready&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_pod_existence"><code class="name flex">
<span>def <span class="ident">check_pod_existence</span></span>(<span>api, pod_name, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_pod_existence(api, pod_name, namespace=&#34;default&#34;):
    pods = api.list_namespaced_pod(namespace)
    for pod in pods.items:
        if pod.metadata.name == pod_name and \
                not pod.metadata.deletion_timestamp:
            return True
    return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_pv_existence"><code class="name flex">
<span>def <span class="ident">check_pv_existence</span></span>(<span>api, pv_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_pv_existence(api, pv_name):
    pvs = api.list_persistent_volume()
    for pv in pvs.items:
        if pv.metadata.name == pv_name and not pv.metadata.deletion_timestamp:
            return True
    return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_pvc_existence"><code class="name flex">
<span>def <span class="ident">check_pvc_existence</span></span>(<span>api, pvc_name, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_pvc_existence(api, pvc_name, namespace=&#34;default&#34;):
    pvcs = api.list_namespaced_persistent_volume_claim(namespace)
    for pvc in pvcs.items:
        if pvc.metadata.name == pvc_name and not \
                pvc.metadata.deletion_timestamp:
            return True
    return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_pvc_in_specific_status"><code class="name flex">
<span>def <span class="ident">check_pvc_in_specific_status</span></span>(<span>api, pvc_name, status)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_pvc_in_specific_status(api, pvc_name, status):
    for i in range(RETRY_EXEC_COUNTS):
        claim = \
            api.read_namespaced_persistent_volume_claim(name=pvc_name,
                                                        namespace=&#39;default&#39;)
        if claim.status.phase == status:
            break
        time.sleep(RETRY_INTERVAL)

    assert claim.status.phase == status</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_recurring_jobs"><code class="name flex">
<span>def <span class="ident">check_recurring_jobs</span></span>(<span>client, recurring_jobs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_recurring_jobs(client, recurring_jobs):
    for name, spec in recurring_jobs.items():
        recurring_job = client.by_id_recurring_job(name)
        assert recurring_job.name == name
        assert recurring_job.task == spec[&#34;task&#34;]
        if len(spec[&#34;groups&#34;]) &gt; 0:
            assert recurring_job.groups == spec[&#34;groups&#34;]
        assert recurring_job.cron == spec[&#34;cron&#34;]

        expect_retain = spec[&#34;retain&#34;]
        if recurring_job.task == &#34;snapshot-cleanup&#34; or \
                recurring_job.task == &#34;filesystem-trim&#34;:
            expect_retain = 0
        assert recurring_job.retain == expect_retain

        assert recurring_job.concurrency == spec[&#34;concurrency&#34;]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_statefulset_existence"><code class="name flex">
<span>def <span class="ident">check_statefulset_existence</span></span>(<span>api, ss_name, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_statefulset_existence(api, ss_name, namespace=&#34;default&#34;):
    ss_list = api.list_namespaced_stateful_set(namespace)
    for ss in ss_list.items:
        if ss.metadata.name == ss_name and not ss.metadata.deletion_timestamp:
            return True
    return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_volume_data"><code class="name flex">
<span>def <span class="ident">check_volume_data</span></span>(<span>volume, data, check_checksum=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_volume_data(volume, data, check_checksum=True):
    dev = get_volume_endpoint(volume)
    check_device_data(dev, data, check_checksum)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_volume_endpoint"><code class="name flex">
<span>def <span class="ident">check_volume_endpoint</span></span>(<span>v)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_volume_endpoint(v):
    engine = get_volume_engine(v)
    endpoint = engine.endpoint
    if v.disableFrontend:
        assert endpoint == &#34;&#34;
    else:
        if v.frontend == VOLUME_FRONTEND_BLOCKDEV or \
           v.frontend == VOLUME_FRONTEND_UBLK:
            assert endpoint == os.path.join(DEV_PATH, v.name)
        elif v.frontend == VOLUME_FRONTEND_ISCSI:
            assert endpoint.startswith(&#34;iscsi://&#34;)
        elif v.frontend == VOLUME_FRONTEND_NVMF:
            assert endpoint.startswith(&#34;nvmf://&#34;)
        else:
            raise Exception(&#34;Unexpected volume frontend:&#34;, v.frontend)
    return endpoint</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_volume_existence"><code class="name flex">
<span>def <span class="ident">check_volume_existence</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_volume_existence(client, volume_name):
    volumes = client.list_volume()
    for volume in volumes:
        if volume.name == volume_name:
            return True
    return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_volume_last_backup"><code class="name flex">
<span>def <span class="ident">check_volume_last_backup</span></span>(<span>client, volume_name, last_backup)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_volume_last_backup(client, volume_name, last_backup):
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(volume_name)
        if volume.lastBackup == last_backup:
            break
        time.sleep(RETRY_INTERVAL)
    volume = client.by_id_volume(volume_name)
    assert volume.lastBackup == last_backup</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.check_volume_replicas"><code class="name flex">
<span>def <span class="ident">check_volume_replicas</span></span>(<span>volume, spec, tag_mapping)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_volume_replicas(volume, spec, tag_mapping):
    &#34;&#34;&#34;
    Check the replicas on the volume to ensure that they were scheduled
    properly.
    :param volume: The Volume to check.
    :param spec: The spec to validate the Tag against.
    :param tag_mapping: The mapping of Nodes to the Tags they have.
    :raise AssertionError: If the Volume doesn&#39;t match all the conditions.
    &#34;&#34;&#34;
    found_hosts = {}
    # Make sure that all the Tags the Volume requested were fulfilled.
    for replica in volume.replicas:
        found_hosts[replica.hostId] = {}
        assert not len(set(spec[&#34;disk&#34;]) -
                       set(tag_mapping[replica.hostId][&#34;disk&#34;]))
        assert not len(set(spec[&#34;node&#34;]) -
                       set(tag_mapping[replica.hostId][&#34;node&#34;]))

    # The Volume should have replicas on as many nodes as matched
    # the requirements (specified by &#34;expected&#34; in the spec variable).
    assert len(found_hosts) == spec[&#34;expected&#34;]</code></pre>
</details>
<div class="desc"><p>Check the replicas on the volume to ensure that they were scheduled
properly.
:param volume: The Volume to check.
:param spec: The spec to validate the Tag against.
:param tag_mapping: The mapping of Nodes to the Tags they have.
:raise AssertionError: If the Volume doesn't match all the conditions.</p></div>
</dd>
<dt id="tests.common.cleanup_all_backing_images"><code class="name flex">
<span>def <span class="ident">cleanup_all_backing_images</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_all_backing_images(client):
    backing_images = client.list_backing_image()
    for bi in backing_images:
        try:
            client.delete(bi)
        except Exception as e:
            print(&#34;\nException when cleanup backing image &#34;, bi)
            print(e)
    for i in range(RETRY_COUNTS):
        backing_images = client.list_backing_image()
        if len(backing_images) == 0:
            break
        time.sleep(RETRY_INTERVAL)
    assert len(client.list_backing_image()) == 0</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_all_recurring_jobs"><code class="name flex">
<span>def <span class="ident">cleanup_all_recurring_jobs</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_all_recurring_jobs(client):
    recurring_jobs = client.list_recurring_job()
    for recurring_job in recurring_jobs:
        try:
            client.delete(recurring_job)
        except Exception as e:
            print(&#34;\nException when cleanup recurring job &#34;, recurring_job)
            print(e)
    wait_for_recurring_jobs_cleanup(client)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_all_support_bundles"><code class="name flex">
<span>def <span class="ident">cleanup_all_support_bundles</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_all_support_bundles(client):
    &#34;&#34;&#34;
    Clean up all support bundles
    :param client: The Longhorn client to use in the request.
    &#34;&#34;&#34;
    support_bundles = client.list_support_bundle()
    for support_bundle in support_bundles:
        id = support_bundle[&#39;id&#39;]
        name = support_bundle[&#39;name&#39;]
        # ignore the error when clean up
        try:
            delete_support_bundle(id, name, client)
        except Exception as e:
            print(&#34;\nException when cleanup support_bundle &#34;, support_bundle)
            print(e)

    ok = False
    for _ in range(RETRY_COUNTS):
        support_bundles = client.list_support_bundle()
        if len(support_bundles) == 0:
            ok = True
            break
        time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"><p>Clean up all support bundles
:param client: The Longhorn client to use in the request.</p></div>
</dd>
<dt id="tests.common.cleanup_all_volumes"><code class="name flex">
<span>def <span class="ident">cleanup_all_volumes</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_all_volumes(client):
    &#34;&#34;&#34;
    Clean up all volumes
    :param client: The Longhorn client to use in the request.
    &#34;&#34;&#34;

    volumes = client.list_volume()
    for v in volumes:
        # ignore the error when clean up
        try:
            client.delete(v)
            wait_for_volume_delete(client, v.name)
        except Exception as e:
            print(&#34;\nException when cleanup volume &#34;, v)
            print(e)
    for i in range(RETRY_COUNTS):
        volumes = client.list_volume()
        if len(volumes) == 0:
            break
        time.sleep(RETRY_INTERVAL)

    volumes = client.list_volume()
    assert len(volumes) == 0</code></pre>
</details>
<div class="desc"><p>Clean up all volumes
:param client: The Longhorn client to use in the request.</p></div>
</dd>
<dt id="tests.common.cleanup_client"><code class="name flex">
<span>def <span class="ident">cleanup_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_client():
    core_api = k8sclient.CoreV1Api()
    client = get_longhorn_api_client()

    enable_default_disk(client)

    cleanup_all_volumes(client)

    # cleanup test disks
    cleanup_test_disks(client)

    if recurring_job_feature_supported(client):
        cleanup_all_recurring_jobs(client)

    if backing_image_feature_supported(client):
        cleanup_all_backing_images(client)

    cleanup_crypto_secret()
    cleanup_storage_class()
    if system_backup_feature_supported(client):
        system_restores_cleanup(client)

    cleanup_all_support_bundles(client)

    # enable nodes scheduling
    reset_node(client, core_api)
    reset_settings(client)
    reset_disks_for_all_nodes(client)
    scale_up_engine_image_daemonset(client)
    reset_engine_image(client)
    wait_for_all_instance_manager_running(client)

    enable_v2 = os.environ.get(&#39;RUN_V2_TEST&#39;)
    if enable_v2 == &#34;true&#34;:
        return

    # check replica subdirectory of default disk path
    if not os.path.exists(DEFAULT_REPLICA_DIRECTORY):
        subprocess.check_call(
            [&#34;mkdir&#34;, &#34;-p&#34;, DEFAULT_REPLICA_DIRECTORY])</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_crypto_secret"><code class="name flex">
<span>def <span class="ident">cleanup_crypto_secret</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_crypto_secret():
    secret_deletes = [&#34;longhorn-crypto&#34;]
    api = get_core_api_client()
    ret = api.list_namespaced_secret(namespace=LONGHORN_NAMESPACE)
    for sc in ret.items:
        if sc.metadata.name in secret_deletes:
            delete_crypto_secret(name=sc.metadata.name,
                                 namespace=LONGHORN_NAMESPACE)

    ok = False
    for _ in range(RETRY_COUNTS):
        ok = True
        ret = api.list_namespaced_secret(namespace=LONGHORN_NAMESPACE)
        for s in ret.items:
            if s.metadata.name in secret_deletes:
                ok = False
                break
        if ok:
            break
        time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_disks_on_node"><code class="name flex">
<span>def <span class="ident">cleanup_disks_on_node</span></span>(<span>client, node_id, *disks)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_disks_on_node(client, node_id, *disks):  # NOQA
    # Disable scheduling for the new disks on self node
    node = client.by_id_node(node_id)
    for name, disk in node.disks.items():
        if disk.path != DEFAULT_DISK_PATH:
            disk.allowScheduling = False

    # Update disks of self node
    update_disks = get_update_disks(node.disks)
    update_node_disks(client, node.name, disks=update_disks, retry=True)
    node = wait_for_disk_update(client, node_id, len(update_disks))

    # Remove new disks on self node and enable scheduling for the default disk
    default_disks = {}
    for name, disk in iter(node.disks.items()):
        if disk.path == DEFAULT_DISK_PATH:
            disk.allowScheduling = True
            default_disks[name] = disk

    # Update disks of self node
    update_disks = get_update_disks(node.disks)
    update_node_disks(client, node.name, disks=default_disks, retry=True)
    wait_for_disk_update(client, node_id, len(default_disks))

    # Cleanup host disks
    for disk in disks:
        cleanup_host_disks(client, disk)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_host_disk"><code class="name flex">
<span>def <span class="ident">cleanup_host_disk</span></span>(<span>vol_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_host_disk(vol_name):
    mount_path = os.path.join(DIRECTORY_PATH, vol_name)
    umount_disk(mount_path)

    cmd = [&#39;rm&#39;, &#39;-r&#39;, mount_path]
    subprocess.check_call(cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_host_disks"><code class="name flex">
<span>def <span class="ident">cleanup_host_disks</span></span>(<span>client, *args)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_host_disks(client, *args):
    # clean disk
    for vol_name in args:
        # umount disk
        cleanup_host_disk(vol_name)
        # clean volume
        cleanup_volume_by_name(client, vol_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_node_disks"><code class="name flex">
<span>def <span class="ident">cleanup_node_disks</span></span>(<span>client, node_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_node_disks(client, node_name):
    node = client.by_id_node(node_name)
    disks = node.disks
    for _, disk in iter(disks.items()):
        disk.allowScheduling = False
    update_disks = get_update_disks(disks)
    node = client.by_id_node(node_name)

    # Retry if &#34;too many retries error&#34; happened.
    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node.diskUpdate(disks=update_disks)
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(e)
            raise
        else:
            break

    for name, disk in iter(disks.items()):
        wait_for_disk_status(client, node_name,
                             name, &#34;allowScheduling&#34;, False)

    # Retry if &#34;too many retries error&#34; happened.
    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node.diskUpdate(disks={})
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(e)
            raise
        else:
            break

    return wait_for_disk_update(client, node_name, 0)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_storage_class"><code class="name flex">
<span>def <span class="ident">cleanup_storage_class</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_storage_class():
    # premium-rwo, standard-rwo and standard are installed in gke by default
    # azurefile-csi, azurefile-csi-premium, azurefile-premium, managed,
    # managed-csi, managed-csi-premium, managed-premium are installed
    # in aks by default
    skip_sc_deletes = [&#34;longhorn&#34;, &#34;local-path&#34;,
                       &#34;premium-rwo&#34;, &#34;standard-rwo&#34;, &#34;standard&#34;,
                       &#34;azurefile-csi&#34;, &#34;azurefile-csi-premium&#34;,
                       &#34;azurefile-premium&#34;, &#34;managed&#34;, &#34;managed-csi&#34;,
                       &#34;managed-csi-premium&#34;, &#34;managed-premium&#34;]
    api = get_storage_api_client()
    ret = api.list_storage_class()
    for sc in ret.items:
        if sc.metadata.name in skip_sc_deletes:
            continue
        delete_storage_class(sc.metadata.name)

    ok = False
    for _ in range(RETRY_COUNTS):
        ok = True
        ret = api.list_storage_class()
        for sc in ret.items:
            if sc.metadata.name not in skip_sc_deletes:
                ok = False
                break
        if ok:
            break
        time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_test_disks"><code class="name flex">
<span>def <span class="ident">cleanup_test_disks</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_test_disks(client):
    try:
        del_dirs = os.listdir(DIRECTORY_PATH)
    except FileNotFoundError:
        del_dirs = []

    host_id = get_self_host_id()
    node = client.by_id_node(host_id)
    disks = node.disks
    for name, disk in iter(disks.items()):
        for del_dir in del_dirs:
            dir_path = os.path.join(DIRECTORY_PATH, del_dir)
            if dir_path == disk.path:
                disk.allowScheduling = False
    update_disks = get_update_disks(disks)

    # Retry if &#34;too many retries error&#34; happened.
    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node = node.diskUpdate(disks=update_disks)
            disks = node.disks
            for name, disk in iter(disks.items()):
                for del_dir in del_dirs:
                    dir_path = os.path.join(DIRECTORY_PATH, del_dir)
                    if dir_path == disk.path:
                        wait_for_disk_status(client, host_id, name,
                                             &#34;allowScheduling&#34;, False)
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(&#34;\nException when update node disks&#34;, node)
            print(e)
            raise
        else:
            break

    # delete test disks
    disks = node.disks
    update_disks = {}
    for name, disk in iter(disks.items()):
        if disk.allowScheduling:
            update_disks[name] = disk
    # Retry if &#34;too many retries error&#34; happened.
    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node.diskUpdate(disks=update_disks)
            wait_for_disk_update(client, host_id, len(update_disks))
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(&#34;\nException when delete node test disks&#34;, node)
            print(e)
            raise
        else:
            break
    # cleanup host disks
    for del_dir in del_dirs:
        try:
            cleanup_host_disk(del_dir)
        except Exception as e:
            print(&#34;\nException when cleanup host disk&#34;, del_dir)
            print(e)
            pass</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.cleanup_volume"><code class="name flex">
<span>def <span class="ident">cleanup_volume</span></span>(<span>client, volume)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_volume(client, volume):
    &#34;&#34;&#34;
    Clean up the volume after the test.
    :param client: The Longhorn client to use in the request.
    :param volume: The volume to clean up.
    &#34;&#34;&#34;
    volume.detach()
    volume = wait_for_volume_detached(client, volume.name)
    client.delete(volume)
    wait_for_volume_delete(client, volume.name)
    volumes = client.list_volume()
    assert len(volumes) == 0</code></pre>
</details>
<div class="desc"><p>Clean up the volume after the test.
:param client: The Longhorn client to use in the request.
:param volume: The volume to clean up.</p></div>
</dd>
<dt id="tests.common.cleanup_volume_by_name"><code class="name flex">
<span>def <span class="ident">cleanup_volume_by_name</span></span>(<span>client, vol_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_volume_by_name(client, vol_name):
    volume = client.by_id_volume(vol_name)
    volume.detach()
    client.delete(volume)
    wait_for_volume_delete(client, vol_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.client"><code class="name flex">
<span>def <span class="ident">client</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def client(request):
    &#34;&#34;&#34;
    Return an individual Longhorn API client for testing.
    &#34;&#34;&#34;
    k8sconfig.load_incluster_config()
    # Make sure nodes and managers are all online.
    ips = get_mgr_ips()

    api_client = None

    # check if longhorn manager port is open before calling get_client
    for ip in ips:
        family = socket.AF_INET6 if &#39;:&#39; in ip else socket.AF_INET
        sock = socket.socket(family, socket.SOCK_STREAM)

        try:
            if sock.connect_ex((ip, 9500)) == 0:
                api_client = get_client(ip + PORT)
                break
        finally:
            sock.close()

    if api_client is None:
        raise RuntimeError(
            &#34;Failed to connect to any Longhorn manager on ports 9500&#34;)

    hosts = api_client.list_node()
    assert len(hosts) == len(ips)

    request.addfinalizer(lambda: cleanup_client())

    if not os.path.exists(DIRECTORY_PATH):
        try:
            os.makedirs(DIRECTORY_PATH)
        except OSError as e:
            raise Exception(
                f&#34;Failed to create directory {DIRECTORY_PATH}: {e}&#34;
            )

    cleanup_client()

    return api_client</code></pre>
</details>
<div class="desc"><p>Return an individual Longhorn API client for testing.</p></div>
</dd>
<dt id="tests.common.clients"><code class="name flex">
<span>def <span class="ident">clients</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def clients(request):
    k8sconfig.load_incluster_config()
    ips = get_mgr_ips()
    client = get_client(ips[0] + PORT)
    hosts = client.list_node()
    assert len(hosts) == len(ips)
    clis = get_clients(hosts)

    def finalizer():
        cleanup_client()

    request.addfinalizer(finalizer)

    cleanup_client()

    return clis</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.copy_file_to_volume_dev_mb_data"><code class="name flex">
<span>def <span class="ident">copy_file_to_volume_dev_mb_data</span></span>(<span>src_path, dest_path, src_offset, dest_offset, size_in_mb, timeout_cnt=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy_file_to_volume_dev_mb_data(src_path, dest_path,
                                    src_offset, dest_offset, size_in_mb,
                                    timeout_cnt=5):
    cmd = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;dd if=%s of=%s bs=1M count=%d skip=%d seek=%d&#39; %
        (src_path, dest_path, size_in_mb, src_offset, dest_offset)
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT * timeout_cnt,
                 error_message=&#39;Timeout on copying file to dev&#39;):
        subprocess.check_call(cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.copy_pod_volume_data"><code class="name flex">
<span>def <span class="ident">copy_pod_volume_data</span></span>(<span>api, pod_name, src_path, dest_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy_pod_volume_data(api, pod_name, src_path, dest_path):
    write_cmd = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;dd if=&#39; + src_path + &#39; of=&#39; + dest_path
    ]
    return stream(
        api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
        command=write_cmd, stderr=True, stdin=False, stdout=True,
        tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.core_api"><code class="name flex">
<span>def <span class="ident">core_api</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def core_api(request):
    &#34;&#34;&#34;
    Create a new CoreV1API instance.
    Returns:
        A new CoreV1API Instance.
    &#34;&#34;&#34;
    c = Configuration()
    c.assert_hostname = False
    Configuration.set_default(c)
    k8sconfig.load_incluster_config()
    core_api = k8sclient.CoreV1Api()

    return core_api</code></pre>
</details>
<div class="desc"><p>Create a new CoreV1API instance.</p>
<h2 id="returns">Returns</h2>
<p>A new CoreV1API Instance.</p></div>
</dd>
<dt id="tests.common.crash_engine_process_with_sigkill"><code class="name flex">
<span>def <span class="ident">crash_engine_process_with_sigkill</span></span>(<span>client, core_api, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crash_engine_process_with_sigkill(client, core_api, volume_name):
    volume = client.by_id_volume(volume_name)
    ins_mgr_name = volume.controllers[0].instanceManagerName

    kill_command = [
            &#39;/bin/sh&#39;, &#39;-c&#39;,
            &#34;kill `pgrep -f \&#34;controller &#34; + volume_name + &#34;\&#34;`&#34;]

    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream read&#39;):
        stream(core_api.connect_get_namespaced_pod_exec,
               ins_mgr_name,
               LONGHORN_NAMESPACE, command=kill_command,
               stderr=True, stdin=False, stdout=True, tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.crash_replica_processes"><code class="name flex">
<span>def <span class="ident">crash_replica_processes</span></span>(<span>client, api, volname, replicas=None, wait_to_fail=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crash_replica_processes(client, api, volname, replicas=None,
                            wait_to_fail=True):
    threads = []

    if replicas is None:
        volume = client.by_id_volume(volname)
        replicas = volume.replicas

    for r in replicas:
        assert r.instanceManagerName != &#34;&#34;

        pgrep_command = f&#34;pgrep -f {r[&#39;dataPath&#39;]}&#34;
        pid = exec_instance_manager(api, r.instanceManagerName, pgrep_command)
        assert pid != &#34;&#34;

        kill_command = f&#34;kill {pid}&#34;
        exec_instance_manager(api, r.instanceManagerName, kill_command)

        if wait_to_fail is True:
            thread = create_assert_error_check_thread(
                wait_for_replica_failed,
                client, volname, r[&#39;name&#39;], RETRY_COUNTS, RETRY_INTERVAL_SHORT
            )
            threads.append(thread)

    if wait_to_fail:
        assert_from_assert_error_check_threads(threads)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_and_check_volume"><code class="name flex">
<span>def <span class="ident">create_and_check_volume</span></span>(<span>client,<br>volume_name,<br>num_of_replicas=3,<br>size='33554432',<br>backing_image='',<br>frontend='blockdev',<br>snapshot_data_integrity='ignored',<br>access_mode='rwo',<br>data_engine='v1')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_and_check_volume(client, volume_name,
                            num_of_replicas=3, size=SIZE, backing_image=&#34;&#34;,
                            frontend=VOLUME_FRONTEND_BLOCKDEV,
                            snapshot_data_integrity=&#34;ignored&#34;,
                            access_mode=ACCESS_MODE_RWO, data_engine=DATA_ENGINE):  # NOQA
    &#34;&#34;&#34;
    Create a new volume with the specified parameters. Assert that the new
    volume is detached and that all of the requested parameters match.

    :param client: The Longhorn client to use in the request.
    :param volume_name: The name of the volume.
    :param num_of_replicas: The number of replicas the volume should have.
    :param size: The size of the volume, as a string representing the number
    of bytes.
    :param backing_image: The backing image to use for the volume.
    :param frontend: The frontend to use for the volume.
    :return: The volume instance created.
    &#34;&#34;&#34;
    if not backing_image_feature_supported(client):
        backing_image = None
    client.create_volume(name=volume_name, size=size,
                         numberOfReplicas=num_of_replicas,
                         backingImage=backing_image, frontend=frontend,
                         snapshotDataIntegrity=snapshot_data_integrity,
                         accessMode=access_mode, dataEngine=data_engine)
    volume = wait_for_volume_detached(client, volume_name)
    assert volume.name == volume_name
    assert volume.size == size
    assert volume.numberOfReplicas == num_of_replicas
    assert volume.state == &#34;detached&#34;
    if backing_image_feature_supported(client):
        assert volume.backingImage == backing_image
    assert volume.frontend == frontend
    assert volume.created != &#34;&#34;
    return volume</code></pre>
</details>
<div class="desc"><p>Create a new volume with the specified parameters. Assert that the new
volume is detached and that all of the requested parameters match.</p>
<p>:param client: The Longhorn client to use in the request.
:param volume_name: The name of the volume.
:param num_of_replicas: The number of replicas the volume should have.
:param size: The size of the volume, as a string representing the number
of bytes.
:param backing_image: The backing image to use for the volume.
:param frontend: The frontend to use for the volume.
:return: The volume instance created.</p></div>
</dd>
<dt id="tests.common.create_and_wait_deployment"><code class="name flex">
<span>def <span class="ident">create_and_wait_deployment</span></span>(<span>apps_api, deployment_manifest)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_and_wait_deployment(apps_api, deployment_manifest):
    apps_api.create_namespaced_deployment(
        body=deployment_manifest,
        namespace=&#39;default&#39;)

    deployment_name = deployment_manifest[&#34;metadata&#34;][&#34;name&#34;]
    desired_replica_count = deployment_manifest[&#34;spec&#34;][&#34;replicas&#34;]

    wait_deployment_replica_ready(
        apps_api,
        deployment_name,
        desired_replica_count
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_and_wait_pod"><code class="name flex">
<span>def <span class="ident">create_and_wait_pod</span></span>(<span>api, pod_manifest)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_and_wait_pod(api, pod_manifest):
    &#34;&#34;&#34;
    Creates a new Pod attached to a PersistentVolumeClaim for testing.

    The function will block until the Pod is online or until it times out,
    whichever occurs first. The volume created by the manifest passed in will
    be mounted to &#39;/data&#39;.

    Args:
        api: An instance of CoreV1API.
        pod_name: The name of the Pod.
        volume: The volume manifest.
    &#34;&#34;&#34;
    api.create_namespaced_pod(
        body=pod_manifest,
        namespace=&#39;default&#39;)

    pod_name = pod_manifest[&#39;metadata&#39;][&#39;name&#39;]

    wait_pod(pod_name)</code></pre>
</details>
<div class="desc"><p>Creates a new Pod attached to a PersistentVolumeClaim for testing.</p>
<p>The function will block until the Pod is online or until it times out,
whichever occurs first. The volume created by the manifest passed in will
be mounted to '/data'.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>api</code></strong></dt>
<dd>An instance of CoreV1API.</dd>
<dt><strong><code>pod_name</code></strong></dt>
<dd>The name of the Pod.</dd>
<dt><strong><code>volume</code></strong></dt>
<dd>The volume manifest.</dd>
</dl></div>
</dd>
<dt id="tests.common.create_and_wait_statefulset"><code class="name flex">
<span>def <span class="ident">create_and_wait_statefulset</span></span>(<span>statefulset_manifest)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_and_wait_statefulset(statefulset_manifest):
    &#34;&#34;&#34;
    Create a new StatefulSet for testing.

    This function will block until all replicas in the StatefulSet are online
    or it times out, whichever occurs first.
    &#34;&#34;&#34;
    create_statefulset(statefulset_manifest)
    wait_statefulset(statefulset_manifest)</code></pre>
</details>
<div class="desc"><p>Create a new StatefulSet for testing.</p>
<p>This function will block until all replicas in the StatefulSet are online
or it times out, whichever occurs first.</p></div>
</dd>
<dt id="tests.common.create_assert_error_check_thread"><code class="name flex">
<span>def <span class="ident">create_assert_error_check_thread</span></span>(<span>func, *args)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_assert_error_check_thread(func, *args):
    &#34;&#34;&#34;
        Do func by threading with arguments

        Parameters:
            func:   function that want to do things in parallel.
            args:   arguments for function.
    &#34;&#34;&#34;
    assert isinstance(func, types.FunctionType), &#34;First arg is not a function.&#34;

    t = AssertErrorCheckThread(target=func, args=args)
    t.start()

    return t</code></pre>
</details>
<div class="desc"><p>Do func by threading with arguments</p>
<h2 id="parameters">Parameters</h2>
<p>func:
function that want to do things in parallel.
args:
arguments for function.</p></div>
</dd>
<dt id="tests.common.create_backing_image_with_matching_url"><code class="name flex">
<span>def <span class="ident">create_backing_image_with_matching_url</span></span>(<span>client,<br>name,<br>url,<br>minNumberOfCopies=1,<br>nodeSelector=[],<br>diskSelector=[],<br>dataEngine='v1')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_backing_image_with_matching_url(client, name, url,
                                           minNumberOfCopies=1,
                                           nodeSelector=[], diskSelector=[],
                                           dataEngine=DATA_ENGINE):
    backing_images = client.list_backing_image()
    found = False
    for bi in backing_images:
        if bi.name == name:
            found = True
            break
    if found:
        if bi.sourceType != BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD or \
                bi.parameters[&#34;url&#34;] != url:
            client.delete(bi)
            bi = client.by_id_backing_image(name=name)
        if bi is None or bi.deletionTimestamp != &#34;&#34;:
            wait_for_backing_image_delete(client, name)
            found = False
    if not found:
        expected_checksum = &#34;&#34;
        # Only the following 2 URLs will be used in the integration tests
        # for now.
        if url == BACKING_IMAGE_RAW_URL:
            expected_checksum = BACKING_IMAGE_RAW_CHECKSUM
        elif url == BACKING_IMAGE_QCOW2_URL:
            if dataEngine == &#34;v2&#34;:
                expected_checksum = BACKING_IMAGE_RAW_CHECKSUM
            else:
                expected_checksum = BACKING_IMAGE_QCOW2_CHECKSUM
        bi = client.create_backing_image(
            name=name, sourceType=BACKING_IMAGE_SOURCE_TYPE_DOWNLOAD,
            parameters={&#34;url&#34;: url}, expectedChecksum=expected_checksum,
            minNumberOfCopies=minNumberOfCopies,
            nodeSelector=nodeSelector, diskSelector=diskSelector,
            dataEngine=dataEngine)
    assert bi

    is_ready = False
    for i in range(RETRY_COUNTS):
        bi = client.by_id_backing_image(name)
        if (len(bi.diskFileStatusMap) == minNumberOfCopies and
                bi.currentChecksum != &#34;&#34;):
            for disk, status in iter(bi.diskFileStatusMap.items()):
                if status.state == &#34;ready&#34;:
                    is_ready = True
                    break
            if is_ready:
                break
        time.sleep(RETRY_INTERVAL)

    return bi</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_backup"><code class="name flex">
<span>def <span class="ident">create_backup</span></span>(<span>client, volname, data={}, labels={})</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_backup(client, volname, data={}, labels={}):
    volume = client.by_id_volume(volname)
    create_snapshot(client, volname)
    if not data:
        data = write_volume_random_data(volume)
    else:
        data = write_volume_data(volume, data)
    snap = create_snapshot(client, volname)
    create_snapshot(client, volname)

    # after backup request we need to wait for completion of the backup
    # since the backup.cfg will only be available once the backup operation
    # has been completed
    volume.snapshotBackup(name=snap.name, labels=labels)
    wait_for_backup_completion(client, volname, snap.name)

    verified = False
    for i in range(RETRY_COMMAND_COUNT):
        bv, b = find_backup(client, volname, snap.name)
        new_b = bv.backupGet(name=b.name)
        if new_b.name == b.name and \
           new_b.url == b.url and \
           new_b.snapshotName == b.snapshotName and \
           new_b.snapshotCreated == b.snapshotCreated and \
           new_b.created == b.created and \
           new_b.volumeName == b.volumeName and \
           new_b.volumeSize == b.volumeSize and \
           new_b.volumeCreated == b.volumeCreated:
            verified = True
            break
        time.sleep(RETRY_INTERVAL)
    assert verified

    # Don&#39;t directly compare the Label dictionaries, since the server could
    # have added extra Labels.
    for key, val in iter(labels.items()):
        assert new_b.labels.get(key) == val

    volume = wait_for_volume_status(client, volname,
                                    &#34;lastBackup&#34;,
                                    b.name)
    assert volume.lastBackupAt != &#34;&#34;

    return bv, b, snap, data</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_backup_from_volume_attached_to_pod"><code class="name flex">
<span>def <span class="ident">create_backup_from_volume_attached_to_pod</span></span>(<span>client, core_api, volume_name, pod_name, data_path='/data/test', data_size=100)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_backup_from_volume_attached_to_pod(client, core_api,
                                              volume_name, pod_name,
                                              data_path=&#39;/data/test&#39;,
                                              data_size=DATA_SIZE_IN_MB_1):
    &#34;&#34;&#34;
        Write data in the pod and take a backup.
        Args:
            client: The Longhorn client to use in the request.
            core_api: An instance of CoreV1API.
            pod_name: The name of the Pod.
            volume_name: The volume name which is attached to the pod.
            data_path: File name suffixed to the mount point. e.g /data/file
            data_size: Size of the data to be written in the pod.
        Returns:
            The backup volume name, backup, checksum of data written in the
            backup
    &#34;&#34;&#34;
    write_pod_volume_random_data(core_api, pod_name,
                                 data_path, data_size)
    data_checksum = get_pod_data_md5sum(core_api, pod_name, data_path)

    snap = create_snapshot(client, volume_name)
    volume = client.by_id_volume(volume_name)
    volume.snapshotBackup(name=snap.name)
    wait_for_backup_completion(client, volume_name, snap.name)
    backup_volume, backup = find_backup(client, volume_name, snap.name)

    return backup_volume, backup, data_checksum</code></pre>
</details>
<div class="desc"><p>Write data in the pod and take a backup.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>client</code></strong></dt>
<dd>The Longhorn client to use in the request.</dd>
<dt><strong><code>core_api</code></strong></dt>
<dd>An instance of CoreV1API.</dd>
<dt><strong><code>pod_name</code></strong></dt>
<dd>The name of the Pod.</dd>
<dt><strong><code>volume_name</code></strong></dt>
<dd>The volume name which is attached to the pod.</dd>
<dt><strong><code>data_path</code></strong></dt>
<dd>File name suffixed to the mount point. e.g /data/file</dd>
<dt><strong><code>data_size</code></strong></dt>
<dd>Size of the data to be written in the pod.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The backup volume name, backup, checksum of data written in the
backup</p></div>
</dd>
<dt id="tests.common.create_crypto_secret"><code class="name flex">
<span>def <span class="ident">create_crypto_secret</span></span>(<span>secret_manifest, namespace='longhorn-system')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_crypto_secret(secret_manifest, namespace=LONGHORN_NAMESPACE):
    api = get_core_api_client()
    api.create_namespaced_secret(namespace,
                                 body=secret_manifest)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_deployment_and_write_data"><code class="name flex">
<span>def <span class="ident">create_deployment_and_write_data</span></span>(<span>client,<br>core_api,<br>make_deployment_with_pvc,<br>volume_name,<br>size,<br>replica_count,<br>data_size,<br>attach_node_id=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_deployment_and_write_data(client, # NOQA
                                     core_api, # NOQA
                                     make_deployment_with_pvc, # NOQA
                                     volume_name, # NOQA
                                     size, # NOQA
                                     replica_count, # NOQA
                                     data_size, # NOQA
                                     attach_node_id=None): # NOQA
    apps_api = get_apps_api_client()
    volume = client.create_volume(name=volume_name,
                                  size=size,
                                  numberOfReplicas=replica_count,
                                  dataEngine=DATA_ENGINE)
    volume = wait_for_volume_detached(client, volume_name)

    pvc_name = volume_name + &#34;-pvc&#34;
    create_pv_for_volume(client, core_api, volume, volume_name)
    create_pvc_for_volume(client, core_api, volume, pvc_name)
    deployment_name = volume_name + &#34;-dep&#34;
    deployment = make_deployment_with_pvc(deployment_name, pvc_name)
    if attach_node_id:
        deployment[&#34;spec&#34;][&#34;template&#34;][&#34;spec&#34;][&#34;nodeSelector&#34;] \
            = {&#34;kubernetes.io/hostname&#34;: attach_node_id}

    create_and_wait_deployment(apps_api, deployment)

    data_path = &#39;/data/test&#39;
    deployment_pod_names = get_deployment_pod_names(core_api,
                                                    deployment)
    write_pod_volume_random_data(core_api,
                                 deployment_pod_names[0],
                                 data_path,
                                 data_size)

    checksum = get_pod_data_md5sum(core_api,
                                   deployment_pod_names[0],
                                   data_path)

    volume = client.by_id_volume(volume_name)
    return volume, deployment_pod_names[0], checksum, deployment</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_host_disk"><code class="name flex">
<span>def <span class="ident">create_host_disk</span></span>(<span>client, vol_name, size, node_id)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_host_disk(client, vol_name, size, node_id):
    # create a single replica volume and attach it to node
    volume = create_volume(client, vol_name, size, node_id, 1)

    # prepare the disk in the host filesystem
    disk_path = prepare_host_disk(get_volume_endpoint(volume), volume.name)
    return disk_path</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_pv_for_volume"><code class="name flex">
<span>def <span class="ident">create_pv_for_volume</span></span>(<span>client, core_api, volume, pv_name, fs_type='ext4')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_pv_for_volume(client, core_api, volume, pv_name, fs_type=&#34;ext4&#34;):
    volume.pvCreate(pvName=pv_name, fsType=fs_type)
    for i in range(RETRY_COUNTS):
        if check_pv_existence(core_api, pv_name):
            break
        time.sleep(RETRY_INTERVAL)
    assert check_pv_existence(core_api, pv_name)

    ks = {
        &#39;pvName&#39;: pv_name,
        &#39;pvStatus&#39;: &#39;Available&#39;,
        &#39;namespace&#39;: &#39;&#39;,
        &#39;lastPVCRefAt&#39;: &#39;&#39;,
        &#39;lastPodRefAt&#39;: &#39;&#39;,
    }
    wait_volume_kubernetes_status(client, volume.name, ks)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_pvc"><code class="name flex">
<span>def <span class="ident">create_pvc</span></span>(<span>pvc_manifest)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_pvc(pvc_manifest):
    api = get_core_api_client()
    api.create_namespaced_persistent_volume_claim(
        &#39;default&#39;, pvc_manifest)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_pvc_for_volume"><code class="name flex">
<span>def <span class="ident">create_pvc_for_volume</span></span>(<span>client, core_api, volume, pvc_name, pvc_namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_pvc_for_volume(client, core_api, volume, pvc_name, pvc_namespace=&#34;default&#34;): # NOQA
    volume.pvcCreate(namespace=pvc_namespace, pvcName=pvc_name)
    for i in range(RETRY_COUNTS):
        if check_pvc_existence(core_api, pvc_name, pvc_namespace):
            break
        time.sleep(RETRY_INTERVAL)
    assert check_pvc_existence(core_api, pvc_name, pvc_namespace)

    ks = {
        &#39;pvStatus&#39;: &#39;Bound&#39;,
        &#39;namespace&#39;: pvc_namespace,
        &#39;lastPVCRefAt&#39;: &#39;&#39;,
    }
    wait_volume_kubernetes_status(client, volume.name, ks)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_pvc_spec"><code class="name flex">
<span>def <span class="ident">create_pvc_spec</span></span>(<span>name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_pvc_spec(name):
    # type: (str) -&gt; dict
    &#34;&#34;&#34;
    Generate a volume manifest using the given name for the PVC.

    This spec is used to test dynamically provisioned PersistentVolumes (those
    created using a storage class).
    &#34;&#34;&#34;
    return {
        &#39;name&#39;: &#39;pod-data&#39;,
        &#39;persistentVolumeClaim&#39;: {
            &#39;claimName&#39;: name,
            &#39;readOnly&#39;: False
        }
    }</code></pre>
</details>
<div class="desc"><p>Generate a volume manifest using the given name for the PVC.</p>
<p>This spec is used to test dynamically provisioned PersistentVolumes (those
created using a storage class).</p></div>
</dd>
<dt id="tests.common.create_recurring_jobs"><code class="name flex">
<span>def <span class="ident">create_recurring_jobs</span></span>(<span>client, recurring_jobs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_recurring_jobs(client, recurring_jobs):
    time.sleep(60 - datetime.utcnow().second)

    for name, spec in recurring_jobs.items():
        client.create_recurring_job(Name=name,
                                    Task=spec[&#34;task&#34;],
                                    Groups=spec[&#34;groups&#34;],
                                    Cron=spec[&#34;cron&#34;],
                                    Retain=spec[&#34;retain&#34;],
                                    Concurrency=spec[&#34;concurrency&#34;],
                                    Labels=spec[&#34;labels&#34;])</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_rwx_volume_with_storageclass"><code class="name flex">
<span>def <span class="ident">create_rwx_volume_with_storageclass</span></span>(<span>client, core_api, storage_class)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_rwx_volume_with_storageclass(client,
                                        core_api,
                                        storage_class):

    VOLUME_SIZE = str(DEFAULT_VOLUME_SIZE * Gi)

    pvc_name = generate_volume_name()

    pvc_spec = {
        &#34;apiVersion&#34;: &#34;v1&#34;,
        &#34;kind&#34;: &#34;PersistentVolumeClaim&#34;,
        &#34;metadata&#34;: {
                &#34;name&#34;: pvc_name,
        },
        &#34;spec&#34;: {
            &#34;accessModes&#34;: [
                &#34;ReadWriteMany&#34;
            ],
            &#34;storageClassName&#34;: storage_class[&#39;metadata&#39;][&#39;name&#39;],
            &#34;resources&#34;: {
                &#34;requests&#34;: {
                    &#34;storage&#34;: VOLUME_SIZE
                }
            }
        }
    }

    core_api.create_namespaced_persistent_volume_claim(
        &#39;default&#39;,
        pvc_spec
    )

    check_pvc_in_specific_status(core_api, pvc_name, &#39;Bound&#39;)

    volume_name = get_volume_name(core_api, pvc_name)

    wait_for_volume_creation(client, volume_name)
    if storage_class[&#39;parameters&#39;][&#39;fromBackup&#39;] != &#34;&#34;:
        wait_for_volume_restoration_completed(client, volume_name)
    wait_for_volume_detached(client, volume_name)

    return volume_name</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_snapshot"><code class="name flex">
<span>def <span class="ident">create_snapshot</span></span>(<span>longhorn_api_client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_snapshot(longhorn_api_client, volume_name):
    volume = longhorn_api_client.by_id_volume(volume_name)
    snap = volume.snapshotCRCreate()
    snap_name = snap.name

    snapshot_created = False
    for i in range(RETRY_COUNTS):
        snapshots = volume.snapshotList(volume=volume_name)

        for vs in snapshots.data:
            if vs.name == snap_name:
                snapshot_created = True
                snap = vs
                break
        if snapshot_created is True:
            break
        time.sleep(RETRY_INTERVAL)

    assert snapshot_created
    return snap</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_statefulset"><code class="name flex">
<span>def <span class="ident">create_statefulset</span></span>(<span>statefulset_manifest)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_statefulset(statefulset_manifest):
    &#34;&#34;&#34;
    Create a new StatefulSet for testing.
    &#34;&#34;&#34;
    api = get_apps_api_client()
    api.create_namespaced_stateful_set(
        body=statefulset_manifest,
        namespace=&#39;default&#39;)</code></pre>
</details>
<div class="desc"><p>Create a new StatefulSet for testing.</p></div>
</dd>
<dt id="tests.common.create_storage_class"><code class="name flex">
<span>def <span class="ident">create_storage_class</span></span>(<span>sc_manifest, data_engine='v1')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_storage_class(sc_manifest, data_engine=DATA_ENGINE):
    api = get_storage_api_client()
    sc_manifest[&#39;parameters&#39;][&#39;dataEngine&#39;] = data_engine
    api.create_storage_class(
        body=sc_manifest)

    sc_name = sc_manifest[&#39;metadata&#39;][&#39;name&#39;]
    for i in range(RETRY_COUNTS):
        try:
            sc = api.read_storage_class(sc_name)
            return sc
        except ApiException as e:
            if e.status != 404:
                raise
        time.sleep(RETRY_INTERVAL)

    assert False, f&#34;Failed to wait for sc {sc_name} to be created&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_support_bundle"><code class="name flex">
<span>def <span class="ident">create_support_bundle</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_support_bundle(client):  # NOQA
    data = {&#39;description&#39;: &#39;Test&#39;, &#39;issueURL&#39;: &#34;&#34;}
    return requests.post(get_support_bundle_url(client), json=data).json()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_volume"><code class="name flex">
<span>def <span class="ident">create_volume</span></span>(<span>client, vol_name, size, node_id, r_num)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_volume(client, vol_name, size, node_id, r_num):
    volume = client.create_volume(name=vol_name, size=size,
                                  numberOfReplicas=r_num,
                                  dataEngine=DATA_ENGINE)
    assert volume.numberOfReplicas == r_num
    assert volume.frontend == VOLUME_FRONTEND_BLOCKDEV

    volume = wait_for_volume_detached(client, vol_name)
    assert len(volume.replicas) == r_num

    assert volume.state == &#34;detached&#34;
    assert volume.created != &#34;&#34;

    volumeByName = client.by_id_volume(vol_name)
    assert volumeByName.name == volume.name
    assert volumeByName.size == volume.size
    assert volumeByName.numberOfReplicas == volume.numberOfReplicas
    assert volumeByName.state == volume.state
    assert volumeByName.created == volume.created

    volume.attach(hostId=node_id)
    volume = wait_for_volume_healthy(client, vol_name)

    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_volume_and_backup"><code class="name flex">
<span>def <span class="ident">create_volume_and_backup</span></span>(<span>client, vol_name, vol_size, backup_data_size)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_volume_and_backup(client, vol_name, vol_size, backup_data_size):
    client.create_volume(name=vol_name,
                         numberOfReplicas=1,
                         size=str(vol_size),
                         dataEngine=DATA_ENGINE)
    volume = wait_for_volume_detached(client, vol_name)
    volume.attach(hostId=get_self_host_id())
    volume = wait_for_volume_healthy(client, vol_name)

    data = {&#39;pos&#39;: 0,
            &#39;len&#39;: backup_data_size,
            &#39;content&#39;: generate_random_data(backup_data_size)}

    _, backup, _, _ = create_backup(client, vol_name, data)

    return volume, backup</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.create_volume_and_write_data"><code class="name flex">
<span>def <span class="ident">create_volume_and_write_data</span></span>(<span>client, volume_name, volume_size='33554432', data_engine='v1')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_volume_and_write_data(client, volume_name, volume_size=SIZE,
                                 data_engine=DATA_ENGINE):
    &#34;&#34;&#34;
    1. Create and attach a volume
    2. Write the data to volume
    &#34;&#34;&#34;
    # Step 1
    volume = create_and_check_volume(client,
                                     volume_name,
                                     size=volume_size,
                                     data_engine=data_engine)
    volume = volume.attach(hostId=get_self_host_id())
    volume = wait_for_volume_healthy(client, volume_name)

    # Step 2
    volume_data = write_volume_random_data(volume)

    return volume, volume_data</code></pre>
</details>
<div class="desc"><ol>
<li>Create and attach a volume</li>
<li>Write the data to volume</li>
</ol></div>
</dd>
<dt id="tests.common.crypto_secret"><code class="name flex">
<span>def <span class="ident">crypto_secret</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def crypto_secret(request):
    core_api = get_core_api_client()

    def get_crypto_secret(namespace=LONGHORN_NAMESPACE):
        crypto_secret.manifest = {
            &#39;apiVersion&#39;: &#39;v1&#39;,
            &#39;kind&#39;: &#39;Secret&#39;,
            &#39;metadata&#39;: {
                &#39;name&#39;: &#39;longhorn-crypto&#39;,
                &#39;namespace&#39;: namespace,
            },
            &#39;stringData&#39;: {
                &#39;CRYPTO_KEY_VALUE&#39;: &#39;simple&#39;,
                &#39;CRYPTO_KEY_PROVIDER&#39;: &#39;secret&#39;
            }
        }

        if is_k8s_node_gke_cos(core_api):
            # GKE COS&#39;s cryptsetup does not natively support &#34;argon2i&#34; and
            # &#34;argon2id&#34;.
            # https://github.com/longhorn/longhorn/issues/10049
            crypto_secret.manifest[&#39;stringData&#39;][&#39;CRYPTO_PBKDF&#39;] = &#39;pbkdf2&#39;

        return crypto_secret.manifest

    def finalizer():
        try:
            core_api.delete_namespaced_secret(
                name=crypto_secret.manifest[&#39;metadata&#39;][&#39;name&#39;],
                namespace=crypto_secret.manifest[&#39;metadata&#39;][&#39;namespace&#39;])
        except ApiException as e:
            assert e.status == 404

    request.addfinalizer(finalizer)

    return get_crypto_secret</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.csi_pv"><code class="name flex">
<span>def <span class="ident">csi_pv</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def csi_pv(request):
    return get_pv_manifest(request)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.csi_pv_backingimage"><code class="name flex">
<span>def <span class="ident">csi_pv_backingimage</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def csi_pv_backingimage(request):
    pv_manifest = get_pv_manifest(request)
    pv_manifest[&#39;spec&#39;][&#39;capacity&#39;][&#39;storage&#39;] = \
        size_to_string(BACKING_IMAGE_EXT4_SIZE)
    pv_manifest[&#39;spec&#39;][&#39;csi&#39;][&#39;volumeAttributes&#39;][&#39;backingImage&#39;] = \
        BACKING_IMAGE_NAME

    def finalizer():
        api = get_core_api_client()
        delete_and_wait_pv(api, pv_manifest[&#39;metadata&#39;][&#39;name&#39;])

        client = get_longhorn_api_client()
        delete_and_wait_longhorn(client, pv_manifest[&#39;metadata&#39;][&#39;name&#39;])

    request.addfinalizer(finalizer)

    return pv_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.csi_pvc_name"><code class="name flex">
<span>def <span class="ident">csi_pvc_name</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def csi_pvc_name(request):
    return generate_volume_name()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_and_wait_deployment"><code class="name flex">
<span>def <span class="ident">delete_and_wait_deployment</span></span>(<span>apps_api, deployment_name, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_and_wait_deployment(apps_api, deployment_name, namespace=&#39;default&#39;):
    try:
        apps_api.delete_namespaced_deployment(
            name=deployment_name,
            namespace=namespace
        )
    except ApiException as e:
        assert e.status == 404

    wait_delete_deployment(apps_api, deployment_name, namespace)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_and_wait_longhorn"><code class="name flex">
<span>def <span class="ident">delete_and_wait_longhorn</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_and_wait_longhorn(client, name):
    &#34;&#34;&#34;
    Delete a volume from Longhorn.
    &#34;&#34;&#34;
    try:
        v = client.by_id_volume(name)
        client.delete(v)
    except ApiException as ex:
        assert ex.status == 404
    except longhorn.ApiError as err:
        # for deleting a non-existing volume,
        # the status_code is 404.
        assert err.error.code == 404

    wait_for_volume_delete(client, name)</code></pre>
</details>
<div class="desc"><p>Delete a volume from Longhorn.</p></div>
</dd>
<dt id="tests.common.delete_and_wait_pod"><code class="name flex">
<span>def <span class="ident">delete_and_wait_pod</span></span>(<span>api, pod_name, namespace='default', wait=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_and_wait_pod(api, pod_name, namespace=&#39;default&#39;, wait=True):
    &#34;&#34;&#34;
    Delete a specified Pod.

    This function does not check if the Pod does exist and will throw an error
    if a nonexistent Pod is specified.

    Args:
        api: An instance of CoreV1API.
        pod_name: The name of the Pod.
    &#34;&#34;&#34;
    target_pod = None
    try:
        target_pod = api.read_namespaced_pod(name=pod_name,
                                             namespace=namespace)
    except ApiException as e:
        assert e.status == 404
        return

    try:
        api.delete_namespaced_pod(
            name=pod_name, namespace=namespace,
            body=k8sclient.V1DeleteOptions())
    except ApiException as e:
        assert e.status == 404
        return

    if wait:
        wait_delete_pod(api, target_pod.metadata.uid, namespace=namespace)</code></pre>
</details>
<div class="desc"><p>Delete a specified Pod.</p>
<p>This function does not check if the Pod does exist and will throw an error
if a nonexistent Pod is specified.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>api</code></strong></dt>
<dd>An instance of CoreV1API.</dd>
<dt><strong><code>pod_name</code></strong></dt>
<dd>The name of the Pod.</dd>
</dl></div>
</dd>
<dt id="tests.common.delete_and_wait_pv"><code class="name flex">
<span>def <span class="ident">delete_and_wait_pv</span></span>(<span>api, pv_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_and_wait_pv(api, pv_name):
    try:
        api.delete_persistent_volume(
            name=pv_name, body=k8sclient.V1DeleteOptions())
    except ApiException as e:
        assert e.status == 404

    wait_delete_pv(api, pv_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_and_wait_pvc"><code class="name flex">
<span>def <span class="ident">delete_and_wait_pvc</span></span>(<span>api, pvc_name, retry_counts=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_and_wait_pvc(api, pvc_name, retry_counts=RETRY_COUNTS):
    try:
        api.delete_namespaced_persistent_volume_claim(
            name=pvc_name, namespace=&#39;default&#39;,
            body=k8sclient.V1DeleteOptions())
    except ApiException as e:
        assert e.status == 404

    wait_delete_pvc(api, pvc_name, retry_counts=retry_counts)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_and_wait_statefulset"><code class="name flex">
<span>def <span class="ident">delete_and_wait_statefulset</span></span>(<span>api, client, statefulset)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_and_wait_statefulset(api, client, statefulset):
    apps_api = get_apps_api_client()
    if not check_statefulset_existence(apps_api,
                                       statefulset[&#39;metadata&#39;][&#39;name&#39;]):
        return

    # We need to generate the names for the PVCs on our own so we can
    # delete them.
    pod_data = get_statefulset_pod_info(api, statefulset)

    try:
        apps_api.delete_namespaced_stateful_set(
            name=statefulset[&#39;metadata&#39;][&#39;name&#39;],
            namespace=&#39;default&#39;, body=k8sclient.V1DeleteOptions())
    except ApiException as e:
        assert e.status == 404

    for i in range(DEFAULT_POD_TIMEOUT):
        ret = apps_api.list_namespaced_stateful_set(namespace=&#39;default&#39;)
        found = False
        for item in ret.items:
            if item.metadata.name == statefulset[&#39;metadata&#39;][&#39;name&#39;]:
                found = True
                break
        if not found:
            break
        time.sleep(DEFAULT_POD_INTERVAL)
    assert not found
    client = get_longhorn_api_client()
    for pod in pod_data:
        # Wait on Pods too, we apparently had timeout issues with them.
        wait_delete_pod(api, pod[&#39;pod_uid&#39;])
        delete_and_wait_pvc(api, pod[&#39;pvc_name&#39;])
        # The StatefulSet tests involve both StorageClass provisioned volumes
        # and our manually created PVs. This checks the status of our PV once
        # the PVC is deleted. If it is Failed, we know it is a PV and we must
        # delete it manually. If it is removed from the system, we can just
        # wait for deletion.
        for i in range(DEFAULT_POD_TIMEOUT):
            ret = api.list_persistent_volume()
            found = False
            for item in ret.items:
                if item.metadata.name == pod[&#39;pv_name&#39;]:
                    if item.status.phase in (&#39;Failed&#39;, &#39;Released&#39;):
                        delete_and_wait_pv(api, pod[&#39;pv_name&#39;])
                        delete_and_wait_longhorn(client, pod[&#39;pv_name&#39;])
                    else:
                        found = True
                        break
            if not found:
                break
            time.sleep(DEFAULT_POD_INTERVAL)
        assert not found
        wait_for_volume_delete(client, pod[&#39;pv_name&#39;])</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_and_wait_volume_attachment"><code class="name flex">
<span>def <span class="ident">delete_and_wait_volume_attachment</span></span>(<span>storage_api, volume_attachment_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_and_wait_volume_attachment(storage_api, volume_attachment_name):
    try:
        storage_api.delete_volume_attachment(
            name=volume_attachment_name
        )
    except ApiException as e:
        assert e.status == 404

    wait_delete_volume_attachment(storage_api, volume_attachment_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_backup"><code class="name flex">
<span>def <span class="ident">delete_backup</span></span>(<span>client, bv, backup_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_backup(client, bv, backup_name):
    bv.backupDelete(name=backup_name)
    wait_for_backup_delete(client, bv.volumeName, backup_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_backup_backing_image"><code class="name flex">
<span>def <span class="ident">delete_backup_backing_image</span></span>(<span>client, backing_image_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_backup_backing_image(client, backing_image_name):
    bbi = client.by_id_backupBackingImage(backing_image_name)
    client.delete(bbi)
    wait_for_backup_backing_image_delete(client, backing_image_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_backup_volume"><code class="name flex">
<span>def <span class="ident">delete_backup_volume</span></span>(<span>client, backup_volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_backup_volume(client, backup_volume_name):
    bv = client.by_id_backupVolume(backup_volume_name)
    client.delete(bv)
    wait_for_backup_volume_delete(client, backup_volume_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_crypto_secret"><code class="name flex">
<span>def <span class="ident">delete_crypto_secret</span></span>(<span>namespace, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_crypto_secret(namespace, name):
    api = get_core_api_client()
    try:
        api.delete_namespaced_secret(namespace=namespace, name=name)
    except ApiException as e:
        assert e.status == 404</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_replica_on_test_node"><code class="name flex">
<span>def <span class="ident">delete_replica_on_test_node</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_replica_on_test_node(client, volume_name): # NOQA

    lht_host_id = get_self_host_id()

    volume = client.by_id_volume(volume_name)
    for replica in volume.replicas:
        if replica.hostId == lht_host_id:
            replica_name = replica.name
    volume.replicaRemove(name=replica_name)
    wait_for_volume_degraded(client, volume_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_replica_processes"><code class="name flex">
<span>def <span class="ident">delete_replica_processes</span></span>(<span>client, api, volname)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_replica_processes(client, api, volname):
    replica_map = {}
    volume = client.by_id_volume(volname)
    for r in volume.replicas:
        replica_map[r.instanceManagerName] = r.name

    for rm_name, r_name in replica_map.items():
        delete_command = &#39;longhorn-instance-manager process delete &#39; + \
                         &#39;--name &#39; + r_name
        exec_instance_manager(api, rm_name, delete_command)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_statefulset"><code class="name flex">
<span>def <span class="ident">delete_statefulset</span></span>(<span>apps_api, statefulset)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_statefulset(apps_api, statefulset):
    ss_name = statefulset[&#39;metadata&#39;][&#39;name&#39;]
    ss_namespace = statefulset[&#39;metadata&#39;][&#39;namespace&#39;]
    apps_api.delete_namespaced_stateful_set(
        name=ss_name, namespace=ss_namespace,
        body=k8sclient.V1DeleteOptions()
    )

    for _ in range(DEFAULT_POD_TIMEOUT):
        ret = apps_api.list_namespaced_stateful_set(namespace=ss_namespace)
        found = False
        for item in ret.items:
            if item.metadata.name == ss_name:
                found = True
                break
        if not found:
            break
        time.sleep(DEFAULT_POD_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_storage_class"><code class="name flex">
<span>def <span class="ident">delete_storage_class</span></span>(<span>sc_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_storage_class(sc_name):
    api = get_storage_api_client()
    try:
        api.delete_storage_class(sc_name, body=k8sclient.V1DeleteOptions())
    except ApiException as e:
        assert e.status == 404</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.delete_support_bundle"><code class="name flex">
<span>def <span class="ident">delete_support_bundle</span></span>(<span>node_id, name, client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_support_bundle(node_id, name, client):
    url = get_support_bundle_url(client)
    support_bundle_url = &#39;{}/{}/{}&#39;.format(url, node_id, name)
    return requests.delete(support_bundle_url)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.dev_read"><code class="name flex">
<span>def <span class="ident">dev_read</span></span>(<span>dev, start, count)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dev_read(dev, start, count):
    r_data = &#34;&#34;
    fdev = open(dev, &#39;rb&#39;)
    if fdev is not None:
        fdev.seek(start)
        r_data = fdev.read(count)
        fdev.close()
    return r_data</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.dev_write"><code class="name flex">
<span>def <span class="ident">dev_write</span></span>(<span>dev, start, data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dev_write(dev, start, data):
    data = bytes(data, encoding=&#39;utf-8&#39;)
    w_length = 0
    fdev = open(dev, &#39;rb+&#39;)
    if fdev is not None:
        fdev.seek(start)
        fdev.write(data)
        fdev.close()
        w_length = len(data)
    return w_length</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.disable_auto_salvage"><code class="name flex">
<span>def <span class="ident">disable_auto_salvage</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def disable_auto_salvage(client):
    auto_salvage_setting = client.by_id_setting(SETTING_AUTO_SALVAGE)
    setting = client.update(auto_salvage_setting, value=&#34;false&#34;)

    assert setting.name == SETTING_AUTO_SALVAGE
    assert setting.value == &#34;false&#34;

    yield

    auto_salvage_setting = client.by_id_setting(SETTING_AUTO_SALVAGE)
    setting = client.update(auto_salvage_setting, value=&#34;true&#34;)

    assert setting.name == SETTING_AUTO_SALVAGE
    assert setting.value == &#34;true&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.download_support_bundle"><code class="name flex">
<span>def <span class="ident">download_support_bundle</span></span>(<span>node_id, name, client, target_path='')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_support_bundle(node_id, name, client, target_path=&#34;&#34;):  # NOQA
    url = get_support_bundle_url(client)
    support_bundle_url = &#39;{}/{}/{}&#39;.format(url, node_id, name)
    download_url = &#39;{}/download&#39;.format(support_bundle_url)
    r = requests.get(download_url, allow_redirects=True, timeout=300)
    r.raise_for_status()

    if target_path != &#34;&#34;:
        with open(target_path, &#39;wb&#39;) as f:
            f.write(r.content)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.enable_default_disk"><code class="name flex">
<span>def <span class="ident">enable_default_disk</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def enable_default_disk(client):
    lht_hostId = get_self_host_id()
    node = client.by_id_node(lht_hostId)
    disks = get_update_disks(node.disks)
    for disk in disks.values():
        if disk[&#34;path&#34;] == DEFAULT_DISK_PATH:
            disk.allowScheduling = True
            disk.evictionRequested = False

    update_node_disks(client, node.name, disks=disks, retry=True)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.exec_command_in_pod"><code class="name flex">
<span>def <span class="ident">exec_command_in_pod</span></span>(<span>api, command, pod_name, namespace, container=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exec_command_in_pod(api, command, pod_name, namespace, container=None):
    &#34;&#34;&#34;
    Execute command in the pod.
    Args:
        api: An instance of CoreV1API.
        pod_name: The name of the Pod.
        command: The command to execute in the pod.
        namespace: The namespace where the pod exists.
    Returns:
        The output of the command.
    &#34;&#34;&#34;
    exec_command = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        command
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream read/write&#39;):
        return stream(
            api.connect_get_namespaced_pod_exec, pod_name, namespace,
            command=exec_command, stderr=True, stdin=False, stdout=True,
            container=container, tty=False)</code></pre>
</details>
<div class="desc"><p>Execute command in the pod.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>api</code></strong></dt>
<dd>An instance of CoreV1API.</dd>
<dt><strong><code>pod_name</code></strong></dt>
<dd>The name of the Pod.</dd>
<dt><strong><code>command</code></strong></dt>
<dd>The command to execute in the pod.</dd>
<dt><strong><code>namespace</code></strong></dt>
<dd>The namespace where the pod exists.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The output of the command.</p></div>
</dd>
<dt id="tests.common.exec_instance_manager"><code class="name flex">
<span>def <span class="ident">exec_instance_manager</span></span>(<span>api, im_name, cmd)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exec_instance_manager(api, im_name, cmd):
    exec_cmd = [&#39;/bin/sh&#39;, &#39;-c&#39;, cmd]

    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream read&#39;):
        output = stream(api.connect_get_namespaced_pod_exec,
                        im_name,
                        LONGHORN_NAMESPACE, command=exec_cmd,
                        stderr=True, stdin=False, stdout=True, tty=False)
        return output</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.exec_local"><code class="name flex">
<span>def <span class="ident">exec_local</span></span>(<span>cmd)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exec_local(cmd):
    exec_cmd = cmd.split()
    return subprocess.check_output(exec_cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.exec_nsenter"><code class="name flex">
<span>def <span class="ident">exec_nsenter</span></span>(<span>cmd, process_name=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exec_nsenter(cmd, process_name=None):
    if process_name:
        proc_pid = find_process_pid(process_name)
        cmd_parts = cmd.split()
    else:
        proc_pid = find_dockerd_pid() or &#34;1&#34;
        cmd_parts = [&#34;bash&#34;, &#34;-c&#34;, cmd]

    exec_cmd = [&#34;nsenter&#34;, &#34;--mount=/host/proc/{}/ns/mnt&#34;.format(proc_pid),
                &#34;--net=/host/proc/{}/ns/net&#34;.format(proc_pid)]
    exec_cmd.extend(cmd_parts)
    return subprocess.check_output(exec_cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.expand_and_wait_for_pvc"><code class="name flex">
<span>def <span class="ident">expand_and_wait_for_pvc</span></span>(<span>api, pvc, size)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expand_and_wait_for_pvc(api, pvc, size):
    pvc[&#39;spec&#39;][&#39;resources&#39;] = {
        &#39;requests&#39;: {
            &#39;storage&#39;: size_to_string(size)
        }
    }

    pvc_name = pvc[&#39;metadata&#39;][&#39;name&#39;]
    api.patch_namespaced_persistent_volume_claim(
        pvc_name, &#39;default&#39;, pvc)
    complete = False
    for i in range(RETRY_COUNTS_LONG):
        claim = api.read_namespaced_persistent_volume_claim(
            name=pvc_name, namespace=&#39;default&#39;)
        if claim.spec.resources.requests[&#39;storage&#39;] ==\
                claim.status.capacity[&#39;storage&#39;]:
            complete = True
            break
        time.sleep(RETRY_INTERVAL_LONG)
    assert complete
    return claim</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.fail_replica_expansion"><code class="name flex">
<span>def <span class="ident">fail_replica_expansion</span></span>(<span>client, api, volname, size, replicas=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fail_replica_expansion(client, api, volname, size, replicas=None):
    if replicas is None:
        volume = client.by_id_volume(volname)
        replicas = volume.replicas

    for r in replicas:
        tmp_meta_file_name = \
            EXPANSION_SNAP_TMP_META_NAME_PATTERN % size
        # os.path.join() cannot deal with the path containing &#34;/&#34;
        cmd = [
            &#39;/bin/sh&#39;, &#39;-c&#39;,
            &#39;mkdir %s &amp;&amp; sync&#39; %
            (INSTANCE_MANAGER_HOST_PATH_PREFIX + r.dataPath +
             &#34;/&#34; + tmp_meta_file_name)
        ]
        if not r.instanceManagerName:
            raise Exception(
                &#34;Should use replica objects in the running volume,&#34;
                &#34;otherwise the field r.instanceManagerName is empty&#34;)
        stream(api.connect_get_namespaced_pod_exec,
               r.instanceManagerName,
               LONGHORN_NAMESPACE, command=cmd,
               stderr=True, stdin=False, stdout=True, tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.find_ancestor_process_by_name"><code class="name flex">
<span>def <span class="ident">find_ancestor_process_by_name</span></span>(<span>ancestor_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_ancestor_process_by_name(ancestor_name):
    p = find_self()
    while True:
        if not p or p[&#34;Pid&#34;] == &#34;1&#34;:
            break
        if p[&#34;Name&#34;] == ancestor_name:
            return p[&#34;Pid&#34;]
        p = get_process_info(&#34;/host/proc/{}/status&#34;.format(p[&#34;PPid&#34;]))
    return</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.find_backup"><code class="name flex">
<span>def <span class="ident">find_backup</span></span>(<span>client, vol_name, snap_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_backup(client, vol_name, snap_name):
    &#34;&#34;&#34;
    find_backup will look for a backup on the backupstore
    it&#39;s important to note, that this can only be used for completed backups
    since the backup.cfg will only be written once a backup operation has
    been completed successfully
    &#34;&#34;&#34;

    bv = None
    for i in range(120):
        if bv is None:
            bv = find_backup_volume(client, vol_name)
        if bv is not None:
            backups = bv.backupList().data
            for b in backups:
                if b.snapshotName == snap_name:
                    return bv, b
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert False, &#34;failed to find backup for snapshot &#34; + snap_name + \
                  &#34; for volume &#34; + vol_name</code></pre>
</details>
<div class="desc"><p>find_backup will look for a backup on the backupstore
it's important to note, that this can only be used for completed backups
since the backup.cfg will only be written once a backup operation has
been completed successfully</p></div>
</dd>
<dt id="tests.common.find_backup_volume"><code class="name flex">
<span>def <span class="ident">find_backup_volume</span></span>(<span>client, volume_name, retry=1)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_backup_volume(client, volume_name, retry=1):
    for _ in range(retry):
        bvs = client.list_backupVolume()
        for bv in bvs:
            volumeName = getattr(bv, &#39;volumeName&#39;, bv.name)
            if volumeName == volume_name and bv.created != &#34;&#34;:
                return bv
        time.sleep(RETRY_BACKUP_INTERVAL)
    return None</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.find_dockerd_pid"><code class="name flex">
<span>def <span class="ident">find_dockerd_pid</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_dockerd_pid():
    return find_ancestor_process_by_name(&#34;dockerd&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.find_process_pid"><code class="name flex">
<span>def <span class="ident">find_process_pid</span></span>(<span>process_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_process_pid(process_name):
    for file in os.listdir(HOST_PROC_DIR):
        if not os.path.isdir(os.path.join(HOST_PROC_DIR, file)):
            continue

        # Check if file name is an integer
        if not file.isdigit():
            continue

        with open(os.path.join(HOST_PROC_DIR, file, &#39;status&#39;), &#39;r&#39;) as file:
            status_content = file.readlines()

        proc_status_content = None
        name_pattern = re.compile(r&#39;^Name:\s+(.+)$&#39;)

        for line in status_content:
            name_match = name_pattern.match(line)
            if name_match and name_match.group(1) == process_name:
                proc_status_content = status_content
                break

        if proc_status_content is None:
            continue

        pid_pattern = re.compile(r&#39;^Pid:\s+(\d+)$&#39;)

        for line in proc_status_content:
            pid_match = pid_pattern.match(line)
            if pid_match:
                return int(pid_match.group(1))

    raise Exception(f&#34;Failed to find the {process_name} PID&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.find_replica_for_backup"><code class="name flex">
<span>def <span class="ident">find_replica_for_backup</span></span>(<span>client, volume_name, backup_id)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_replica_for_backup(client, volume_name, backup_id):
    replica_name = None
    for _ in range(RETRY_EXEC_COUNTS):
        volume = client.by_id_volume(volume_name)
        for status in volume.backupStatus:
            if status.id == backup_id:
                replica_name = status.replica
        if replica_name:
            return replica_name
        else:
            time.sleep(RETRY_BACKUP_INTERVAL)
    assert replica_name</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.find_self"><code class="name flex">
<span>def <span class="ident">find_self</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_self():
    return get_process_info(&#34;/host/proc/self/status&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.fix_replica_expansion_failure"><code class="name flex">
<span>def <span class="ident">fix_replica_expansion_failure</span></span>(<span>client, api, volname, size, replicas=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fix_replica_expansion_failure(client, api, volname, size, replicas=None):
    if replicas is None:
        volume = client.by_id_volume(volname)
        replicas = volume.replicas

    for r in replicas:
        if not r.instanceManagerName:
            raise Exception(
                &#34;Should use replica objects in the running volume,&#34;
                &#34;otherwise the field r.instanceManagerName is empty&#34;)

        tmp_meta_file_name = \
            EXPANSION_SNAP_TMP_META_NAME_PATTERN % size
        tmp_meta_file_path = \
            INSTANCE_MANAGER_HOST_PATH_PREFIX + \
            r.dataPath + &#34;/&#34; + tmp_meta_file_name

        removed = False
        for i in range(RETRY_COMMAND_COUNT):
            # os.path.join() cannot deal with the path containing &#34;/&#34;
            cmd = [
                &#39;/bin/sh&#39;, &#39;-c&#39;,
                &#39;rm -rf %s &amp;&amp; sync&#39; % tmp_meta_file_path
            ]
            stream(api.connect_get_namespaced_pod_exec,
                   r.instanceManagerName,
                   LONGHORN_NAMESPACE, command=cmd,
                   stderr=True, stdin=False, stdout=True, tty=False)
            cmd = [&#39;/bin/sh&#39;, &#39;-c&#39;, &#39;ls %s&#39; % tmp_meta_file_path]
            output = stream(
                api.connect_get_namespaced_pod_exec,
                r.instanceManagerName, LONGHORN_NAMESPACE, command=cmd,
                stderr=True, stdin=False, stdout=True, tty=False)
            if &#34;No such file or directory&#34; in output:
                removed = True
                break
            time.sleep(RETRY_INTERVAL_LONG)
        assert removed</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.generate_attachment_ticket_id"><code class="name flex">
<span>def <span class="ident">generate_attachment_ticket_id</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_attachment_ticket_id():
    return ATTACHMENT_TICKET_ID_PREFIX + &#34;-&#34; + \
           &#39;&#39;.join(random.choice(string.ascii_lowercase + string.digits)
                   for _ in range(6))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.generate_pod_with_pvc_manifest"><code class="name flex">
<span>def <span class="ident">generate_pod_with_pvc_manifest</span></span>(<span>pod_name, pvc_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_pod_with_pvc_manifest(pod_name, pvc_name):
    pod_manifest = {
        &#34;apiVersion&#34;: &#34;v1&#34;,
        &#34;kind&#34;: &#34;Pod&#34;,
        &#34;metadata&#34;: {
           &#34;name&#34;: pod_name,
           &#34;namespace&#34;: &#34;default&#34;
        },
        &#34;spec&#34;: {
           &#34;containers&#34;: [
              {
                 &#34;name&#34;: &#34;volume-test&#34;,
                 &#34;image&#34;: &#34;nginx:stable-alpine&#34;,
                 &#34;imagePullPolicy&#34;: &#34;IfNotPresent&#34;,
                 &#34;volumeMounts&#34;: [
                    {
                       &#34;name&#34;: &#34;volv&#34;,
                       &#34;mountPath&#34;: &#34;/data&#34;
                    }
                 ],
                 &#34;ports&#34;: [
                    {
                       &#34;containerPort&#34;: 80
                    }
                 ]
              }
           ],
           &#34;volumes&#34;: [
              {
                 &#34;name&#34;: &#34;volv&#34;,
                 &#34;persistentVolumeClaim&#34;: {
                    &#34;claimName&#34;: pvc_name
                 }
              }
           ]
        }
    }

    return pod_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.generate_random_data"><code class="name flex">
<span>def <span class="ident">generate_random_data</span></span>(<span>count)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_random_data(count):
    return &#39;&#39;.join(random.choice(string.ascii_lowercase + string.digits)
                   for _ in range(count))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.generate_random_pos"><code class="name flex">
<span>def <span class="ident">generate_random_pos</span></span>(<span>size, used={})</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_random_pos(size, used={}):
    for i in range(RETRY_COUNTS):
        pos = 0
        if int(SIZE) != size:
            pos = random.randrange(0, int(SIZE)-size, 1)
        collided = False
        # it&#39;s [start, end) vs [pos, pos + size)
        for start, end in used.items():
            if pos + size &lt;= start or pos &gt;= end:
                continue
            collided = True
            break
        if not collided:
            break
    assert not collided
    used[pos] = pos + size
    return pos</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.generate_random_suffix"><code class="name flex">
<span>def <span class="ident">generate_random_suffix</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_random_suffix():
    return &#34;-&#34; + &#39;&#39;.join(random.choice(string.ascii_lowercase + string.digits)
                         for _ in range(6))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.generate_sts_name"><code class="name flex">
<span>def <span class="ident">generate_sts_name</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_sts_name():
    return STATEFULSET_NAME + &#34;-&#34; + \
        &#39;&#39;.join(random.choice(string.ascii_lowercase + string.digits)
                for _ in range(6))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.generate_support_bundle"><code class="name flex">
<span>def <span class="ident">generate_support_bundle</span></span>(<span>case_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_support_bundle(case_name):  # NOQA
    &#34;&#34;&#34;
        Generate support bundle into folder ./support_bundle/case_name.zip

        Won&#39;t generate support bundle if current support bundle count
        greater than MAX_SUPPORT_BINDLE_NUMBER.
        Args:
            case_name: support bundle will named case_name.zip
    &#34;&#34;&#34;

    os.makedirs(&#34;support_bundle&#34;, exist_ok=True)
    file_cnt = len(os.listdir(&#34;support_bundle&#34;))

    if file_cnt &gt;= MAX_SUPPORT_BINDLE_NUMBER:
        warnings.warn(&#34;Ignoring the bundle download because of \
                            avoiding overwhelming the disk usage.&#34;)
        return

    # Use API gen support bundle
    client = get_longhorn_api_client()
    cleanup_all_support_bundles(client)

    url = client._url.replace(&#39;schemas&#39;, &#39;supportbundles&#39;)
    data = {&#39;description&#39;: case_name, &#39;issueURL&#39;: case_name}
    try:
        res_raw = requests.post(url, json=data)
        res_raw.raise_for_status()
        res = res_raw.json()
    except Exception as e:
        warnings.warn(f&#34;Error while generating support bundle: {e}&#34;)
        return
    id = res[&#39;id&#39;]
    name = res[&#39;name&#39;]

    support_bundle_url = &#39;{}/{}/{}&#39;.format(url, id, name)
    for i in range(RETRY_EXEC_COUNTS):
        res = requests.get(support_bundle_url).json()

        if res[&#39;progressPercentage&#39;] == 100:
            break
        else:
            time.sleep(RETRY_INTERVAL_LONG)

    if res[&#39;progressPercentage&#39;] != 100:
        warnings.warn(&#34;Timeout to wait support bundle ready, skip download&#34;)
        return

    # Download support bundle
    download_url = &#39;{}/download&#39;.format(support_bundle_url)
    try:
        r = requests.get(download_url, allow_redirects=True, timeout=300)
        r.raise_for_status()
        with open(&#39;./support_bundle/{0}.zip&#39;.format(case_name), &#39;wb&#39;) as f:
            f.write(r.content)
    except Exception as e:
        warnings.warn(&#34;Error occurred when downloading support bundle {}.zip\n\
            The error was {}&#34;.format(case_name, e))</code></pre>
</details>
<div class="desc"><p>Generate support bundle into folder ./support_bundle/case_name.zip</p>
<p>Won't generate support bundle if current support bundle count
greater than MAX_SUPPORT_BINDLE_NUMBER.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>case_name</code></strong></dt>
<dd>support bundle will named case_name.zip</dd>
</dl></div>
</dd>
<dt id="tests.common.generate_volume_name"><code class="name flex">
<span>def <span class="ident">generate_volume_name</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_volume_name():
    return VOLUME_NAME + &#34;-&#34; + \
        &#39;&#39;.join(random.choice(string.ascii_lowercase + string.digits)
                for _ in range(6))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_all_support_bundle_manager_deployments"><code class="name flex">
<span>def <span class="ident">get_all_support_bundle_manager_deployments</span></span>(<span>apps_api)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_support_bundle_manager_deployments(apps_api):  # NOQA
    name_prefix = &#39;longhorn-support-bundle-manager&#39;
    support_bundle_managers = []

    deployments = apps_api.list_namespaced_deployment(LONGHORN_NAMESPACE)
    for deployment in deployments.items:
        if deployment.metadata.name.startswith(name_prefix):
            support_bundle_managers.append(deployment)

    return support_bundle_managers</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_apps_api_client"><code class="name flex">
<span>def <span class="ident">get_apps_api_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_apps_api_client():
    load_k8s_config()
    return k8sclient.AppsV1Api()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_backupstore_poll_interval"><code class="name flex">
<span>def <span class="ident">get_backupstore_poll_interval</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_backupstore_poll_interval():
    poll_interval = os.environ.get(&#34;LONGHORN_BACKUPSTORE_POLL_INTERVAL&#34;, &#34;&#34;)
    assert len(poll_interval) != 0
    return poll_interval</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_backupstore_url"><code class="name flex">
<span>def <span class="ident">get_backupstore_url</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_backupstore_url():
    backupstore = os.environ.get(&#34;LONGHORN_BACKUPSTORES&#34;, &#34;&#34;)
    backupstore = backupstore.replace(&#34; &#34;, &#34;&#34;)
    backupstores = backupstore.split(&#34;,&#34;)

    assert len(backupstores) != 0
    return backupstores</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_backupstores"><code class="name flex">
<span>def <span class="ident">get_backupstores</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_backupstores():
    backupstore = os.environ.get(&#34;LONGHORN_BACKUPSTORES&#34;, &#34;&#34;)

    try:
        backupstore = backupstore.replace(&#34; &#34;, &#34;&#34;)
        backupstores = backupstore.split(&#34;,&#34;)
        for i in range(len(backupstores)):
            backupstores[i] = backupstores[i].split(&#34;:&#34;)[0]
    except ValueError:
        backupstores = backupstore.split(&#34;:&#34;)[0]
    return backupstores</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_client"><code class="name flex">
<span>def <span class="ident">get_client</span></span>(<span>address_with_port)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_client(address_with_port):
    # Split IP and port
    if address_with_port.count(&#39;:&#39;) &gt; 1:
        ip_part, port = address_with_port.rsplit(&#39;:&#39;, 1)
        ip = ipaddress.ip_address(ip_part)
        if ip.version == 6:
            formatted_address = f&#34;[{ip_part}]:{port}&#34;
        else:
            formatted_address = f&#34;{ip_part}:{port}&#34;
    else:
        formatted_address = address_with_port

    url = f&#39;http://{formatted_address}/v1/schemas&#39;
    c = longhorn.from_env(url=url)
    return c</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_clients"><code class="name flex">
<span>def <span class="ident">get_clients</span></span>(<span>hosts)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_clients(hosts):
    clients = {}
    for host in hosts:
        assert host.name is not None
        assert host.address is not None
        clients[host.name] = get_client(host.address + PORT)
    return clients</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_clone_volume_name"><code class="name flex">
<span>def <span class="ident">get_clone_volume_name</span></span>(<span>client, source_volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_clone_volume_name(client, source_volume_name):
    for _ in range(RETRY_EXEC_COUNTS):
        volumes = client.list_volume()
        for volume in volumes:
            if volume[&#39;cloneStatus&#39;][&#39;sourceVolume&#39;] == \
                    source_volume_name:
                return volume.name
        time.sleep(RETRY_INTERVAL_LONG)
    return None</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_compatibility_test_image"><code class="name flex">
<span>def <span class="ident">get_compatibility_test_image</span></span>(<span>cli_v, cli_minv, ctl_v, ctl_minv, data_v, data_minv)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_compatibility_test_image(cli_v, cli_minv,
                                 ctl_v, ctl_minv,
                                 data_v, data_minv):
    return &#34;%s.%d-%d.%d-%d.%d-%d&#34; % (COMPATIBILTY_TEST_IMAGE_PREFIX,
                                     cli_v, cli_minv,
                                     ctl_v, ctl_minv,
                                     data_v, data_minv)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_core_api_client"><code class="name flex">
<span>def <span class="ident">get_core_api_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_core_api_client():
    load_k8s_config()
    return k8sclient.CoreV1Api()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_custom_object_api_client"><code class="name flex">
<span>def <span class="ident">get_custom_object_api_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_custom_object_api_client():
    load_k8s_config()
    return k8sclient.CustomObjectsApi()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_default_engine_image"><code class="name flex">
<span>def <span class="ident">get_default_engine_image</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_default_engine_image(client):
    images = client.list_engine_image()
    for img in images:
        if img.default:
            return img
    assert False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_deployment_pod_names"><code class="name flex">
<span>def <span class="ident">get_deployment_pod_names</span></span>(<span>core_api, deployment)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_deployment_pod_names(core_api, deployment):
    label_selector = \
        &#34;name=&#34; + deployment[&#34;metadata&#34;][&#34;labels&#34;][&#34;name&#34;]
    deployment_pod_list = \
        core_api.list_namespaced_pod(namespace=&#34;default&#34;,
                                     label_selector=label_selector)
    pod_names = []
    for pod in deployment_pod_list.items:
        pod_names.append(pod.metadata.name)
    return pod_names</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_device_checksum"><code class="name flex">
<span>def <span class="ident">get_device_checksum</span></span>(<span>dev)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_device_checksum(dev):
    hash = hashlib.sha512()

    with open(dev, &#39;rb&#39;) as fdev:
        if fdev is not None:
            for chunk in iter(lambda: fdev.read(4096), b&#34;&#34;):
                hash.update(chunk)

    return hash.hexdigest()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_disk_uuid"><code class="name flex">
<span>def <span class="ident">get_disk_uuid</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_disk_uuid():

    f = open(os.path.join(DEFAULT_DISK_PATH, &#39;longhorn-disk.cfg&#39;))
    data = json.load(f)

    return data[&#34;diskUUID&#34;]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_engine_host_id"><code class="name flex">
<span>def <span class="ident">get_engine_host_id</span></span>(<span>client, vol_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_engine_host_id(client, vol_name):
    volume = client.by_id_volume(vol_name)

    engines = volume.controllers
    if len(engines) != 1:
        return

    return engines[0].hostId</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_engine_image_status_value"><code class="name flex">
<span>def <span class="ident">get_engine_image_status_value</span></span>(<span>client, ei_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_engine_image_status_value(client, ei_name):
    if hasattr(client.by_id_engine_image(ei_name), &#34;nodeDeploymentMap&#34;):
        return &#34;deployed&#34;
    else:
        return &#34;ready&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_host_disk_size"><code class="name flex">
<span>def <span class="ident">get_host_disk_size</span></span>(<span>disk)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_host_disk_size(disk):
    cmd = [&#39;stat&#39;, &#39;-fc&#39;,
           &#39;{&#34;path&#34;:&#34;%n&#34;,&#34;fsid&#34;:&#34;%i&#34;,&#34;type&#34;:&#34;%T&#34;,&#34;freeBlock&#34;:%f,&#39;
           &#39;&#34;totalBlock&#34;:%b,&#34;blockSize&#34;:%S}&#39;,
           disk]
    # As the disk available storage is rounded off to 100Mb
    truncate_to = 100 * 1024 * 1024
    output = subprocess.check_output(cmd)
    disk_info = json.loads(output)
    block_size = disk_info[&#34;blockSize&#34;]
    free_blk = disk_info[&#34;freeBlock&#34;]
    total_blk = disk_info[&#34;totalBlock&#34;]
    free = int((free_blk * block_size) / truncate_to) * truncate_to
    total = (total_blk * block_size)
    return free, total</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_host_replica_count"><code class="name flex">
<span>def <span class="ident">get_host_replica_count</span></span>(<span>client, volume_name, host_id, chk_running=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_host_replica_count(client, volume_name, host_id, chk_running=False):
    volume = client.by_id_volume(volume_name)

    replica_count = 0
    for replica in volume.replicas:
        if chk_running and not replica.running:
            continue
        if replica.hostId == host_id:
            replica_count += 1
    return replica_count</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_instance_manager_names"><code class="name flex">
<span>def <span class="ident">get_instance_manager_names</span></span>(<span>client, data_engine='v1')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_instance_manager_names(client, data_engine=DATA_ENGINE):
    ims = client.list_instance_manager()
    result = []

    for im in ims:
        if im.dataEngine == data_engine:
            result.append(im.name)
    return result</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_iscsi_ip"><code class="name flex">
<span>def <span class="ident">get_iscsi_ip</span></span>(<span>iscsi)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_iscsi_ip(iscsi):
    parsed = urlparse(iscsi)
    return parsed.hostname</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_iscsi_lun"><code class="name flex">
<span>def <span class="ident">get_iscsi_lun</span></span>(<span>iscsi)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_iscsi_lun(iscsi):
    iscsi_endpoint = parse_iscsi_endpoint(iscsi)
    return iscsi_endpoint[2]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_iscsi_port"><code class="name flex">
<span>def <span class="ident">get_iscsi_port</span></span>(<span>iscsi)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_iscsi_port(iscsi):
    parsed = urlparse(iscsi)
    return parsed.port</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_iscsi_target"><code class="name flex">
<span>def <span class="ident">get_iscsi_target</span></span>(<span>iscsi)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_iscsi_target(iscsi):
    iscsi_endpoint = parse_iscsi_endpoint(iscsi)
    return iscsi_endpoint[1]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_k8s_zone_label"><code class="name flex">
<span>def <span class="ident">get_k8s_zone_label</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_k8s_zone_label():
    ver_api = get_version_api_client()
    k8s_ver_data = ver_api.get_code()

    k8s_ver_major = k8s_ver_data.major
    assert k8s_ver_major == &#39;1&#39;

    k8s_ver_minor = k8s_ver_data.minor

    # k8s_ver_minor no needs to be an int
    # it could be &#34;24+&#34; in eks
    if int(re.sub(&#39;\\D&#39;, &#39;&#39;, k8s_ver_minor)) &gt;= 17:
        k8s_zone_label = K8S_ZONE_LABEL
    else:
        k8s_zone_label = DEPRECATED_K8S_ZONE_LABEL

    return k8s_zone_label</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_liveness_probe_spec"><code class="name flex">
<span>def <span class="ident">get_liveness_probe_spec</span></span>(<span>initial_delay=5, period=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_liveness_probe_spec(initial_delay=5, period=5):
    pod_liveness_probe_spec = {
        &#34;exec&#34;: {
            &#34;command&#34;: [
                &#34;ls&#34;,
                &#34;/data/lost+found&#34;
            ]
        },
        &#34;initialDelaySeconds&#34;: initial_delay,
        &#34;periodSeconds&#34;: period
    }

    return pod_liveness_probe_spec</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_longhorn_api_client"><code class="name flex">
<span>def <span class="ident">get_longhorn_api_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_longhorn_api_client():
    for _ in range(RETRY_COUNTS):
        try:
            k8sconfig.load_incluster_config()
            ips = get_mgr_ips()

            # check if longhorn manager port is open before calling get_client
            for ip in ips:
                # Determine if IP is IPv6
                family = socket.AF_INET6 if &#39;:&#39; in ip else socket.AF_INET
                sock = socket.socket(family, socket.SOCK_STREAM)
                sock.settimeout(RETRY_COUNTS_SHORT)

                try:
                    if sock.connect_ex((ip, 9500)) == 0:
                        return get_client(ip + PORT)
                finally:
                    sock.close()
        except Exception:
            time.sleep(RETRY_INTERVAL)

    raise Exception(&#34;Failed to get Longhorn API client after retries&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_mgr_ips"><code class="name flex">
<span>def <span class="ident">get_mgr_ips</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mgr_ips():
    ret = k8sclient.CoreV1Api().list_pod_for_all_namespaces(
            label_selector=&#34;app=longhorn-manager&#34;,
            watch=False)
    mgr_ips = []
    for i in ret.items:
        mgr_ips.append(i.status.pod_ip)
    return mgr_ips</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_node_by_disk_id"><code class="name flex">
<span>def <span class="ident">get_node_by_disk_id</span></span>(<span>client, disk_id)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_node_by_disk_id(client, disk_id): # NOQA
    nodes = client.list_node()

    for node in nodes:
        disks = node.disks
        for name, disk in iter(disks.items()):
            if disk.diskUUID == disk_id:
                return node
    # should handle empty result in caller
    return &#34;&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_nvmf_ip"><code class="name flex">
<span>def <span class="ident">get_nvmf_ip</span></span>(<span>nvmf)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_nvmf_ip(nvmf):
    nvmf_endpoint = parse_nvmf_endpoint(nvmf)
    return nvmf_endpoint[0].split(&#39;:&#39;)[0]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_nvmf_nqn"><code class="name flex">
<span>def <span class="ident">get_nvmf_nqn</span></span>(<span>nvmf)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_nvmf_nqn(nvmf):
    nvmf_endpoint = parse_nvmf_endpoint(nvmf)
    return nvmf_endpoint[1]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_nvmf_port"><code class="name flex">
<span>def <span class="ident">get_nvmf_port</span></span>(<span>nvmf)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_nvmf_port(nvmf):
    nvmf_endpoint = parse_nvmf_endpoint(nvmf)
    return nvmf_endpoint[0].split(&#39;:&#39;)[1]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_pod_data_md5sum"><code class="name flex">
<span>def <span class="ident">get_pod_data_md5sum</span></span>(<span>api, pod_name, path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pod_data_md5sum(api, pod_name, path):
    md5sum_command = [
        &#39;/bin/sh&#39;, &#39;-c&#39;, &#39;md5sum &#39; + path + &#34; | awk &#39;{print $1}&#39;&#34;
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT * 3,
                 error_message=&#39;Timeout on executing stream md5sum&#39;):
        return stream(
            api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
            command=md5sum_command, stderr=True, stdin=False, stdout=True,
            tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_process_info"><code class="name flex">
<span>def <span class="ident">get_process_info</span></span>(<span>p_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_process_info(p_path):
    info = {}
    with open(p_path) as file:
        for line in file.readlines():
            if &#39;Name:\t&#39; == line[0:len(&#39;Name:\t&#39;)]:
                info[&#34;Name&#34;] = line[len(&#34;Name:&#34;):].strip()
            if &#39;Pid:\t&#39; == line[0:len(&#39;Pid:\t&#39;)]:
                info[&#34;Pid&#34;] = line[len(&#34;Pid:&#34;):].strip()
            if &#39;PPid:\t&#39; == line[0:len(&#39;PPid:\t&#39;)]:
                info[&#34;PPid&#34;] = line[len(&#34;PPid:&#34;):].strip()
    if &#34;Name&#34; not in info or &#34;Pid&#34; not in info or &#34;PPid&#34; not in info:
        return
    return info</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_pv_manifest"><code class="name flex">
<span>def <span class="ident">get_pv_manifest</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pv_manifest(request):
    volume_name = generate_volume_name()
    pv_manifest = {
        &#39;apiVersion&#39;: &#39;v1&#39;,
        &#39;kind&#39;: &#39;PersistentVolume&#39;,
        &#39;metadata&#39;: {
            &#39;name&#39;: volume_name
        },
        &#39;spec&#39;: {
            &#39;capacity&#39;: {
                &#39;storage&#39;: size_to_string(DEFAULT_VOLUME_SIZE * Gi)
            },
            &#39;volumeMode&#39;: &#39;Filesystem&#39;,
            &#39;accessModes&#39;: [&#39;ReadWriteOnce&#39;],
            &#39;persistentVolumeReclaimPolicy&#39;: &#39;Delete&#39;,
            &#39;csi&#39;: {
                &#39;driver&#39;: &#39;driver.longhorn.io&#39;,
                &#39;fsType&#39;: &#39;ext4&#39;,
                &#39;volumeAttributes&#39;: {
                    &#39;numberOfReplicas&#39;:
                        DEFAULT_LONGHORN_PARAMS[&#39;numberOfReplicas&#39;],
                    &#39;staleReplicaTimeout&#39;:
                        DEFAULT_LONGHORN_PARAMS[&#39;staleReplicaTimeout&#39;]
                },
                &#39;volumeHandle&#39;: volume_name
            }
        }
    }

    def finalizer():
        api = get_core_api_client()
        delete_and_wait_pv(api, pv_manifest[&#39;metadata&#39;][&#39;name&#39;])

        client = get_longhorn_api_client()
        delete_and_wait_longhorn(client, pv_manifest[&#39;metadata&#39;][&#39;name&#39;])

    request.addfinalizer(finalizer)

    return pv_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_pvc_manifest"><code class="name flex">
<span>def <span class="ident">get_pvc_manifest</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pvc_manifest(request):
    pvc_manifest = {
        &#39;apiVersion&#39;: &#39;v1&#39;,
        &#39;kind&#39;: &#39;PersistentVolumeClaim&#39;,
        &#39;metadata&#39;: {
            &#39;name&#39;: generate_volume_name()
        },
        &#39;spec&#39;: {
            &#39;accessModes&#39;: [
                &#39;ReadWriteOnce&#39;
            ],
            &#39;resources&#39;: {
                &#39;requests&#39;: {
                    &#39;storage&#39;: size_to_string(DEFAULT_VOLUME_SIZE * Gi)
                }
            }
        }
    }

    def finalizer():
        api = k8sclient.CoreV1Api()

        if not check_pvc_existence(api, pvc_manifest[&#39;metadata&#39;][&#39;name&#39;]):
            return

        claim = api.read_namespaced_persistent_volume_claim(
            name=pvc_manifest[&#39;metadata&#39;][&#39;name&#39;], namespace=&#39;default&#39;)
        volume_name = claim.spec.volume_name

        api = get_core_api_client()
        delete_and_wait_pvc(api, pvc_manifest[&#39;metadata&#39;][&#39;name&#39;])

        # Working around line break issue.
        key = &#39;volume.beta.kubernetes.io/storage-provisioner&#39;
        # If not using StorageClass (such as in CSI test), the Longhorn volume
        # will not be automatically deleted, causing this to throw an error.
        if (key in claim.metadata.annotations):
            client = get_longhorn_api_client()
            wait_for_volume_delete(client, volume_name)

    request.addfinalizer(finalizer)

    return pvc_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_random_client"><code class="name flex">
<span>def <span class="ident">get_random_client</span></span>(<span>clients)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_random_client(clients):
    for _, client in iter(clients.items()):
        break
    return client</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_scheduling_api_client"><code class="name flex">
<span>def <span class="ident">get_scheduling_api_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_scheduling_api_client():
    load_k8s_config()
    return k8sclient.SchedulingV1Api()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_self_host_id"><code class="name flex">
<span>def <span class="ident">get_self_host_id</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_self_host_id():
    return os.environ.get(&#34;NODE_NAME&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_statefulset_pod_info"><code class="name flex">
<span>def <span class="ident">get_statefulset_pod_info</span></span>(<span>api, s_set)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_statefulset_pod_info(api, s_set):
    pod_info = []
    for i in range(s_set[&#39;spec&#39;][&#39;replicas&#39;]):
        pod_name = s_set[&#39;metadata&#39;][&#39;name&#39;] + &#39;-&#39; + str(i)
        pod = api.read_namespaced_pod(name=pod_name, namespace=&#39;default&#39;)
        pvc_name = pod.spec.volumes[0].persistent_volume_claim.claim_name
        pv_name = get_volume_name(api, pvc_name)
        pod_info.append({
            &#39;pod_name&#39;: pod_name,
            &#39;pod_uid&#39;: pod.metadata.uid,
            &#39;pv_name&#39;: pv_name,
            &#39;pvc_name&#39;: pvc_name,
        })
    return pod_info</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_storage_api_client"><code class="name flex">
<span>def <span class="ident">get_storage_api_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_storage_api_client():
    load_k8s_config()
    return k8sclient.StorageV1Api()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_support_bundle"><code class="name flex">
<span>def <span class="ident">get_support_bundle</span></span>(<span>node_id, name, client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_support_bundle(node_id, name, client):  # NOQA
    url = get_support_bundle_url(client)
    resp = requests.get(&#39;{}/{}/{}&#39;.format(url, node_id, name))
    assert resp.status_code == 200
    return resp.json()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_support_bundle_url"><code class="name flex">
<span>def <span class="ident">get_support_bundle_url</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_support_bundle_url(client):  # NOQA
    return client._url.replace(&#39;schemas&#39;, &#39;supportbundles&#39;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_update_disks"><code class="name flex">
<span>def <span class="ident">get_update_disks</span></span>(<span>disks)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_update_disks(disks):
    update_disk = {}
    for key, disk in iter(disks.items()):
        update_disk[key] = disk
    return update_disk</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_upgrade_test_image"><code class="name flex">
<span>def <span class="ident">get_upgrade_test_image</span></span>(<span>cli_v, cli_minv, ctl_v, ctl_minv, data_v, data_minv)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_upgrade_test_image(cli_v, cli_minv,
                           ctl_v, ctl_minv,
                           data_v, data_minv):
    return &#34;%s.%d-%d.%d-%d.%d-%d&#34; % (UPGRADE_TEST_IMAGE_PREFIX,
                                     cli_v, cli_minv,
                                     ctl_v, ctl_minv,
                                     data_v, data_minv)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_version_api_client"><code class="name flex">
<span>def <span class="ident">get_version_api_client</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_version_api_client():
    load_k8s_config()
    return k8sclient.VersionApi()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_volume_dev_mb_data_md5sum"><code class="name flex">
<span>def <span class="ident">get_volume_dev_mb_data_md5sum</span></span>(<span>path, offset_in_mb, length_in_mb)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_volume_dev_mb_data_md5sum(path, offset_in_mb, length_in_mb):
    md5sum_command = [
        &#39;/bin/sh&#39;, &#39;-c&#39;,
        &#39;dd if=%s bs=1M skip=%d count=%d | md5sum&#39; %
        (path, offset_in_mb, length_in_mb)
    ]

    with timeout(seconds=STREAM_EXEC_TIMEOUT * 5,
                 error_message=&#39;Timeout on computing dev md5sum&#39;):
        output = subprocess.check_output(
            md5sum_command).strip().decode(&#39;utf-8&#39;)
        return output.split(&#34; &#34;)[1]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_volume_endpoint"><code class="name flex">
<span>def <span class="ident">get_volume_endpoint</span></span>(<span>v)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_volume_endpoint(v):
    endpoint = check_volume_endpoint(v)
    return endpoint</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_volume_engine"><code class="name flex">
<span>def <span class="ident">get_volume_engine</span></span>(<span>v)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_volume_engine(v):
    engines = v.controllers
    assert len(engines) != 0
    return engines[0]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_volume_name"><code class="name flex">
<span>def <span class="ident">get_volume_name</span></span>(<span>api, pvc_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_volume_name(api, pvc_name):
    # type: (dict) -&gt; str
    &#34;&#34;&#34;
    Given a PersistentVolumeClaim, return the name of the associated PV.
    &#34;&#34;&#34;
    claim = api.read_namespaced_persistent_volume_claim(
        name=pvc_name, namespace=&#39;default&#39;)
    return claim.spec.volume_name</code></pre>
</details>
<div class="desc"><p>Given a PersistentVolumeClaim, return the name of the associated PV.</p></div>
</dd>
<dt id="tests.common.get_volume_recurring_jobs_and_groups"><code class="name flex">
<span>def <span class="ident">get_volume_recurring_jobs_and_groups</span></span>(<span>volume)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_volume_recurring_jobs_and_groups(volume):
    volumeJobs = volume.recurringJobList()
    jobs = []
    groups = []
    for volumeJob in volumeJobs:
        if volumeJob[&#39;isGroup&#39;]:
            groups.append(volumeJob[&#39;name&#39;])
        else:
            jobs.append(volumeJob[&#39;name&#39;])
    return jobs, groups</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.get_volume_running_replica_cnt"><code class="name flex">
<span>def <span class="ident">get_volume_running_replica_cnt</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_volume_running_replica_cnt(client, volume_name):  # NOQA
    nodes = client.list_node()
    cnt = 0

    for node in nodes:
        cnt = cnt + get_host_replica_count(
            client, volume_name, node.name, chk_running=True)

    return cnt</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.is_backupTarget_azurite"><code class="name flex">
<span>def <span class="ident">is_backupTarget_azurite</span></span>(<span>s)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_backupTarget_azurite(s):
    return s.startswith(&#34;azblob://&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.is_backupTarget_cifs"><code class="name flex">
<span>def <span class="ident">is_backupTarget_cifs</span></span>(<span>s)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_backupTarget_cifs(s):
    return s.startswith(&#34;cifs://&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.is_backupTarget_nfs"><code class="name flex">
<span>def <span class="ident">is_backupTarget_nfs</span></span>(<span>s)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_backupTarget_nfs(s):
    return s.startswith(&#34;nfs://&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.is_backupTarget_s3"><code class="name flex">
<span>def <span class="ident">is_backupTarget_s3</span></span>(<span>s)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_backupTarget_s3(s):
    return s.startswith(&#34;s3://&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.is_k8s_node_gke_cos"><code class="name flex">
<span>def <span class="ident">is_k8s_node_gke_cos</span></span>(<span>core_api)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_k8s_node_gke_cos(core_api):
    return is_k8s_node_label(core_api,
                             K8S_GKE_OS_DISTRO_LABEL,
                             K8S_GKE_OS_DISTRO_COS,
                             get_self_host_id())</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.is_k8s_node_label"><code class="name flex">
<span>def <span class="ident">is_k8s_node_label</span></span>(<span>core_api, label_key, label_value, node_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_k8s_node_label(core_api, label_key, label_value, node_name):
    node = core_api.read_node(node_name)

    if label_key in node.metadata.labels:
        if node.metadata.labels[label_key] == label_value:
            return True
    return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.is_replica_available"><code class="name flex">
<span>def <span class="ident">is_replica_available</span></span>(<span>r)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_replica_available(r):
    return r is not None and r.running and not \
        r.failedAt and r.mode == &#39;RW&#39;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.iscsi_login"><code class="name flex">
<span>def <span class="ident">iscsi_login</span></span>(<span>iscsi_ep)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iscsi_login(iscsi_ep):
    ip = get_iscsi_ip(iscsi_ep)
    port = get_iscsi_port(iscsi_ep)
    target = get_iscsi_target(iscsi_ep)
    lun = get_iscsi_lun(iscsi_ep)
    # discovery
    cmd_discovery = &#34;iscsiadm -m discovery -t st -p &#34; + ip
    exec_nsenter(cmd_discovery, ISCSI_PROCESS)
    # login
    cmd_login = &#34;iscsiadm -m node -T &#34; + target + &#34; -p &#34; + ip + &#34; --login&#34;
    exec_nsenter(cmd_login, ISCSI_PROCESS)
    blk_name = &#34;ip-%s:%s-iscsi-%s-lun-%s&#34; % (ip, port, target, lun)
    wait_for_device_login(ISCSI_DEV_PATH, blk_name)
    dev = os.path.realpath(ISCSI_DEV_PATH + &#34;/&#34; + blk_name)
    return dev</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.iscsi_logout"><code class="name flex">
<span>def <span class="ident">iscsi_logout</span></span>(<span>iscsi_ep)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iscsi_logout(iscsi_ep):
    ip = get_iscsi_ip(iscsi_ep)
    target = get_iscsi_target(iscsi_ep)
    cmd_logout = &#34;iscsiadm -m node -T &#34; + target + &#34; -p &#34; + ip + &#34; --logout&#34;
    exec_nsenter(cmd_logout, ISCSI_PROCESS)
    cmd_rm_discovery = &#34;iscsiadm -m discovery -p &#34; + ip + &#34; -o delete&#34;
    exec_nsenter(cmd_rm_discovery, ISCSI_PROCESS)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.json_string_go_to_python"><code class="name flex">
<span>def <span class="ident">json_string_go_to_python</span></span>(<span>str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def json_string_go_to_python(str):
    return str.replace(&#34;u\&#39;&#34;, &#34;\&#34;&#34;).replace(&#34;\&#39;&#34;, &#34;\&#34;&#34;). \
        replace(&#34;True&#34;, &#34;true&#34;).replace(&#34;False&#34;, &#34;false&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.lazy_umount_disk"><code class="name flex">
<span>def <span class="ident">lazy_umount_disk</span></span>(<span>mount_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lazy_umount_disk(mount_path):
    cmd = [&#39;umount&#39;, &#39;-l&#39;, mount_path]
    subprocess.check_call(cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.load_k8s_config"><code class="name flex">
<span>def <span class="ident">load_k8s_config</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_k8s_config():
    c = Configuration()
    c.assert_hostname = False
    Configuration.set_default(c)
    k8sconfig.load_incluster_config()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.make_deployment_cpu_request"><code class="name flex">
<span>def <span class="ident">make_deployment_cpu_request</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def make_deployment_cpu_request(request):
    def _generate_deployment_cpu_request_manifest(deployment_name, cpu_request, replicas=1): # NOQA
        make_deployment_cpu_request.deployment_manifest = {
            &#34;apiVersion&#34;: &#34;apps/v1&#34;,
            &#34;kind&#34;: &#34;Deployment&#34;,
            &#34;metadata&#34;: {
               &#34;name&#34;: deployment_name,
               &#34;labels&#34;: {
                  &#34;name&#34;: deployment_name
               }
            },
            &#34;spec&#34;: {
               &#34;replicas&#34;: replicas,
               &#34;selector&#34;: {
                  &#34;matchLabels&#34;: {
                     &#34;name&#34;: deployment_name
                  }
               },
               &#34;template&#34;: {
                  &#34;metadata&#34;: {
                     &#34;labels&#34;: {
                        &#34;name&#34;: deployment_name
                     }
                  },
                  &#34;spec&#34;: {
                     &#34;containers&#34;: [
                        {
                           &#34;name&#34;: deployment_name,
                           &#34;image&#34;: &#34;nginx:stable-alpine&#34;,
                           &#34;resources&#34;: {
                               &#34;limits&#34;: {
                                   &#34;cpu&#34;: str(cpu_request * 2)+&#34;m&#34;,
                                   &#34;memory&#34;: &#34;30Mi&#34;,
                               },
                               &#34;requests&#34;: {
                                   &#34;cpu&#34;: str(cpu_request)+&#34;m&#34;,
                                   &#34;memory&#34;: &#34;15Mi&#34;,
                               }
                           }
                        }
                     ],
                  }
               }
            }
        }

        return make_deployment_cpu_request.deployment_manifest

    def finalizer():
        apps_api = get_apps_api_client()
        deployment_name = \
            make_deployment_cpu_request.deployment_manifest[&#34;metadata&#34;][&#34;name&#34;]
        delete_and_wait_deployment(
            apps_api,
            deployment_name
        )

    request.addfinalizer(finalizer)

    return _generate_deployment_cpu_request_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.make_deployment_with_pvc"><code class="name flex">
<span>def <span class="ident">make_deployment_with_pvc</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def make_deployment_with_pvc(request):
    def _generate_deployment_with_pvc_manifest(deployment_name, pvc_name, replicas=1): # NOQA
        if not hasattr(make_deployment_with_pvc, &#39;deployment_manifests&#39;):
            make_deployment_with_pvc.deployment_manifests = []
        make_deployment_with_pvc.deployment_manifests.append({
            &#34;apiVersion&#34;: &#34;apps/v1&#34;,
            &#34;kind&#34;: &#34;Deployment&#34;,
            &#34;metadata&#34;: {
               &#34;name&#34;: deployment_name,
               &#34;labels&#34;: {
                  &#34;name&#34;: deployment_name
               }
            },
            &#34;spec&#34;: {
               &#34;replicas&#34;: replicas,
               &#34;selector&#34;: {
                  &#34;matchLabels&#34;: {
                     &#34;name&#34;: deployment_name
                  }
               },
               &#34;template&#34;: {
                  &#34;metadata&#34;: {
                     &#34;labels&#34;: {
                        &#34;name&#34;: deployment_name
                     }
                  },
                  &#34;spec&#34;: {
                     &#34;containers&#34;: [
                        {
                           &#34;name&#34;: deployment_name,
                           &#34;image&#34;: &#34;nginx:stable-alpine&#34;,
                           &#34;volumeMounts&#34;: [
                              {
                                 &#34;name&#34;: &#34;volv&#34;,
                                 &#34;mountPath&#34;: &#34;/data&#34;
                              }
                           ]
                        }
                     ],
                     &#34;volumes&#34;: [
                        {
                           &#34;name&#34;: &#34;volv&#34;,
                           &#34;persistentVolumeClaim&#34;: {
                              &#34;claimName&#34;: pvc_name
                           }
                        }
                     ]
                  }
               }
            }
        })

        return make_deployment_with_pvc.deployment_manifests[-1]

    def finalizer():
        apps_api = get_apps_api_client()
        if not hasattr(make_deployment_with_pvc, &#39;deployment_manifests&#39;):
            return
        for deployment_manifest in \
                make_deployment_with_pvc.deployment_manifests:
            deployment_name = deployment_manifest[&#34;metadata&#34;][&#34;name&#34;]
            delete_and_wait_deployment(
                apps_api,
                deployment_name
            )

    request.addfinalizer(finalizer)

    return _generate_deployment_with_pvc_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.monitor_restore_progress"><code class="name flex">
<span>def <span class="ident">monitor_restore_progress</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def monitor_restore_progress(client, volume_name):
    completed = 0
    rs = {}
    for i in range(RETRY_COUNTS_LONG):
        completed = 0
        v = client.by_id_volume(volume_name)
        rs = v.restoreStatus
        for r in rs:
            assert r.error == &#34;&#34;
            if r.state == &#34;complete&#34;:
                assert r.progress == 100
                completed += 1
        if completed == len(rs):
            break
        time.sleep(RETRY_INTERVAL)
    assert completed == len(rs)
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.mount_disk"><code class="name flex">
<span>def <span class="ident">mount_disk</span></span>(<span>dev, mount_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mount_disk(dev, mount_path):
    # create directory before mount
    cmd = [&#39;mkdir&#39;, &#39;-p&#39;, mount_path]
    subprocess.check_call(cmd)
    cmd = [&#39;mount&#39;, dev, mount_path]
    subprocess.check_call(cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.node_default_tags"><code class="name flex">
<span>def <span class="ident">node_default_tags</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.yield_fixture
def node_default_tags():
    &#34;&#34;&#34;
    Assign the Tags under DEFAULT_TAGS to the Longhorn client&#39;s Nodes to
    provide a base set of Tags to work with in the tests.
    :return: A dictionary mapping a Node&#39;s ID to the Tags it has.
    &#34;&#34;&#34;
    client = get_longhorn_api_client()  # NOQA
    nodes = client.list_node()
    assert len(nodes) == 3

    tag_mappings = {}
    for tags, node in zip(DEFAULT_TAGS, nodes):
        if DATA_ENGINE == &#34;v2&#34;:
            # if the v2 data engine is enabled, both a file system disk
            # and a block disk will coexist. This is because a v2 backing image
            # requires a file system disk to function.
            assert len(node.disks) == 2
        else:
            assert len(node.disks) == 1

        update_disks = get_update_disks(node.disks)
        update_disks[list(update_disks)[0]].tags = tags[&#34;disk&#34;]
        new_node = update_node_disks(client, node.name, disks=update_disks,
                                     retry=True)
        disks = get_update_disks(new_node.disks)
        assert disks[list(new_node.disks)[0]].tags == tags[&#34;disk&#34;]

        new_node = set_node_tags(client, node, tags[&#34;node&#34;])
        assert new_node.tags == tags[&#34;node&#34;]

        tag_mappings[node.id] = tags
    yield tag_mappings

    client = get_longhorn_api_client()  # NOQA
    nodes = client.list_node()
    for node in nodes:
        update_disks = get_update_disks(node.disks)
        update_disks[list(update_disks)[0]].tags = []
        new_node = update_node_disks(client, node.name, disks=update_disks,
                                     retry=True)
        disks = get_update_disks(new_node.disks)
        assert len(disks[list(new_node.disks)[0]].tags) == 0, \
            f&#34; disk = {disks}&#34;

        new_node = set_node_tags(client, node)
        assert len(new_node.tags) == 0, f&#34; Node = {new_node}&#34;</code></pre>
</details>
<div class="desc"><p>Assign the Tags under DEFAULT_TAGS to the Longhorn client's Nodes to
provide a base set of Tags to work with in the tests.
:return: A dictionary mapping a Node's ID to the Tags it has.</p></div>
</dd>
<dt id="tests.common.nvmf_login"><code class="name flex">
<span>def <span class="ident">nvmf_login</span></span>(<span>nvmf)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nvmf_login(nvmf):
    # Related commands are documented at:
    # https://github.com/longhorn/longhorn-tests/wiki/Connect-to-the-NVMf-frontend-volume # NOQA
    ip = get_nvmf_ip(nvmf)
    port = get_nvmf_port(nvmf)
    # NVMe Qualified Name
    nqn = get_nvmf_nqn(nvmf)

    cmd_connect = f&#34;nvme connect -t tcp -a {ip} -s {port} -n {nqn}&#34;
    subprocess.check_output(cmd_connect.split())
    return wait_for_nvme_device()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.nvmf_logout"><code class="name flex">
<span>def <span class="ident">nvmf_logout</span></span>(<span>nvmf)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nvmf_logout(nvmf):
    nqn = get_nvmf_nqn(nvmf)
    try:
        subprocess.check_call([&#34;nvme&#34;, &#34;disconnect&#34;, &#34;-n&#34;, nqn])
        print(f&#34;Disconnected from {nqn}&#34;)
    except subprocess.CalledProcessError as e:
        print(f&#34;Failed to disconnect from {nqn}: {e}&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.offline_expand_attached_volume"><code class="name flex">
<span>def <span class="ident">offline_expand_attached_volume</span></span>(<span>client, volume_name, size='67108864')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def offline_expand_attached_volume(client, volume_name, size=EXPAND_SIZE):
    volume = wait_for_volume_healthy(client, volume_name)
    engine = get_volume_engine(volume)

    volume.detach()
    volume = wait_for_volume_detached(client, volume.name)
    volume.expand(size=size)
    wait_for_volume_expansion(client, volume.name)
    volume = wait_for_volume_detached(client, volume.name)
    volume.attach(hostId=engine.hostId, disableFrontend=False)
    wait_for_volume_healthy(client, volume_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.parse_iscsi_endpoint"><code class="name flex">
<span>def <span class="ident">parse_iscsi_endpoint</span></span>(<span>iscsi)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_iscsi_endpoint(iscsi):
    iscsi_endpoint = iscsi[8:]
    return iscsi_endpoint.split(&#39;/&#39;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.parse_nvmf_endpoint"><code class="name flex">
<span>def <span class="ident">parse_nvmf_endpoint</span></span>(<span>nvmf)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_nvmf_endpoint(nvmf):
    return nvmf[7:].split(&#39;/&#39;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.pod"><code class="name flex">
<span>def <span class="ident">pod</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def pod(request):
    pod_manifest = {
        &#39;apiVersion&#39;: &#39;v1&#39;,
        &#39;kind&#39;: &#39;Pod&#39;,
        &#39;metadata&#39;: {
            &#39;name&#39;: &#39;test-pod&#39;
        },
        &#39;spec&#39;: {
            &#39;containers&#39;: [{
                &#39;image&#39;: &#39;busybox:1.34.0&#39;,
                &#39;imagePullPolicy&#39;: &#39;IfNotPresent&#39;,
                &#39;name&#39;: &#39;sleep&#39;,
                &#34;args&#34;: [
                    &#34;/bin/sh&#34;,
                    &#34;-c&#34;,
                    &#34;while true;do date;sleep 5; done&#34;
                ],
                &#34;volumeMounts&#34;: [{
                    &#39;name&#39;: &#39;pod-data&#39;,
                    &#39;mountPath&#39;: &#39;/data&#39;
                }],
            }],
            &#39;volumes&#39;: []
        }
    }

    def finalizer():
        api = get_core_api_client()
        delete_and_wait_pod(api, pod_manifest[&#39;metadata&#39;][&#39;name&#39;])

    request.addfinalizer(finalizer)

    return pod_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.pod_make"><code class="name flex">
<span>def <span class="ident">pod_make</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def pod_make(request):
    def make_pod(name=&#39;test-pod&#39;):
        pod_manifest = {
            &#39;apiVersion&#39;: &#39;v1&#39;,
            &#39;kind&#39;: &#39;Pod&#39;,
            &#39;metadata&#39;: {
                &#39;name&#39;: name
            },
            &#39;spec&#39;: {
                &#39;containers&#39;: [{
                    &#39;image&#39;: &#39;busybox:1.34.0&#39;,
                    &#39;imagePullPolicy&#39;: &#39;IfNotPresent&#39;,
                    &#39;name&#39;: &#39;sleep&#39;,
                    &#34;args&#34;: [
                        &#34;/bin/sh&#34;,
                        &#34;-c&#34;,
                        &#34;while true; do date; sleep 5; done&#34;
                    ],
                    &#34;volumeMounts&#34;: [{
                        &#39;name&#39;: &#39;pod-data&#39;,
                        &#39;mountPath&#39;: &#39;/data&#39;
                    }],
                }],
                &#39;volumes&#39;: []
            }
        }

        def finalizer():
            api = get_core_api_client()
            try:
                pod_name = pod_manifest[&#39;metadata&#39;][&#39;name&#39;]
                delete_and_wait_pod(api, pod_name)
            except Exception as e:
                print(&#34;\nException when waiting for pod deletion&#34;)
                print(e)
                return
            try:
                volume_details = pod_manifest[&#39;spec&#39;][&#39;volumes&#39;][0]
                pvc_name = volume_details[&#39;persistentVolumeClaim&#39;][&#39;claimName&#39;]
                delete_and_wait_pvc(api, pvc_name)
            except Exception as e:
                print(&#34;\nException when waiting for PVC deletion&#34;)
                print(e)
            try:
                found = False
                pvs = api.list_persistent_volume()
                for item in pvs.items:
                    if item.spec.claim_ref.name == pvc_name:
                        pv = item
                        found = True
                        break
                if found:
                    pv_name = pv.metadata.name
                    delete_and_wait_pv(api, pv_name)
            except Exception as e:
                print(&#34;\nException when waiting for PV deletion&#34;)
                print(e)

        request.addfinalizer(finalizer)
        return pod_manifest

    return make_pod</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.prepare_host_disk"><code class="name flex">
<span>def <span class="ident">prepare_host_disk</span></span>(<span>dev, vol_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_host_disk(dev, vol_name):
    cmd = [&#39;mkfs.ext4&#39;, dev]
    subprocess.check_call(cmd)

    mount_path = os.path.join(DIRECTORY_PATH, vol_name)
    mount_disk(dev, mount_path)
    return mount_path</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.prepare_pod_with_data_in_mb"><code class="name flex">
<span>def <span class="ident">prepare_pod_with_data_in_mb</span></span>(<span>client,<br>core_api,<br>csi_pv,<br>pvc,<br>pod_make,<br>volume_name,<br>volume_size='1073741824',<br>num_of_replicas=3,<br>data_path='/data/test',<br>data_size_in_mb=100,<br>add_liveness_probe=True,<br>access_mode='rwo',<br>data_engine='v1')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_pod_with_data_in_mb(
        client, core_api, csi_pv, pvc, pod_make, volume_name,
        volume_size=str(1*Gi), num_of_replicas=3, data_path=&#34;/data/test&#34;,
        data_size_in_mb=DATA_SIZE_IN_MB_1, add_liveness_probe=True,
        access_mode=ACCESS_MODE_RWO, data_engine=DATA_ENGINE):# NOQA:

    pod_name = volume_name + &#34;-pod&#34;
    pv_name = volume_name
    pvc_name = volume_name + &#34;-pvc&#34;

    pod = pod_make(name=pod_name)
    csi_pv[&#39;metadata&#39;][&#39;name&#39;] = pv_name
    csi_pv[&#39;spec&#39;][&#39;csi&#39;][&#39;volumeHandle&#39;] = volume_name
    csi_pv[&#39;spec&#39;][&#39;capacity&#39;][&#39;storage&#39;] = volume_size
    pvc[&#39;metadata&#39;][&#39;name&#39;] = pvc_name
    pvc[&#39;spec&#39;][&#39;volumeName&#39;] = pv_name
    pvc[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] = volume_size
    pvc[&#39;spec&#39;][&#39;storageClassName&#39;] = &#39;&#39;
    pod[&#39;spec&#39;][&#39;volumes&#39;] = [create_pvc_spec(pvc_name)]

    if add_liveness_probe is True:
        pod_liveness_probe_spec = \
            get_liveness_probe_spec(initial_delay=1,
                                    period=1)
        pod[&#39;spec&#39;][&#39;containers&#39;][0][&#39;livenessProbe&#39;] = \
            pod_liveness_probe_spec

    create_and_check_volume(client, volume_name,
                            num_of_replicas=num_of_replicas,
                            size=volume_size,
                            access_mode=access_mode,
                            data_engine=data_engine)
    core_api.create_persistent_volume(csi_pv)
    core_api.create_namespaced_persistent_volume_claim(
        body=pvc, namespace=&#39;default&#39;)

    create_and_wait_pod(core_api, pod)

    write_pod_volume_random_data(core_api, pod_name,
                                 data_path, data_size_in_mb)
    md5sum = get_pod_data_md5sum(core_api, pod_name, data_path)

    stream(core_api.connect_get_namespaced_pod_exec,
           pod_name, &#39;default&#39;, command=[&#34;sync&#34;],
           stderr=True, stdin=False, stdout=True, tty=False)

    return pod_name, pv_name, pvc_name, md5sum</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.prepare_statefulset_with_data_in_mb"><code class="name flex">
<span>def <span class="ident">prepare_statefulset_with_data_in_mb</span></span>(<span>client,<br>core_api,<br>statefulset,<br>sts_name,<br>storage_class,<br>data_path='/data/test',<br>data_size_in_mb=100)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_statefulset_with_data_in_mb(
        client, core_api, statefulset, sts_name, storage_class,
        data_path=&#34;/data/test&#34;,
        data_size_in_mb=DATA_SIZE_IN_MB_1):
    update_statefulset_manifests(statefulset, storage_class, sts_name)
    statefulset[&#39;spec&#39;][&#39;replicas&#39;] = 1

    create_storage_class(storage_class)
    create_and_wait_statefulset(statefulset)

    pod_info = get_statefulset_pod_info(core_api, statefulset)
    volumes = client.list_volume()
    assert len(volumes) == statefulset[&#39;spec&#39;][&#39;replicas&#39;]

    vol_name = None
    pod_name = None
    md5sum = None
    for v in volumes:
        info = pod_info[0]
        if v.name == info[&#39;pv_name&#39;]:
            write_pod_volume_random_data(core_api, info[&#39;pod_name&#39;],
                                         data_path, data_size_in_mb)
            md5sum = get_pod_data_md5sum(core_api, info[&#39;pod_name&#39;],
                                         data_path)
            stream(core_api.connect_get_namespaced_pod_exec,
                   info[&#39;pod_name&#39;], &#39;default&#39;, command=[&#34;sync&#34;],
                   stderr=True, stdin=False, stdout=True, tty=False)

            vol_name = v.name
            pod_name = info[&#39;pod_name&#39;]
            break

    assert vol_name is not None
    assert pod_name is not None
    assert md5sum is not None
    return vol_name, pod_name, md5sum</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.priority_class"><code class="name flex">
<span>def <span class="ident">priority_class</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def priority_class(request):
    priority_class = {
        &#39;apiVersion&#39;: &#39;scheduling.k8s.io/v1&#39;,
        &#39;kind&#39;: &#39;PriorityClass&#39;,
        &#39;metadata&#39;: {
            &#39;name&#39;: PRIORITY_CLASS_NAME + &#34;-&#34; + &#39;&#39;.join(
                random.choice(string.ascii_lowercase +
                              string.digits)
                for _ in range(6))
        },
        &#39;value&#39;: random.randrange(PRIORITY_CLASS_MIN, PRIORITY_CLASS_MAX)
    }

    def finalizer():
        # ensure that the priority class gets unset for longhorn
        # before deleting the class
        client = get_longhorn_api_client()
        setting = client.by_id_setting(SETTING_PRIORITY_CLASS)
        setting = client.update(setting, value=&#39;&#39;)
        assert setting.value == &#39;&#39;

        api = get_scheduling_api_client()
        try:
            api.delete_priority_class(name=priority_class[&#39;metadata&#39;][&#39;name&#39;],
                                      body=k8sclient.V1DeleteOptions())
        except ApiException as e:
            assert e.status == 404

    request.addfinalizer(finalizer)

    return priority_class</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.pvc"><code class="name flex">
<span>def <span class="ident">pvc</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def pvc(request):
    return get_pvc_manifest(request)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.pvc_backingimage"><code class="name flex">
<span>def <span class="ident">pvc_backingimage</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def pvc_backingimage(request):
    pvc_manifest = get_pvc_manifest(request)
    pvc_manifest[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] = \
        size_to_string(BACKING_IMAGE_EXT4_SIZE)
    return pvc_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.pvc_name"><code class="name flex">
<span>def <span class="ident">pvc_name</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def pvc_name(request):
    return generate_volume_name()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.random_labels"><code class="name flex">
<span>def <span class="ident">random_labels</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def random_labels():
    labels = {}
    i = 0
    while i &lt; 3:
        key = &#34;label/&#34; + &#34;&#34;.join(random.choice(string.ascii_lowercase +
                                               string.digits)
                                 for _ in range(6))
        if not labels.get(key):
            labels[&#34;key&#34;] = generate_random_data(VOLUME_RWTEST_SIZE)
            i += 1
    return labels</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.read_pod_block_volume_data"><code class="name flex">
<span>def <span class="ident">read_pod_block_volume_data</span></span>(<span>api, pod_name, data_size, offset, device_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_pod_block_volume_data(api, pod_name, data_size, offset, device_path):
    read_command = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;dd if=&#39; + device_path +
        &#39; status=none bs=&#39; + str(data_size) + &#39; count=1 skip=&#39; + str(offset)
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream read&#39;):
        return stream(
            api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
            command=read_command, stderr=True, stdin=False, stdout=True,
            tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.read_volume_data"><code class="name flex">
<span>def <span class="ident">read_volume_data</span></span>(<span>api, pod_name, filename='test')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_volume_data(api, pod_name, filename=&#39;test&#39;):
    &#34;&#34;&#34;
    Retrieve data from a Pod&#39;s volume.

    Args:
        api: An instance of CoreV1API.
        pod_name: The name of the Pod.

    Returns:
        The data contained within the volume.
    &#34;&#34;&#34;
    read_command = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;cat /data/&#39; + filename
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream read&#39;):
        return stream(
            api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
            command=read_command, stderr=True, stdin=False, stdout=True,
            tty=False)</code></pre>
</details>
<div class="desc"><p>Retrieve data from a Pod's volume.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>api</code></strong></dt>
<dd>An instance of CoreV1API.</dd>
<dt><strong><code>pod_name</code></strong></dt>
<dd>The name of the Pod.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The data contained within the volume.</p></div>
</dd>
<dt id="tests.common.recurring_job_feature_supported"><code class="name flex">
<span>def <span class="ident">recurring_job_feature_supported</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def recurring_job_feature_supported(client):
    if hasattr(client.by_id_schema(&#34;volumeRecurringJob&#34;), &#34;id&#34;):
        return True
    else:
        return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.remount_volume_read_only"><code class="name flex">
<span>def <span class="ident">remount_volume_read_only</span></span>(<span>client, core_api, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remount_volume_read_only(client, core_api, volume_name):
    volume_name_hash = hashlib.sha256(volume_name.encode()).hexdigest()

    volume = client.by_id_volume(volume_name)
    instance_manager_name = volume.controllers[0].instanceManagerName

    print(f&#34;Remounting volume {volume_name} as read-only: {volume_name_hash}&#34;)

    command = [
            &#39;/bin/sh&#39;, &#39;-c&#39;,
            f&#34;mount -o remount,ro /host/var/lib/kubelet/plugins/kubernetes.io/csi/driver.longhorn.io/{volume_name_hash}/globalmount&#34;    # NOQA
    ]

    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream read&#39;):
        stream(core_api.connect_get_namespaced_pod_exec,
               instance_manager_name, LONGHORN_NAMESPACE, command=command,
               stderr=True, stdin=False, stdout=True, tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.reset_disks_for_all_nodes"><code class="name flex">
<span>def <span class="ident">reset_disks_for_all_nodes</span></span>(<span>client, add_block_disks=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_disks_for_all_nodes(client, add_block_disks=False):  # NOQA
    default_disks = {
        &#34;v1&#34;: {
            &#34;path&#34;: DEFAULT_DISK_PATH,
            &#34;type&#34;: &#34;filesystem&#34;,
            &#34;default&#34;: True,
        }
    }

    if v2_data_engine_cr_supported(client):
        enable_v2 = os.environ.get(&#39;RUN_V2_TEST&#39;)
        if enable_v2 == &#34;true&#34; or add_block_disks is True:
            default_disks[&#34;v2&#34;] = {
                &#34;path&#34;: BLOCK_DEV_PATH,
                &#34;type&#34;: &#34;block&#34;,
                &#34;default&#34;: True,
            }
            default_disks[&#34;v1&#34;][&#34;default&#34;] = False

    nodes = client.list_node()
    for n in nodes:
        node = n  # Captures the correct value of n in the closure.

        # Reset default disk if default disks are not the only disks
        # on the node.
        cleanup_required = False
        if len(node.disks) != len(default_disks):
            cleanup_required = True

        for name, disk in iter(node.disks.items()):
            if cleanup_required:
                break

            if disk.path not in [v[&#34;path&#34;] for v in default_disks.values()]:
                cleanup_required = True
                break

            if name == &#34;default-disk&#34;:
                for data_engine, disk in default_disks.items():
                    if not disk[&#34;default&#34;]:
                        continue

                    if disk[&#34;path&#34;] != node.disks[name].path:
                        cleanup_required = True
                    break

        if cleanup_required:
            update_disks = get_update_disks(node.disks)
            for disk_name, disk in iter(update_disks.items()):
                disk.allowScheduling = False
                update_disks[disk_name] = disk
                node = update_node_disks(client, node.name, disks=update_disks,
                                         retry=True)
            update_disks = {}
            node = update_node_disks(client, node.name, disks=update_disks,
                                     retry=True)
            node = wait_for_disk_update(client, node.name, 0)

        if len(node.disks) != len(default_disks):
            update_disks = {}
            for data_engine, disk in default_disks.items():
                disk_name = data_engine
                if disk[&#34;default&#34;]:
                    disk_name = &#34;default-disk&#34;

                update_disks[disk_name] = {
                    &#34;path&#34;: disk[&#34;path&#34;],
                    &#34;diskType&#34;: disk[&#34;type&#34;],
                    &#34;allowScheduling&#34;: True
                }

            node = update_node_disks(client, node.name, disks=update_disks,
                                     retry=True)
            node = wait_for_disk_update(client, node.name, len(default_disks))
            assert len(node.disks) == len(default_disks)
        # wait for node controller to update disk status
        disks = node.disks
        update_disks = {}
        for name, disk in iter(disks.items()):
            update_disk = disk
            update_disk.allowScheduling = True
            if disk.diskType == &#34;filesystem&#34;:
                reserved_storage = int(update_disk.storageMaximum * 30 / 100)
            else:
                reserved_storage = 0
            update_disk.storageReserved = reserved_storage
            update_disk.tags = []
            update_disks[name] = update_disk
        node = update_node_disks(client, node.name, disks=update_disks,
                                 retry=True)
        for name, disk in iter(node.disks.items()):
            # wait for node controller update disk status
            wait_for_disk_status(client, node.name, name,
                                 &#34;allowScheduling&#34;, True)
            wait_for_disk_status(client, node.name, name,
                                 &#34;storageScheduled&#34;, 0)

            expected_reserved_storage = 0
            if disk.diskType == &#34;filesystem&#34;:
                expected_reserved_storage = reserved_storage
            wait_for_disk_status(client, node.name, name,
                                 &#34;storageReserved&#34;,
                                 expected_reserved_storage)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.reset_engine_image"><code class="name flex">
<span>def <span class="ident">reset_engine_image</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_engine_image(client):
    core_api = get_core_api_client()
    ready = False

    for i in range(RETRY_COUNTS):
        ready = True
        ei_list = client.list_engine_image().data
        for ei in ei_list:
            if ei.default:
                if ei.state != get_engine_image_status_value(client, ei.name):
                    ready = False
            else:
                wait_for_engine_image_ref_count(client, ei.name, 0)
                client.delete(ei)
                wait_for_engine_image_deletion(client, core_api, ei.name)
        if ready:
            break
        time.sleep(RETRY_INTERVAL)

    assert ready</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.reset_longhorn_node_zone"><code class="name flex">
<span>def <span class="ident">reset_longhorn_node_zone</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_longhorn_node_zone(client):
    core_api = get_core_api_client()

    # No need to reset zone label for GKE COS node as the node zone label is
    # periodically updated with the actual GCP zone.
    # https://github.com/longhorn/longhorn-tests/pull/1819
    if is_k8s_node_gke_cos(core_api):
        return

    nodes = client.list_node()
    for n in nodes:
        set_k8s_node_zone_label(core_api, n.name, None)
    wait_longhorn_node_zone_reset(client)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.reset_node"><code class="name flex">
<span>def <span class="ident">reset_node</span></span>(<span>client, core_api)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_node(client, core_api):
    # remove nodes taint
    reset_nodes_taint(client)

    nodes = client.list_node()
    for node in nodes:
        try:
            set_node_cordon(core_api, node.id, False)
            node = client.by_id_node(node.id)

            node = set_node_tags(client, node, tags=[])
            node = wait_for_node_tag_update(client, node.id, [])
            node = set_node_scheduling(client, node, allowScheduling=True)
            wait_for_node_update(client, node.id,
                                 &#34;allowScheduling&#34;, True)
        except Exception as e:
            print(&#34;\nException when reset node scheduling and tags&#34;, node)
            print(e)

    managed_k8s_cluster = os.getenv(&#34;MANAGED_K8S_CLUSTER&#34;).lower() == &#39;true&#39;
    if not managed_k8s_cluster:
        reset_longhorn_node_zone(client)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.reset_nodes_taint"><code class="name flex">
<span>def <span class="ident">reset_nodes_taint</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_nodes_taint(client):
    core_api = get_core_api_client()
    nodes = client.list_node()

    for node in nodes:
        core_api.patch_node(node.id, {
            &#34;spec&#34;: {&#34;taints&#34;: []}
        })</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.reset_settings"><code class="name flex">
<span>def <span class="ident">reset_settings</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_settings(client):

    for setting in client.list_setting():
        setting_name = setting.name
        setting_default_value = setting.definition.default
        setting_readonly = setting.definition.readOnly

        # We don&#39;t provide the setup for the storage network, hence there is no
        # default value. We need to skip here to avoid test failure when
        # resetting this to an empty default value.
        if setting_name == &#34;storage-network&#34;:
            continue
        # The test CI deploys Longhorn with the setting value longhorn-critical
        # for the setting priority-class. Don&#39;t reset it to empty (which is
        # the default value defined in longhorn-manager code) because this will
        # restart Longhorn managed components and fail the test cases.
        # https://github.com/longhorn/longhorn/issues/7413#issuecomment-1881707958
        if setting.name == SETTING_PRIORITY_CLASS:
            continue

        # The version of the support bundle kit will be specified by a command
        # option when starting the manager. And setting requires a value.
        #
        # Longhorn has a default version for each release provided to the
        # manager when starting. Meaning this setting doesn&#39;t have a default
        # value.
        #
        # The design grants the ability to update later by cases for
        # troubleshooting purposes. Meaning this setting is editable.
        #
        # So we need to skip here to avoid test failure when resetting this to
        # an empty default value.
        if setting_name == &#34;support-bundle-manager-image&#34;:
            continue

        if setting_name == &#34;registry-secret&#34;:
            continue

        if setting_name == &#34;v2-data-engine&#34;:
            if v2_data_engine_cr_supported(client):
                setting = client.by_id_setting(SETTING_V2_DATA_ENGINE)
                try:
                    client.update(setting, value=&#34;true&#34;)
                except Exception as e:
                    print(f&#34;\nException setting {setting_name} to true&#34;)
                    print(e)
                continue

        s = client.by_id_setting(setting_name)
        if s.value != setting_default_value and not setting_readonly:
            try:
                client.update(s, value=setting_default_value)
            except Exception as e:
                print(&#34;\nException when resetting &#34;,
                      setting_name,
                      &#34; to value: &#34;,
                      setting_default_value)
                print(s)
                print(e)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.restart_and_wait_ready_engine_count"><code class="name flex">
<span>def <span class="ident">restart_and_wait_ready_engine_count</span></span>(<span>client, ready_engine_count)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def restart_and_wait_ready_engine_count(client, ready_engine_count): # NOQA
    &#34;&#34;&#34;
    Delete/restart engine daemonset and wait ready engine image count after
    daemonset restart
    &#34;&#34;&#34;

    apps_api = get_apps_api_client()
    default_img = get_default_engine_image(client)
    ds_name = &#34;engine-image-&#34; + default_img.name
    apps_api.delete_namespaced_daemon_set(ds_name, LONGHORN_NAMESPACE)
    wait_for_engine_image_condition(client, default_img.name, &#34;False&#34;)
    wait_for_engine_image_state(client, default_img.name, &#34;deploying&#34;)
    wait_for_running_engine_image_count(default_img.name, ready_engine_count)</code></pre>
</details>
<div class="desc"><p>Delete/restart engine daemonset and wait ready engine image count after
daemonset restart</p></div>
</dd>
<dt id="tests.common.restore_backup_and_get_data_checksum"><code class="name flex">
<span>def <span class="ident">restore_backup_and_get_data_checksum</span></span>(<span>client, core_api, backup, pod, file_name='', command='')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def restore_backup_and_get_data_checksum(client, core_api, backup, pod,
                                         file_name=&#39;&#39;, command=&#39;&#39;):
    &#34;&#34;&#34;
        Restore the backup in a pod and get the checksum of all the files
        or checksum of a particular file.
        Args:
            client: The Longhorn client to use in the request.
            core_api: An instance of CoreV1API.
            backup: The backup to be restored.
            pod: Pod fixture.
            file_name: Optional - File whose checksum to be computed.
            command: Optional - command to be executed in the pod.
        Returns:
            The checksum as a dictionary as in file_name=checksum and the
            output of the command executed in the pod.
    &#34;&#34;&#34;
    restore_volume_name = generate_volume_name() + &#34;-restore&#34;
    restore_pod_name = restore_volume_name + &#34;-pod&#34;
    restore_pv_name = restore_volume_name + &#34;-pv&#34;
    restore_pvc_name = restore_volume_name + &#34;-pvc&#34;
    data_checksum = {}

    client.create_volume(name=restore_volume_name, size=str(1 * Gi),
                         fromBackup=backup.url,
                         dataEngine=DATA_ENGINE)
    volume = wait_for_volume_detached(client, restore_volume_name)
    create_pv_for_volume(client, core_api, volume, restore_pv_name)
    create_pvc_for_volume(client, core_api, volume, restore_pvc_name)
    pod[&#39;metadata&#39;][&#39;name&#39;] = restore_pod_name
    pod[&#39;spec&#39;][&#39;volumes&#39;] = [{
        &#39;name&#39;: pod[&#39;spec&#39;][&#39;containers&#39;][0][&#39;volumeMounts&#39;][0][&#39;name&#39;],
        &#39;persistentVolumeClaim&#39;: {
            &#39;claimName&#39;: restore_pvc_name,
        },
    }]
    create_and_wait_pod(core_api, pod)

    restore_volume = client.by_id_volume(restore_volume_name)
    assert restore_volume[VOLUME_FIELD_ROBUSTNESS] == VOLUME_ROBUSTNESS_HEALTHY

    if file_name == &#39;&#39;:
        file_list = exec_command_in_pod(core_api, &#39;ls /data&#39;, restore_pod_name,
                                        &#39;default&#39;)
        file_list = file_list.strip()
        file_list = file_list.split(&#39;\n&#39;)
        if len(file_list) &gt; 0:
            for file_name in file_list:
                data_path = &#39;/data/&#39; + file_name
                data_checksum[file_name] = \
                    get_pod_data_md5sum(core_api, restore_pod_name, data_path)
    else:
        data_path = &#39;/data/&#39; + file_name
        data_checksum[file_name] = get_pod_data_md5sum(core_api,
                                                       restore_pod_name,
                                                       data_path)

    # This is optional, if you want to execute any command and get the output
    output = &#39;&#39;
    if command != &#39;&#39;:
        output = exec_command_in_pod(core_api, command, restore_pod_name,
                                     &#39;default&#39;)

    return data_checksum, output, restore_pod_name</code></pre>
</details>
<div class="desc"><p>Restore the backup in a pod and get the checksum of all the files
or checksum of a particular file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>client</code></strong></dt>
<dd>The Longhorn client to use in the request.</dd>
<dt><strong><code>core_api</code></strong></dt>
<dd>An instance of CoreV1API.</dd>
<dt><strong><code>backup</code></strong></dt>
<dd>The backup to be restored.</dd>
<dt><strong><code>pod</code></strong></dt>
<dd>Pod fixture.</dd>
<dt><strong><code>file_name</code></strong></dt>
<dd>Optional - File whose checksum to be computed.</dd>
<dt><strong><code>command</code></strong></dt>
<dd>Optional - command to be executed in the pod.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The checksum as a dictionary as in file_name=checksum and the
output of the command executed in the pod.</p></div>
</dd>
<dt id="tests.common.rwx_statefulset"><code class="name flex">
<span>def <span class="ident">rwx_statefulset</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def rwx_statefulset(request):
    statefulset_manifest = {
        &#39;apiVersion&#39;: &#39;apps/v1&#39;,
        &#39;kind&#39;: &#39;StatefulSet&#39;,
        &#39;metadata&#39;: {
            &#39;name&#39;: &#39;rwx-test-statefulset&#39;,
            &#39;namespace&#39;: &#39;default&#39;,
        },
        &#39;spec&#39;: {
            &#39;selector&#39;: {
                &#39;matchLabels&#39;: {
                    &#39;app&#39;: &#39;rwx-test-statefulset&#39;
                }
            },
            &#39;serviceName&#39;: &#39;rwx-test-statefulset&#39;,
            &#39;replicas&#39;: 1,
            &#39;template&#39;: {
                &#39;metadata&#39;: {
                    &#39;labels&#39;: {
                        &#39;app&#39;: &#39;rwx-test-statefulset&#39;
                    }
                },
                &#39;spec&#39;: {
                    &#39;terminationGracePeriodSeconds&#39;: 10,
                    &#39;containers&#39;: [{
                        &#39;image&#39;: &#39;busybox:1.34.0&#39;,
                        &#39;imagePullPolicy&#39;: &#39;IfNotPresent&#39;,
                        &#39;name&#39;: &#39;sleep&#39;,
                        &#39;args&#39;: [
                            &#39;/bin/sh&#39;,
                            &#39;-c&#39;,
                            &#39;while true;do date;sleep 5; done&#39;
                        ],
                        &#39;volumeMounts&#39;: [{
                            &#39;name&#39;: &#39;pod-data&#39;,
                            &#39;mountPath&#39;: &#39;/data&#39;
                        }]
                    }]
                }
            },
            &#39;volumeClaimTemplates&#39;: [{
                &#39;metadata&#39;: {
                    &#39;name&#39;: &#39;pod-data&#39;
                },
                &#39;spec&#39;: {
                    &#39;accessModes&#39;: [
                        &#39;ReadWriteMany&#39;
                    ],
                    &#39;storageClassName&#39;: &#39;longhorn&#39;,
                    &#39;resources&#39;: {
                        &#39;requests&#39;: {
                            &#39;storage&#39;: size_to_string(
                                           DEFAULT_VOLUME_SIZE * Gi)
                        }
                    }
                }
            }]
        }
    }

    def finalizer():
        api = get_core_api_client()
        client = get_longhorn_api_client()
        delete_and_wait_statefulset(api, client, statefulset_manifest)

    request.addfinalizer(finalizer)

    return statefulset_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.scale_up_engine_image_daemonset"><code class="name flex">
<span>def <span class="ident">scale_up_engine_image_daemonset</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale_up_engine_image_daemonset(client):
    apps_api = get_apps_api_client()
    default_img = get_default_engine_image(client)
    ds_name = &#34;engine-image-&#34; + default_img.name
    body = [{
        &#34;op&#34;: &#34;replace&#34;,
        &#34;path&#34;: &#34;/spec/template/spec/nodeSelector&#34;,
        &#34;value&#34;: None
    }]
    try:
        apps_api.patch_namespaced_daemon_set(
            name=ds_name, namespace=&#39;longhorn-system&#39;, body=body)
    except ApiException as e:
        # for scaling up a running daemond set,
        # the status_code is 422 server error.
        assert e.status == 422

    # make sure default engine image deployed ready
    wait_for_deployed_engine_image_count(client, default_img.name, 3)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.scheduling_api"><code class="name flex">
<span>def <span class="ident">scheduling_api</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def scheduling_api(request):
    &#34;&#34;&#34;
    Create a new SchedulingV1API instance.
    Returns:
        A new CoreV1API Instance.
    &#34;&#34;&#34;
    c = Configuration()
    c.assert_hostname = False
    Configuration.set_default(c)
    k8sconfig.load_incluster_config()
    scheduling_api = k8sclient.SchedulingV1Api()

    return scheduling_api</code></pre>
</details>
<div class="desc"><p>Create a new SchedulingV1API instance.</p>
<h2 id="returns">Returns</h2>
<p>A new CoreV1API Instance.</p></div>
</dd>
<dt id="tests.common.set_and_wait_k8s_nodes_zone_label"><code class="name flex">
<span>def <span class="ident">set_and_wait_k8s_nodes_zone_label</span></span>(<span>core_api, node_zone_map)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_and_wait_k8s_nodes_zone_label(core_api, node_zone_map):
    k8s_zone_label = get_k8s_zone_label()

    for _ in range(RETRY_COUNTS):
        for node_name, zone_name in node_zone_map.items():
            set_k8s_node_label(core_api, node_name, k8s_zone_label, zone_name)

        is_updated = False
        for node_name, zone_name in node_zone_map.items():
            is_updated = \
                is_k8s_node_label(core_api,
                                  k8s_zone_label, zone_name, node_name)
            if not is_updated:
                break

        if is_updated:
            break

        time.sleep(RETRY_INTERVAL)

    assert is_updated, \
        f&#34;Timeout while waiting for nodes zone label to be updated\n&#34; \
        f&#34;Expected: {node_zone_map}&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.set_k8s_node_label"><code class="name flex">
<span>def <span class="ident">set_k8s_node_label</span></span>(<span>core_api, node_name, key, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_k8s_node_label(core_api, node_name, key, value):
    payload = {
        &#34;metadata&#34;: {
            &#34;labels&#34;: {
                key: value}
        }
    }

    core_api.patch_node(node_name, body=payload)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.set_k8s_node_zone_label"><code class="name flex">
<span>def <span class="ident">set_k8s_node_zone_label</span></span>(<span>core_api, node_name, zone_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_k8s_node_zone_label(core_api, node_name, zone_name):
    if is_k8s_node_label(core_api, K8S_ZONE_LABEL, zone_name, node_name):
        return

    k8s_zone_label = get_k8s_zone_label()

    set_k8s_node_label(core_api, node_name, k8s_zone_label, zone_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.set_node_cordon"><code class="name flex">
<span>def <span class="ident">set_node_cordon</span></span>(<span>api, node_name, to_cordon)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_node_cordon(api, node_name, to_cordon):
    &#34;&#34;&#34;
    Set a kubernetes node schedulable status
    &#34;&#34;&#34;
    payload = {
        &#34;spec&#34;: {
            &#34;unschedulable&#34;: to_cordon
        }
    }

    api.patch_node(node_name, payload)</code></pre>
</details>
<div class="desc"><p>Set a kubernetes node schedulable status</p></div>
</dd>
<dt id="tests.common.set_node_scheduling"><code class="name flex">
<span>def <span class="ident">set_node_scheduling</span></span>(<span>client, node, allowScheduling, retry=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_node_scheduling(client, node, allowScheduling, retry=False):
    if node.tags is None:
        node.tags = []

    if not retry:
        return client.update(node, allowScheduling=allowScheduling,
                             tags=node.tags)

    # Retry if &#34;too many retries error&#34; happened.
    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node = client.update(node, allowScheduling=allowScheduling,
                                 tags=node.tags)
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(e)
            raise
        else:
            break

    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.set_node_scheduling_eviction"><code class="name flex">
<span>def <span class="ident">set_node_scheduling_eviction</span></span>(<span>client, node, allowScheduling, evictionRequested, retry=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_node_scheduling_eviction(client, node, allowScheduling, evictionRequested, retry=False):  # NOQA
    if node.tags is None:
        node.tags = []

    if not retry:
        node = client.update(node,
                             allowScheduling=allowScheduling,
                             evictionRequested=evictionRequested)

    # Retry if &#34;too many retries error&#34; happened.
    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node = client.update(node,
                                 allowScheduling=allowScheduling,
                                 evictionRequested=evictionRequested)
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(e)
            raise
        else:
            break

    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.set_node_tags"><code class="name flex">
<span>def <span class="ident">set_node_tags</span></span>(<span>client, node, tags=[], retry=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_node_tags(client, node, tags=[], retry=False):  # NOQA
    &#34;&#34;&#34;
    Set the tags on a node without modifying its scheduling status.
    Retry if &#34;too many retries error&#34; happened.
    :param client: The Longhorn client to use in the request.
    :param node: The Node to update.
    :param tags: The tags to set on the node.
    :return: The updated Node.
    &#34;&#34;&#34;
    if not retry:
        return client.update(node, allowScheduling=node.allowScheduling,
                             tags=tags)

    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node = client.update(node,
                                 allowScheduling=node.allowScheduling,
                                 tags=tags)
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(e)
            raise
        else:
            break

    return node</code></pre>
</details>
<div class="desc"><p>Set the tags on a node without modifying its scheduling status.
Retry if "too many retries error" happened.
:param client: The Longhorn client to use in the request.
:param node: The Node to update.
:param tags: The tags to set on the node.
:return: The updated Node.</p></div>
</dd>
<dt id="tests.common.set_tags_for_node_and_its_disks"><code class="name flex">
<span>def <span class="ident">set_tags_for_node_and_its_disks</span></span>(<span>client, node, tags)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_tags_for_node_and_its_disks(client, node, tags): # NOQA
    if len(tags) == 0:
        expected_tags = []
    else:
        expected_tags = list(tags)

    for disk_name in node.disks.keys():
        node.disks[disk_name].tags = tags
    node = update_node_disks(client, node.name, disks=node.disks)
    for disk_name in node.disks.keys():
        assert node.disks[disk_name].tags == expected_tags

    node = set_node_tags(client, node, tags)
    assert node.tags == expected_tags

    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.settings_reset"><code class="name flex">
<span>def <span class="ident">settings_reset</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def settings_reset():
    yield

    client = get_longhorn_api_client()
    reset_settings(client)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.size_to_string"><code class="name flex">
<span>def <span class="ident">size_to_string</span></span>(<span>volume_size)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def size_to_string(volume_size):
    # type: (int) -&gt; str
    &#34;&#34;&#34;
    Convert a volume size to string format to pass into Kubernetes.
    Args:
        volume_size: The size of the volume in bytes.
    Returns:
        The size of the volume in gigabytes as a passable string to Kubernetes.
    &#34;&#34;&#34;
    if volume_size &gt;= Gi:
        return str(volume_size &gt;&gt; 30) + &#39;Gi&#39;
    elif volume_size &gt;= Mi:
        return str(volume_size &gt;&gt; 20) + &#39;Mi&#39;
    else:
        return str(volume_size &gt;&gt; 10) + &#39;Ki&#39;</code></pre>
</details>
<div class="desc"><p>Convert a volume size to string format to pass into Kubernetes.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>volume_size</code></strong></dt>
<dd>The size of the volume in bytes.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The size of the volume in gigabytes as a passable string to Kubernetes.</p></div>
</dd>
<dt id="tests.common.statefulset"><code class="name flex">
<span>def <span class="ident">statefulset</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def statefulset(request):
    statefulset_manifest = {
        &#39;apiVersion&#39;: &#39;apps/v1&#39;,
        &#39;kind&#39;: &#39;StatefulSet&#39;,
        &#39;metadata&#39;: {
            &#39;name&#39;: &#39;test-statefulset&#39;,
            &#39;namespace&#39;: &#39;default&#39;,
        },
        &#39;spec&#39;: {
            &#39;selector&#39;: {
                &#39;matchLabels&#39;: {
                    &#39;app&#39;: &#39;test-statefulset&#39;
                }
            },
            &#39;serviceName&#39;: &#39;test-statefulset&#39;,
            &#39;replicas&#39;: 2,
            &#39;template&#39;: {
                &#39;metadata&#39;: {
                    &#39;labels&#39;: {
                        &#39;app&#39;: &#39;test-statefulset&#39;
                    }
                },
                &#39;spec&#39;: {
                    &#39;terminationGracePeriodSeconds&#39;: 10,
                    &#39;containers&#39;: [{
                        &#39;image&#39;: &#39;busybox:1.34.0&#39;,
                        &#39;imagePullPolicy&#39;: &#39;IfNotPresent&#39;,
                        &#39;name&#39;: &#39;sleep&#39;,
                        &#39;args&#39;: [
                            &#39;/bin/sh&#39;,
                            &#39;-c&#39;,
                            &#39;while true;do date;sleep 5; done&#39;
                        ],
                        &#39;volumeMounts&#39;: [{
                            &#39;name&#39;: &#39;pod-data&#39;,
                            &#39;mountPath&#39;: &#39;/data&#39;
                        }]
                    }]
                }
            },
            &#39;volumeClaimTemplates&#39;: [{
                &#39;metadata&#39;: {
                    &#39;name&#39;: &#39;pod-data&#39;
                },
                &#39;spec&#39;: {
                    &#39;accessModes&#39;: [
                        &#39;ReadWriteOnce&#39;
                    ],
                    &#39;storageClassName&#39;: DEFAULT_STORAGECLASS_NAME,
                    &#39;resources&#39;: {
                        &#39;requests&#39;: {
                            &#39;storage&#39;: size_to_string(
                                           DEFAULT_VOLUME_SIZE * Gi)
                        }
                    }
                }
            }]
        }
    }

    def finalizer():
        api = get_core_api_client()
        client = get_longhorn_api_client()
        delete_and_wait_statefulset(api, client, statefulset_manifest)

    request.addfinalizer(finalizer)

    return statefulset_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.storage_class"><code class="name flex">
<span>def <span class="ident">storage_class</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def storage_class(request):
    sc_manifest = {
        &#39;apiVersion&#39;: &#39;storage.k8s.io/v1&#39;,
        &#39;kind&#39;: &#39;StorageClass&#39;,
        &#39;metadata&#39;: {
            &#39;name&#39;: DEFAULT_STORAGECLASS_NAME
        },
        &#39;provisioner&#39;: &#39;driver.longhorn.io&#39;,
        &#39;allowVolumeExpansion&#39;: True,
        &#39;parameters&#39;: {
            &#39;numberOfReplicas&#39;: DEFAULT_LONGHORN_PARAMS[&#39;numberOfReplicas&#39;],
            &#39;staleReplicaTimeout&#39;:
                DEFAULT_LONGHORN_PARAMS[&#39;staleReplicaTimeout&#39;]
        },
        &#39;reclaimPolicy&#39;: &#39;Delete&#39;
    }

    def finalizer():
        api = get_storage_api_client()
        try:
            api.delete_storage_class(name=sc_manifest[&#39;metadata&#39;][&#39;name&#39;],
                                     body=k8sclient.V1DeleteOptions())
        except ApiException as e:
            assert e.status == 404

    request.addfinalizer(finalizer)

    return sc_manifest</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.sts_name"><code class="name flex">
<span>def <span class="ident">sts_name</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def sts_name(request):
    return generate_sts_name()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.system_backup_feature_supported"><code class="name flex">
<span>def <span class="ident">system_backup_feature_supported</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_backup_feature_supported(client):
    if hasattr(client.by_id_schema(&#34;systemBackup&#34;), &#34;id&#34;):
        return True
    else:
        return False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.system_backup_random_name"><code class="name flex">
<span>def <span class="ident">system_backup_random_name</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_backup_random_name():
    return &#34;test-system-backup-&#34; + \
        &#39;&#39;.join(random.choice(string.ascii_lowercase + string.digits)
                for _ in range(6))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.system_backup_wait_for_state"><code class="name flex">
<span>def <span class="ident">system_backup_wait_for_state</span></span>(<span>state, name, client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_backup_wait_for_state(state, name, client):  # NOQA
    ok = False
    for _ in range(RETRY_COUNTS):
        try:
            system_backup = client.by_id_system_backup(name)
            assert system_backup.state == state
            ok = True
            break
        except Exception:
            time.sleep(RETRY_INTERVAL)

    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.system_backups_cleanup"><code class="name flex">
<span>def <span class="ident">system_backups_cleanup</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_backups_cleanup(client):
    &#34;&#34;&#34;
    Clean up all system backups
    :param client: The Longhorn client to use in the request.
    &#34;&#34;&#34;

    system_backups = client.list_system_backup()
    for system_backup in system_backups:
        # ignore the error when clean up
        try:
            client.delete(system_backup)
        except Exception as e:
            name = system_backup[&#39;name&#39;]
            print(&#34;\nException when cleanup system backup &#34;, name)
            print(e)

    ok = False
    for _ in range(RETRY_COUNTS):
        system_backups = client.list_system_backup()
        if len(system_backups) == 0:
            ok = True
            break
        time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"><p>Clean up all system backups
:param client: The Longhorn client to use in the request.</p></div>
</dd>
<dt id="tests.common.system_restore_random_name"><code class="name flex">
<span>def <span class="ident">system_restore_random_name</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_restore_random_name():
    return &#34;test-system-restore-&#34; + \
        &#39;&#39;.join(random.choice(string.ascii_lowercase + string.digits)
                for _ in range(6))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.system_restore_wait_for_state"><code class="name flex">
<span>def <span class="ident">system_restore_wait_for_state</span></span>(<span>state, name, client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_restore_wait_for_state(state, name, client):  # NOQA
    ok = False
    for _ in range(RETRY_COUNTS):
        system_restore = client.by_id_system_restore(name)
        try:
            system_restore = client.by_id_system_restore(name)
            assert system_restore.state == state
            ok = True
            break
        except Exception:
            time.sleep(RETRY_INTERVAL_LONG)

    assert ok, \
        f&#34; Expected state {state}, &#34; \
        f&#34; but got {system_restore.state} after {RETRY_COUNTS} attempts&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.system_restores_cleanup"><code class="name flex">
<span>def <span class="ident">system_restores_cleanup</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_restores_cleanup(client):
    &#34;&#34;&#34;
    Clean up all system restores
    :param client: The Longhorn client to use in the request.
    &#34;&#34;&#34;

    system_restores = client.list_system_restore()
    for system_restore in system_restores:
        # ignore the error when clean up
        try:
            client.delete(system_restore)
        except Exception as e:
            name = system_restore[&#39;name&#39;]
            print(&#34;\nException when cleanup system restore &#34;, name)
            print(e)

    ok = False
    for _ in range(RETRY_COUNTS):
        system_restores = client.list_system_restore()
        if len(system_restores) == 0:
            ok = True
            break
        time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"><p>Clean up all system restores
:param client: The Longhorn client to use in the request.</p></div>
</dd>
<dt id="tests.common.umount_disk"><code class="name flex">
<span>def <span class="ident">umount_disk</span></span>(<span>mount_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def umount_disk(mount_path):
    cmd = [&#39;umount&#39;, mount_path]
    subprocess.check_call(cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.update_node_disks"><code class="name flex">
<span>def <span class="ident">update_node_disks</span></span>(<span>client, node_name, disks, retry=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_node_disks(client, node_name, disks, retry=False):
    node = client.by_id_node(node_name)

    if not retry:
        return node.diskUpdate(disks=disks)

    # Retry if &#34;too many retries error&#34; happened.
    for _ in range(NODE_UPDATE_RETRY_COUNT):
        try:
            node = node.diskUpdate(disks=disks)
        except Exception as e:
            if disk_being_syncing in str(e.error.message):
                time.sleep(NODE_UPDATE_RETRY_INTERVAL)
                continue
            print(e)
            raise
        else:
            break
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.update_persistent_volume_claim"><code class="name flex">
<span>def <span class="ident">update_persistent_volume_claim</span></span>(<span>core_api, name, namespace, claim)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_persistent_volume_claim(core_api, name, namespace, claim):
    for _ in range(RETRY_COUNTS):
        try:
            core_api.replace_namespaced_persistent_volume_claim(
                name, namespace, claim
            )
            break
        except Exception as e:
            print(e)
            time.sleep(RETRY_INTERVAL)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.update_recurring_job"><code class="name flex">
<span>def <span class="ident">update_recurring_job</span></span>(<span>client, name, groups, labels, cron='', retain=0, concurrency=0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_recurring_job(client, name, groups, labels, # NOQA
                         cron=&#34;&#34;, retain=0, concurrency=0):
    recurringJob = client.by_id_recurring_job(name)

    update_groups = groups
    update_labels = labels
    update_cron = cron if len(cron) != 0 else recurringJob[&#34;cron&#34;]
    update_retain = retain if retain != 0 else recurringJob[&#34;retain&#34;]
    update_concurrency = \
        concurrency if concurrency != 0 else recurringJob[&#34;concurrency&#34;]

    client.update(recurringJob,
                  groups=update_groups,
                  task=recurringJob[&#34;task&#34;],
                  cron=update_cron,
                  retain=update_retain,
                  concurrency=update_concurrency,
                  labels=update_labels)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.update_setting"><code class="name flex">
<span>def <span class="ident">update_setting</span></span>(<span>client, name, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_setting(client, name, value):
    for _ in range(RETRY_COUNTS):
        try:
            setting = client.by_id_setting(name)
            setting = client.update(setting, value=value)
            break
        except Exception as e:
            print(e)
            time.sleep(RETRY_INTERVAL)
    value = &#34;&#34; if value is None else value
    assert setting.value == value, \
        f&#34;expect update setting {name} to be {value}, but it&#39;s {setting.value}&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.update_statefulset_manifests"><code class="name flex">
<span>def <span class="ident">update_statefulset_manifests</span></span>(<span>ss_manifest, sc_manifest, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_statefulset_manifests(ss_manifest, sc_manifest, name):
    &#34;&#34;&#34;
    Write in a new StatefulSet name and the proper StorageClass name for tests.
    &#34;&#34;&#34;
    ss_manifest[&#39;metadata&#39;][&#39;name&#39;] = \
        ss_manifest[&#39;spec&#39;][&#39;selector&#39;][&#39;matchLabels&#39;][&#39;app&#39;] = \
        ss_manifest[&#39;spec&#39;][&#39;serviceName&#39;] = \
        ss_manifest[&#39;spec&#39;][&#39;template&#39;][&#39;metadata&#39;][&#39;labels&#39;][&#39;app&#39;] = \
        name
    ss_manifest[&#39;spec&#39;][&#39;volumeClaimTemplates&#39;][0][&#39;spec&#39;][&#39;storageClassName&#39;]\
        = DEFAULT_STORAGECLASS_NAME
    sc_manifest[&#39;metadata&#39;][&#39;name&#39;] = DEFAULT_STORAGECLASS_NAME</code></pre>
</details>
<div class="desc"><p>Write in a new StatefulSet name and the proper StorageClass name for tests.</p></div>
</dd>
<dt id="tests.common.v2_data_engine_cr_supported"><code class="name flex">
<span>def <span class="ident">v2_data_engine_cr_supported</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def v2_data_engine_cr_supported(client):
    longhorn_version = client.by_id_setting(&#39;current-longhorn-version&#39;).value
    version_doesnt_support_v2_backimg_image = [&#39;v1.5&#39;, &#39;v1.6&#39;, &#39;v1.7&#39;]
    if any(_version in longhorn_version for
           _version in version_doesnt_support_v2_backimg_image):
        print(f&#39;{longhorn_version} doesn\&#39;t support v2 cr for test&#39;)
        return False
    else:
        return True</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.volume_name"><code class="name flex">
<span>def <span class="ident">volume_name</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture
def volume_name(request):
    return generate_volume_name()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.volume_read"><code class="name flex">
<span>def <span class="ident">volume_read</span></span>(<span>v, start, count)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def volume_read(v, start, count):
    dev = get_volume_endpoint(v)
    return dev_read(dev, start, count)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.volume_valid"><code class="name flex">
<span>def <span class="ident">volume_valid</span></span>(<span>dev)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def volume_valid(dev):
    return stat.S_ISBLK(os.stat(dev).st_mode)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.volume_write"><code class="name flex">
<span>def <span class="ident">volume_write</span></span>(<span>v, start, data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def volume_write(v, start, data):
    dev = get_volume_endpoint(v)
    return dev_write(dev, start, data)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_and_get_any_deployment_pod"><code class="name flex">
<span>def <span class="ident">wait_and_get_any_deployment_pod</span></span>(<span>core_api, deployment_name, is_phase='Running')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_and_get_any_deployment_pod(core_api, deployment_name,
                                    is_phase=&#34;Running&#34;):
    &#34;&#34;&#34;
    Add mechanism to wait for a stable running pod when deployment restarts its
    workload, since Longhorn manager could create/delete the new workload pod
    multiple times, it&#39;s possible that we get an unstable pod which will be
    deleted immediately, so add a wait mechanism to get a stable running pod.
    ref: https://github.com/longhorn/longhorn/issues/4814
    &#34;&#34;&#34;
    stable_pod = None
    wait_for_stable_retry = 0

    for _ in range(DEFAULT_DEPLOYMENT_TIMEOUT):
        label_selector = &#34;name=&#34; + deployment_name
        pods = core_api.list_namespaced_pod(namespace=&#34;default&#34;,
                                            label_selector=label_selector)
        for pod in pods.items:
            if pod.status.phase == is_phase:
                if stable_pod is None or \
                        stable_pod.status.start_time != pod.status.start_time:
                    stable_pod = pod
                    wait_for_stable_retry = 0
                    break
                else:
                    wait_for_stable_retry += 1
                    if wait_for_stable_retry == WAIT_FOR_POD_STABLE_MAX_RETRY:
                        return stable_pod

        time.sleep(DEFAULT_DEPLOYMENT_INTERVAL)
    assert False</code></pre>
</details>
<div class="desc"><p>Add mechanism to wait for a stable running pod when deployment restarts its
workload, since Longhorn manager could create/delete the new workload pod
multiple times, it's possible that we get an unstable pod which will be
deleted immediately, so add a wait mechanism to get a stable running pod.
ref: <a href="https://github.com/longhorn/longhorn/issues/4814">https://github.com/longhorn/longhorn/issues/4814</a></p></div>
</dd>
<dt id="tests.common.wait_and_get_pv_for_pvc"><code class="name flex">
<span>def <span class="ident">wait_and_get_pv_for_pvc</span></span>(<span>api, pvc_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_and_get_pv_for_pvc(api, pvc_name):
    found = False
    for i in range(RETRY_COUNTS):
        pvs = api.list_persistent_volume()
        for item in pvs.items:
            if item.spec.claim_ref.name == pvc_name:
                found = True
                pv = item
                break
        if found:
            break
        time.sleep(RETRY_INTERVAL)

    assert found
    return pv</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_delete_deployment"><code class="name flex">
<span>def <span class="ident">wait_delete_deployment</span></span>(<span>apps_api, deployment_name, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_delete_deployment(apps_api, deployment_name, namespace=&#39;default&#39;):
    for i in range(DEFAULT_DEPLOYMENT_TIMEOUT):
        ret = apps_api.list_namespaced_deployment(namespace=namespace)
        found = False
        for item in ret.items:
            if item.metadata.name == deployment_name:
                found = True
                break
        if not found:
            break
        time.sleep(DEFAULT_DEPLOYMENT_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_delete_dm_device"><code class="name flex">
<span>def <span class="ident">wait_delete_dm_device</span></span>(<span>api, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_delete_dm_device(api, name):
    path = os.path.join(&#34;/dev/mapper&#34;, name)
    for i in range(RETRY_COUNTS):
        found = os.path.exists(path)
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_delete_pod"><code class="name flex">
<span>def <span class="ident">wait_delete_pod</span></span>(<span>api, pod_uid, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_delete_pod(api, pod_uid, namespace=&#39;default&#39;):
    for i in range(POD_DELETION_TIMEOUT):
        ret = api.list_namespaced_pod(namespace=namespace)
        found = False
        for item in ret.items:
            if item.metadata.uid == pod_uid:
                found = True
                break
        if not found:
            break
        time.sleep(DEFAULT_POD_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_delete_pv"><code class="name flex">
<span>def <span class="ident">wait_delete_pv</span></span>(<span>api, pv_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_delete_pv(api, pv_name):
    for i in range(RETRY_COUNTS):
        found = False
        pvs = api.list_persistent_volume()
        for item in pvs.items:
            if item.metadata.name == pv_name:
                if item.status.phase == &#39;Failed&#39;:
                    try:
                        api.delete_persistent_volume(
                            name=pv_name, body=k8sclient.V1DeleteOptions())
                    except ApiException as e:
                        assert e.status == 404
                else:
                    found = True
                    break
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_delete_pvc"><code class="name flex">
<span>def <span class="ident">wait_delete_pvc</span></span>(<span>api, pvc_name, retry_counts=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_delete_pvc(api, pvc_name, retry_counts=RETRY_COUNTS):
    for _ in range(retry_counts):
        found = False
        ret = api.list_namespaced_persistent_volume_claim(namespace=&#39;default&#39;)
        for item in ret.items:
            if item.metadata.name == pvc_name:
                found = True
                break
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_delete_volume_attachment"><code class="name flex">
<span>def <span class="ident">wait_delete_volume_attachment</span></span>(<span>storage_api, volume_attachment_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_delete_volume_attachment(storage_api, volume_attachment_name):
    for i in range(RETRY_COUNTS):
        found = False
        ret = storage_api.list_volume_attachment()
        for item in ret.items:
            if item.metadata.name == volume_attachment_name:
                found = True
                break
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_deployment_replica_ready"><code class="name flex">
<span>def <span class="ident">wait_deployment_replica_ready</span></span>(<span>apps_api, deployment_name, desired_replica_count, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_deployment_replica_ready(apps_api, deployment_name,
                                  desired_replica_count, namespace=&#39;default&#39;):  # NOQA
    ok = False
    for i in range(DEFAULT_DEPLOYMENT_TIMEOUT):
        deployment = apps_api.read_namespaced_deployment(
            name=deployment_name,
            namespace=namespace)

        # deployment is none if deployment is not yet created
        if deployment is not None and \
           deployment.status.ready_replicas == desired_replica_count:
            ok = True
            break

        time.sleep(DEFAULT_DEPLOYMENT_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_all_instance_manager_running"><code class="name flex">
<span>def <span class="ident">wait_for_all_instance_manager_running</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_all_instance_manager_running(client):
    core_api = get_core_api_client()

    nodes = client.list_node()

    for _ in range(RETRY_COUNTS):
        instance_managers = client.list_instance_manager()
        node_to_instance_manager_map = {}
        try:
            for im in instance_managers:
                if im.managerType == &#34;aio&#34;:
                    node_to_instance_manager_map[im.nodeID] = im
                else:
                    print(&#34;\nFound unknown instance manager:&#34;, im)
            if len(node_to_instance_manager_map) != len(nodes):
                time.sleep(RETRY_INTERVAL)
                continue

            for _, im in node_to_instance_manager_map.items():
                wait_for_instance_manager_desire_state(client, core_api,
                                                       im.name, &#34;Running&#34;,
                                                       True)
            break
        except Exception:
            continue</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backing_image_delete"><code class="name flex">
<span>def <span class="ident">wait_for_backing_image_delete</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backing_image_delete(client, name):
    found = False
    for i in range(RETRY_COUNTS):
        bi_list = client.list_backing_image()
        found = False
        for bi in bi_list:
            if bi.name == name:
                found = True
                break
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backing_image_disk_cleanup"><code class="name flex">
<span>def <span class="ident">wait_for_backing_image_disk_cleanup</span></span>(<span>client, bi_name, disk_id)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backing_image_disk_cleanup(client, bi_name, disk_id):
    found = False
    for i in range(RETRY_COUNTS):
        found = False
        bi = client.by_id_backing_image(bi_name)
        for disk, status in iter(bi.diskFileStatusMap.items()):
            if disk == disk_id:
                found = True
                break
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found
    return bi</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backing_image_in_disk_fail"><code class="name flex">
<span>def <span class="ident">wait_for_backing_image_in_disk_fail</span></span>(<span>client, backing_img_name, disk_uuid)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backing_image_in_disk_fail(client, backing_img_name, disk_uuid):

    failed = False
    for i in range(RETRY_BACKUP_COUNTS):
        if failed is False:
            backing_image = client.by_id_backing_image(backing_img_name)
            for uuid, status in iter(backing_image.diskFileStatusMap.items()):
                if uuid == disk_uuid and status.state == &#34;failed&#34;:
                    failed = True
        if failed is True:
            break
        time.sleep(0.1)
    assert failed is True</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backing_image_status"><code class="name flex">
<span>def <span class="ident">wait_for_backing_image_status</span></span>(<span>client, backing_img_name, image_status)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backing_image_status(client, backing_img_name, image_status):

    status_matched = False
    for _ in range(RETRY_EXEC_COUNTS):
        if status_matched:
            break

        backing_image = client.by_id_backing_image(backing_img_name)
        try:
            if backing_image.diskFileStatusMap.items():
                for _, status in iter(backing_image.diskFileStatusMap.items()):
                    if status.state == image_status:
                        status_matched = True
        except Exception as e:
            print(e)
        time.sleep(RETRY_EXEC_INTERVAL)

    assert status_matched is True</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_backing_image_delete"><code class="name flex">
<span>def <span class="ident">wait_for_backup_backing_image_delete</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_backing_image_delete(client, name):
    for _ in range(RETRY_COUNTS):
        bbis = client.list_backupBackingImage()
        found = False
        for bbi in bbis:
            if bbi.name == name:
                found = True
                break
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_completion"><code class="name flex">
<span>def <span class="ident">wait_for_backup_completion</span></span>(<span>client, volume_name, snapshot_name=None, retry_count=300)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_completion(client, volume_name, snapshot_name=None,
                               retry_count=RETRY_BACKUP_COUNTS):
    completed = False
    for _ in range(retry_count):
        v = client.by_id_volume(volume_name)
        for b in v.backupStatus:
            if snapshot_name is not None and b.snapshot != snapshot_name:
                continue
            if b.state == &#34;Completed&#34;:
                assert b.progress == 100
                assert b.error == &#34;&#34;
                completed = True
                break
        if completed:
            break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert completed is True, f&#34; Backup status = {b.state},&#34; \
                              f&#34; Backup Progress = {b.progress}, Volume = {v}&#34;
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_count"><code class="name flex">
<span>def <span class="ident">wait_for_backup_count</span></span>(<span>backup_volume, number, retry_counts=120)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_count(backup_volume, number, retry_counts=120):
    ok = False
    for _ in range(retry_counts):

        complete_backup_cnt = 0
        for single_backup in backup_volume.backupList():
            if single_backup.state == &#34;Completed&#34; and \
                                        int(single_backup.volumeSize) &gt; 0:
                complete_backup_cnt = complete_backup_cnt + 1

        if complete_backup_cnt == number:
            ok = True
            break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_delete"><code class="name flex">
<span>def <span class="ident">wait_for_backup_delete</span></span>(<span>client, volume_name, backup_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_delete(client, volume_name, backup_name):

    def backup_exists():
        bv = find_backup_volume(client, volume_name)
        if bv is not None:
            backups = bv.backupList()
            for b in backups:
                if b.name == backup_name:
                    return True
        return False

    for i in range(RETRY_BACKUP_COUNTS):
        if backup_exists() is False:
            return
        time.sleep(RETRY_BACKUP_INTERVAL)

    assert False, &#34;deleted backup &#34; + backup_name + &#34; for volume &#34; \
                  + volume_name + &#34; is still present&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_failed"><code class="name flex">
<span>def <span class="ident">wait_for_backup_failed</span></span>(<span>client, volume_name, snapshot_name=None, retry_count=300)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_failed(client, volume_name, snapshot_name=None,
                           retry_count=RETRY_BACKUP_COUNTS):
    failed = False
    for _ in range(retry_count):
        v = client.by_id_volume(volume_name)
        for b in v.backupStatus:
            if b.state == &#34;Error&#34;:
                assert b.progress == 0
                assert b.error != &#34;&#34;
                failed = True
                break
        if failed:
            break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert failed is True
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_restore_completed"><code class="name flex">
<span>def <span class="ident">wait_for_backup_restore_completed</span></span>(<span>client, name, backup_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_restore_completed(client, name, backup_name):
    complete = False
    for i in range(RETRY_COUNTS):
        v = client.by_id_volume(name)
        if v.controllers and len(v.controllers) != 0 and \
                v.controllers[0].lastRestoredBackup == backup_name:
            complete = True
            break
        time.sleep(RETRY_INTERVAL_LONG)
    assert complete</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_state"><code class="name flex">
<span>def <span class="ident">wait_for_backup_state</span></span>(<span>client, volume_name, predicate, retry_count=300)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_state(client, volume_name, predicate,
                          retry_count=RETRY_BACKUP_COUNTS):
    completed = False
    for i in range(retry_count):
        v = client.by_id_volume(volume_name)
        for b in v.backupStatus:
            if predicate(b):
                completed = True
                break
        if completed:
            break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert completed is True
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_target_available"><code class="name flex">
<span>def <span class="ident">wait_for_backup_target_available</span></span>(<span>client, available)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_target_available(client, available):
    def find_backup_target_default(client):
        bt = client.list_backup_target()
        assert bt is not None
        return bt.data[0]

    for _ in range(RETRY_COUNTS):
        bt = find_backup_target_default(client)
        if bt.available == available:
            break
        time.sleep(RETRY_INTERVAL)
    if bt.available != available:
        raise Exception(
            &#39;BackupTarget status.available should be {}&#39;, available)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_to_start"><code class="name flex">
<span>def <span class="ident">wait_for_backup_to_start</span></span>(<span>client, volume_name, snapshot_name=None, retry_count=300, chk_progress=0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_to_start(client, volume_name, snapshot_name=None,
                             retry_count=RETRY_BACKUP_COUNTS,
                             chk_progress=0):
    in_progress = False
    for _ in range(retry_count):
        v = client.by_id_volume(volume_name)
        for b in v.backupStatus:
            if snapshot_name is not None and b.snapshot != snapshot_name:
                continue
            if b.state == &#34;InProgress&#34; and b.progress &gt; chk_progress:
                assert b.error == &#34;&#34;
                in_progress = True
                break
        if in_progress:
            break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert in_progress is True
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_volume"><code class="name flex">
<span>def <span class="ident">wait_for_backup_volume</span></span>(<span>client, bv_name, backing_image='')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_volume(client, bv_name, backing_image=&#34;&#34;):
    for _ in range(RETRY_BACKUP_COUNTS):
        bv = client.by_id_backupVolume(bv_name)
        if bv is not None:
            if backing_image == &#34;&#34;:
                break
            if bv.backingImageName == backing_image \
                    and bv.backingImageChecksum != &#34;&#34;:
                break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert bv is not None, &#34;failed to find backup volume &#34; + bv_name</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_volume_backing_image_synced"><code class="name flex">
<span>def <span class="ident">wait_for_backup_volume_backing_image_synced</span></span>(<span>client, volume_name, backing_image, retry_count=300)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_volume_backing_image_synced(
        client, volume_name, backing_image, retry_count=RETRY_BACKUP_COUNTS):

    completed = False
    for _ in range(retry_count):
        bv = find_backup_volume(client, volume_name)
        if bv is not None:
            if bv.backingImageName == backing_image:
                completed = True
                break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert completed is True, f&#34; Backup Volume = {bv},&#34; \
                              f&#34; Backing Image = {backing_image},&#34; \
                              f&#34; Volume = {volume_name}&#34;
    return bv</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_backup_volume_delete"><code class="name flex">
<span>def <span class="ident">wait_for_backup_volume_delete</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_backup_volume_delete(client, name):
    for _ in range(RETRY_BACKUP_COUNTS):
        bvs = client.list_backupVolume()
        found = False
        for bv in bvs:
            if bv.name == name:
                found = True
                break
        if not found:
            break
        time.sleep(RETRY_BACKUP_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_cron_job_count"><code class="name flex">
<span>def <span class="ident">wait_for_cron_job_count</span></span>(<span>batch_v1_api, number, label='', retry_counts=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_cron_job_count(batch_v1_api, number, label=&#34;&#34;,
                            retry_counts=RETRY_COUNTS):
    ok = False
    for _ in range(retry_counts):
        jobs = batch_v1_api.list_namespaced_cron_job(&#39;longhorn-system&#39;,
                                                     label_selector=label)
        if len(jobs.items) == number:
            ok = True
            break
        time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_cron_job_create"><code class="name flex">
<span>def <span class="ident">wait_for_cron_job_create</span></span>(<span>batch_v1_api, label='', retry_counts=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_cron_job_create(batch_v1_api, label=&#34;&#34;,
                             retry_counts=RETRY_COUNTS):
    exist = False
    for _ in range(retry_counts):
        job = batch_v1_api.list_namespaced_cron_job(&#39;longhorn-system&#39;,
                                                    label_selector=label)
        if len(job.items) != 0:
            exist = True
            break
        time.sleep(RETRY_INTERVAL)

    assert exist</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_cron_job_delete"><code class="name flex">
<span>def <span class="ident">wait_for_cron_job_delete</span></span>(<span>batch_v1_api, label='', retry_counts=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_cron_job_delete(batch_v1_api, label=&#34;&#34;,
                             retry_counts=RETRY_COUNTS):
    exist = True
    for _ in range(retry_counts):
        job = batch_v1_api.list_namespaced_cron_job(&#39;longhorn-system&#39;,
                                                    label_selector=label)
        if len(job.items) == 0:
            exist = False
            break
        time.sleep(RETRY_INTERVAL)

    assert not exist</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_deployed_engine_image_count"><code class="name flex">
<span>def <span class="ident">wait_for_deployed_engine_image_count</span></span>(<span>client, image_name, expected_cnt, exclude_nodes=[])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_deployed_engine_image_count(client, image_name, expected_cnt,
                                         exclude_nodes=[]):
    for i in range(RETRY_COUNTS):
        time.sleep(RETRY_INTERVAL)
        image = client.by_id_engine_image(image_name)
        deployed_cnt = 0
        if image.nodeDeploymentMap is None:
            continue
        for node_name in image.nodeDeploymentMap:
            if node_name in exclude_nodes:
                continue
            if image.nodeDeploymentMap[node_name] is True:
                deployed_cnt = deployed_cnt + 1
        if deployed_cnt == expected_cnt:
            break

    assert deployed_cnt == expected_cnt, f&#34;image = {image}&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_device_login"><code class="name flex">
<span>def <span class="ident">wait_for_device_login</span></span>(<span>dest_path, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_device_login(dest_path, name):
    dev = &#34;&#34;
    for i in range(RETRY_COUNTS):
        for j in range(RETRY_COMMAND_COUNT):
            files = []
            try:
                files = os.listdir(dest_path)
                break
            except Exception:
                time.sleep(1)
        assert files
        if name in files:
            dev = name
            break
        time.sleep(RETRY_INTERVAL)
    assert dev == name
    return dev</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_disk_conditions"><code class="name flex">
<span>def <span class="ident">wait_for_disk_conditions</span></span>(<span>client, node_name, disk_name, key, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_disk_conditions(client, node_name, disk_name, key, value):
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(node_name)
        disks = node.disks
        disk = disks[disk_name]
        conditions = disk.conditions
        if conditions[key][&#34;status&#34;] == value:
            break
        time.sleep(RETRY_INTERVAL)
    assert conditions[key][&#34;status&#34;] == value
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_disk_status"><code class="name flex">
<span>def <span class="ident">wait_for_disk_status</span></span>(<span>client, node_name, disk_name, key, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_disk_status(client, node_name, disk_name, key, value):
    # use wait_for_disk_storage_available to check storageAvailable
    assert key != &#34;storageAvailable&#34;
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(node_name)
        disks = node.disks
        if len(disks) &gt; 0 and \
                disk_name in disks and \
                disks[disk_name][key] == value:
            break
        time.sleep(RETRY_INTERVAL)
    assert len(disks) != 0
    assert disk_name in disks
    assert disks[disk_name][key] == value, \
        f&#34;Wrong disk({disk_name}) {key} status.\n&#34; \
        f&#34;Expect={value}\n&#34; \
        f&#34;Got={disks[disk_name][key]}\n&#34; \
        f&#34;node={client.by_id_node(node_name)}\n&#34; \
        f&#34;volumes={client.list_volume()}\n&#34;
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_disk_storage_available"><code class="name flex">
<span>def <span class="ident">wait_for_disk_storage_available</span></span>(<span>client, node_name, disk_name, disk_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_disk_storage_available(client, node_name, disk_name, disk_path):
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(node_name)
        disks = node.disks
        if len(disks) &gt; 0 and disk_name in disks:
            free, _ = get_host_disk_size(disk_path)
            if disks[disk_name][&#34;storageAvailable&#34;] == free:
                break
        time.sleep(RETRY_INTERVAL)
    assert len(disks) != 0
    assert disk_name in disks
    assert disks[disk_name][&#34;storageAvailable&#34;] == free
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_disk_update"><code class="name flex">
<span>def <span class="ident">wait_for_disk_update</span></span>(<span>client, name, disk_num)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_disk_update(client, name, disk_num):
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(name)
        if len(node.disks) == disk_num:
            allUpdated = True
            disks = node.disks
            for d in disks:
                if disks[d][&#34;diskUUID&#34;] == &#34;&#34;:
                    allUpdated = False
                    break
            if allUpdated:
                break
        time.sleep(RETRY_INTERVAL)
    assert len(node.disks) == disk_num
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_disk_uuid"><code class="name flex">
<span>def <span class="ident">wait_for_disk_uuid</span></span>(<span>client, node_name, uuid)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_disk_uuid(client, node_name, uuid):
    found = False
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(node_name)
        disks = node.disks
        for name in disks:
            if disks[name][&#34;diskUUID&#34;] == uuid:
                found = True
                break
        if found:
            break
        time.sleep(RETRY_INTERVAL)
    assert found
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_dr_volume_expansion"><code class="name flex">
<span>def <span class="ident">wait_for_dr_volume_expansion</span></span>(<span>longhorn_api_client, volume_name, size_str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_dr_volume_expansion(longhorn_api_client, volume_name, size_str):
    complete = False
    for i in range(RETRY_COUNTS):
        volume = longhorn_api_client.by_id_volume(volume_name)
        if volume.size == size_str:
            engine = get_volume_engine(volume)
            if engine.size == volume.size:
                complete = True
                break
        time.sleep(RETRY_INTERVAL_LONG)
    assert complete</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_engine_image_condition"><code class="name flex">
<span>def <span class="ident">wait_for_engine_image_condition</span></span>(<span>client, image_name, state)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_engine_image_condition(client, image_name, state):
    &#34;&#34;&#34;
    state: &#34;True&#34;, &#34;False&#34;
    &#34;&#34;&#34;
    # Indicate many times we want to see the ENGINE_NAME in the STATE.
    # This helps to prevent the flaky test case in which the ENGINE_NAME
    # is flapping between ready and not ready a few times before settling
    # down to the ready state
    # https://github.com/longhorn/longhorn/issues/7438
    state_count = 1
    if state == &#34;True&#34;:
        state_count = 60

    c = 0
    for i in range(RETRY_COUNTS):
        wait_for_engine_image_creation(client, image_name)
        image = client.by_id_engine_image(image_name)
        if image[&#39;conditions&#39;][0][&#39;status&#39;] == state:
            c += 1
            if c &gt;= state_count:
                break
        time.sleep(RETRY_INTERVAL_SHORT)
    assert image[&#39;conditions&#39;][0][&#39;status&#39;] == state
    return image</code></pre>
</details>
<div class="desc"><p>state: "True", "False"</p></div>
</dd>
<dt id="tests.common.wait_for_engine_image_creation"><code class="name flex">
<span>def <span class="ident">wait_for_engine_image_creation</span></span>(<span>client, image_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_engine_image_creation(client, image_name):
    for i in range(RETRY_COUNTS):
        images = client.list_engine_image()
        found = False
        for img in images:
            if img.name == image_name:
                found = True
                break
        if found:
            break
        time.sleep(RETRY_INTERVAL_SHORT)
    assert found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_engine_image_deletion"><code class="name flex">
<span>def <span class="ident">wait_for_engine_image_deletion</span></span>(<span>client, core_api, engine_image_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_engine_image_deletion(client, core_api, engine_image_name):
    deleted = False

    for i in range(RETRY_COUNTS):
        time.sleep(RETRY_INTERVAL)
        deleted = True

        ei_list = client.list_engine_image().data
        for ei in ei_list:
            if ei.name == engine_image_name:
                deleted = False
                break
        if not deleted:
            continue

        labels = &#34;longhorn.io/component=engine-image,&#34; \
                 &#34;longhorn.io/engine-image=&#34;+engine_image_name
        ei_pod_list = core_api.list_namespaced_pod(
            LONGHORN_NAMESPACE, label_selector=labels).items
        if len(ei_pod_list) != 0:
            deleted = False
            continue
        if deleted:
            break

    assert deleted</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_engine_image_incompatible"><code class="name flex">
<span>def <span class="ident">wait_for_engine_image_incompatible</span></span>(<span>client, image_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_engine_image_incompatible(client, image_name):
    wait_for_engine_image_creation(client, image_name)
    for i in range(RETRY_COUNTS):
        image = client.by_id_engine_image(image_name)
        if image.incompatible:
            break
        time.sleep(RETRY_INTERVAL)
    assert image.incompatible
    return image</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_engine_image_ref_count"><code class="name flex">
<span>def <span class="ident">wait_for_engine_image_ref_count</span></span>(<span>client, image_name, count)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_engine_image_ref_count(client, image_name, count):
    wait_for_engine_image_creation(client, image_name)
    for i in range(RETRY_COUNTS):
        image = client.by_id_engine_image(image_name)
        if image.refCount == count:
            break
        time.sleep(RETRY_INTERVAL)
    assert image.refCount == count, f&#34;image = {image}&#34;
    if count == 0:
        assert image.noRefSince != &#34;&#34;
    return image</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_engine_image_state"><code class="name flex">
<span>def <span class="ident">wait_for_engine_image_state</span></span>(<span>client, image_name, state)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_engine_image_state(client, image_name, state):
    wait_for_engine_image_creation(client, image_name)
    for i in range(RETRY_COUNTS):
        image = client.by_id_engine_image(image_name)
        if image.state == state:
            break
        time.sleep(RETRY_INTERVAL)
    assert image.state == state
    return image</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_expansion_error_clear"><code class="name flex">
<span>def <span class="ident">wait_for_expansion_error_clear</span></span>(<span>longhorn_api_client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_expansion_error_clear(longhorn_api_client, volume_name):
    complete = False
    for i in range(RETRY_COUNTS):
        volume = longhorn_api_client.by_id_volume(volume_name)
        engine = get_volume_engine(volume)
        if engine.lastExpansionFailedAt == &#34;&#34; and \
                engine.lastExpansionError == &#34;&#34;:
            complete = True
            break
        time.sleep(RETRY_INTERVAL)
    assert complete</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_expansion_failure"><code class="name flex">
<span>def <span class="ident">wait_for_expansion_failure</span></span>(<span>client, volume_name, last_failed_at='')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_expansion_failure(client, volume_name, last_failed_at=&#34;&#34;):
    failed = False
    for i in range(30):
        volume = client.by_id_volume(volume_name)
        engine = get_volume_engine(volume)
        if engine.lastExpansionFailedAt != last_failed_at:
            failed = True
            break
        time.sleep(RETRY_INTERVAL)
    assert failed</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_instance_manager_count"><code class="name flex">
<span>def <span class="ident">wait_for_instance_manager_count</span></span>(<span>client, number, retry_counts=120)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_instance_manager_count(client, number, retry_counts=120):
    for _ in range(retry_counts):
        im_counts = 0
        ims = client.list_instance_manager()
        for im in ims:
            if im.dataEngine == DATA_ENGINE:
                im_counts = im_counts + 1

        if im_counts == number:
            break
        time.sleep(RETRY_INTERVAL_LONG)
    return im_counts</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_instance_manager_desire_state"><code class="name flex">
<span>def <span class="ident">wait_for_instance_manager_desire_state</span></span>(<span>client, core_api, im_name, state, desire=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_instance_manager_desire_state(client, core_api, im_name,
                                           state, desire=True):
    for i in range(RETRY_COUNTS_LONG):
        im = client.by_id_instance_manager(im_name)
        try:
            pod = core_api.read_namespaced_pod(name=im_name,
                                               namespace=LONGHORN_NAMESPACE)
        except Exception as e:
            # Continue with pod restarted case
            if e.reason == EXCEPTION_ERROR_REASON_NOT_FOUND:
                time.sleep(RETRY_INTERVAL)
                continue
            # Report any other error
            else:
                assert (not e)
        if desire:
            if im.currentState == state.lower() and pod.status.phase == state:
                break
        else:
            if im.currentState != state.lower() and pod.status.phase != state:
                break
        time.sleep(RETRY_INTERVAL)
    if desire:
        assert im.currentState == state.lower()
        assert pod.status.phase == state
    else:
        assert im.currentState != state.lower()
        assert pod.status.phase != state
    return im</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_node_mountpropagation_condition"><code class="name flex">
<span>def <span class="ident">wait_for_node_mountpropagation_condition</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_node_mountpropagation_condition(client, name):
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(name)
        conditions = {}
        if &#34;conditions&#34; in node.keys():
            conditions = node.conditions

        if NODE_CONDITION_MOUNTPROPAGATION in \
                conditions.keys() and \
                &#34;status&#34; in \
                conditions[NODE_CONDITION_MOUNTPROPAGATION].keys() \
                and conditions[NODE_CONDITION_MOUNTPROPAGATION][&#34;status&#34;] != \
                CONDITION_STATUS_UNKNOWN:
            break
        time.sleep(RETRY_INTERVAL)
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_node_schedulable_condition"><code class="name flex">
<span>def <span class="ident">wait_for_node_schedulable_condition</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_node_schedulable_condition(client, name):
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(name)
        conditions = {}
        if &#34;conditions&#34; in node.keys():
            conditions = node.conditions

        if NODE_CONDITION_SCHEDULABLE in \
                conditions.keys() and \
                &#34;status&#34; in \
                conditions[NODE_CONDITION_SCHEDULABLE].keys() \
                and conditions[NODE_CONDITION_SCHEDULABLE][&#34;status&#34;] != \
                CONDITION_STATUS_UNKNOWN:
            break
        time.sleep(RETRY_INTERVAL)
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_node_tag_update"><code class="name flex">
<span>def <span class="ident">wait_for_node_tag_update</span></span>(<span>client, name, tags)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_node_tag_update(client, name, tags):
    updated = False
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(name)
        if not tags and not node.tags:
            updated = True
            break
        elif node.tags is not None and set(node.tags) == set(tags):
            updated = True
            break
        time.sleep(RETRY_INTERVAL)
    assert updated
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_node_update"><code class="name flex">
<span>def <span class="ident">wait_for_node_update</span></span>(<span>client, name, key, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_node_update(client, name, key, value):
    for i in range(RETRY_COUNTS):
        node = client.by_id_node(name)
        if str(node[key]) == str(value):
            break
        time.sleep(RETRY_INTERVAL)
    assert str(node[key]) == str(value)
    return node</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_nvme_device"><code class="name flex">
<span>def <span class="ident">wait_for_nvme_device</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_nvme_device():
    for _ in range(RETRY_COUNTS):
        try:
            output = subprocess.check_output([&#34;nvme&#34;, &#34;list&#34;], text=True)
            print(f&#34;nvme list output =\n {output}&#34;)
            for line in output.splitlines():
                if &#34;SPDK bdev Controller&#34; in line:
                    dev_path = line.split()[0]
                    return dev_path
        except subprocess.CalledProcessError as e:
            print(f&#34;nvme list failed: {e.output}&#34;)
        time.sleep(RETRY_INTERVAL)

    raise Exception(&#34;NVMe device not found after retries&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_pod_annotation"><code class="name flex">
<span>def <span class="ident">wait_for_pod_annotation</span></span>(<span>core_api, label_selector, anno_key, anno_val)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_pod_annotation(core_api,
                            label_selector, anno_key, anno_val):
    matches = False
    for _ in range(RETRY_COUNTS):
        pods = core_api.list_namespaced_pod(
            namespace=&#39;longhorn-system&#39;, label_selector=label_selector)
        if anno_val is None:
            if any(pod.metadata.annotations is None or
                   pod.metadata.annotations.get(anno_key, None) is None
                   for pod in pods.items):
                matches = True
                break
        else:
            if any(pod.metadata.annotations is not None and
                    pod.metadata.annotations.get(anno_key, None) == anno_val
                   for pod in pods.items):
                matches = True
                break
        time.sleep(RETRY_INTERVAL)
    assert matches is True</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_pod_phase"><code class="name flex">
<span>def <span class="ident">wait_for_pod_phase</span></span>(<span>core_api, pod_name, pod_phase, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_pod_phase(core_api, pod_name, pod_phase, namespace=&#34;default&#34;):
    is_phase = False
    for _ in range(RETRY_COUNTS):
        try:
            pod = core_api.read_namespaced_pod(name=pod_name,
                                               namespace=namespace)
            if pod.status.phase == pod_phase:
                is_phase = True
                break
        except Exception as e:
            print(f&#34;Waiting for pod {pod_name} {pod_phase} failed: {e}&#34;)

        time.sleep(RETRY_INTERVAL_LONG)
    assert is_phase</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_pod_remount"><code class="name flex">
<span>def <span class="ident">wait_for_pod_remount</span></span>(<span>core_api, pod_name, chk_path='/data/lost+found')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_pod_remount(core_api, pod_name, chk_path=&#34;/data/lost+found&#34;):
    check_command = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;ls &#39; + chk_path
    ]

    ready = False
    for i in range(RETRY_EXEC_COUNTS):
        try:
            output = stream(core_api.connect_get_namespaced_pod_exec,
                            pod_name,
                            &#39;default&#39;,
                            command=check_command,
                            stderr=True, stdin=False,
                            stdout=True, tty=False)
            if &#34;Input/output error&#34; not in output:
                ready = True
                break
        except Exception:
            pass
        if ready:
            break
        time.sleep(RETRY_EXEC_INTERVAL)
    assert ready</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_pod_restart"><code class="name flex">
<span>def <span class="ident">wait_for_pod_restart</span></span>(<span>core_api, pod_name, namespace='default')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_pod_restart(core_api, pod_name, namespace=&#34;default&#34;):
    pod = core_api.read_namespaced_pod(name=pod_name,
                                       namespace=namespace)
    restart_count = pod.status.container_statuses[0].restart_count

    pod_restarted = False
    for i in range(RETRY_COUNTS):
        pod = core_api.read_namespaced_pod(name=pod_name,
                                           namespace=namespace)
        count = pod.status.container_statuses[0].restart_count
        if count &gt; restart_count:
            pod_restarted = True
            break

        time.sleep(RETRY_INTERVAL)
    assert pod_restarted</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_pods_volume_delete"><code class="name flex">
<span>def <span class="ident">wait_for_pods_volume_delete</span></span>(<span>client, pod_list, retry_counts=300)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_pods_volume_delete(client, pod_list,  # NOQA
                                retry_counts=RETRY_BACKUP_COUNTS):
    volume_deleted = False
    for _ in range(retry_counts):
        volume_deleted = True
        volumes = client.list_volume()
        for v in volumes:
            for p in pod_list:
                if v.name == p[&#39;pv_name&#39;]:
                    volume_deleted = False
                    break
        time.sleep(RETRY_INTERVAL)
    assert volume_deleted is True</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_pods_volume_state"><code class="name flex">
<span>def <span class="ident">wait_for_pods_volume_state</span></span>(<span>client, pod_list, field, value, retry_counts=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_pods_volume_state(client, pod_list, field, value,  # NOQA
                               retry_counts=RETRY_COUNTS):
    for _ in range(retry_counts):
        volume_names = []
        volumes = client.list_volume()
        for v in volumes:
            for p in pod_list:
                if v.name == p[&#39;pv_name&#39;] and v[field] == value:
                    volume_names.append(v.name)
                    break
        time.sleep(RETRY_INTERVAL)
    return len(volume_names) == len(pod_list)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_pvc_phase"><code class="name flex">
<span>def <span class="ident">wait_for_pvc_phase</span></span>(<span>api, pvc_name, phase)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_pvc_phase(api, pvc_name, phase):
    complete = False
    for _ in range(RETRY_COUNTS):
        pvc = api.read_namespaced_persistent_volume_claim(
            name=pvc_name, namespace=&#39;default&#39;)
        try:
            assert pvc.status.phase == phase
            complete = True
            break
        except AssertionError:
            pass
        time.sleep(RETRY_INTERVAL)
    assert complete
    return pvc</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_rebuild_complete"><code class="name flex">
<span>def <span class="ident">wait_for_rebuild_complete</span></span>(<span>client, volume_name, retry_count=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_rebuild_complete(client, volume_name, retry_count=RETRY_COUNTS):
    completed = 0
    rebuild_statuses = {}
    for i in range(retry_count):
        completed = 0
        v = client.by_id_volume(volume_name)
        rebuild_statuses = v.rebuildStatus
        for status in rebuild_statuses:
            if status.state == &#34;complete&#34;:
                assert status.progress == 100, f&#34;status = {status}&#34;
                assert not status.error
                assert not status.isRebuilding
                completed += 1
            elif status.state == &#34;&#34;:
                assert not status.error
                assert not status.isRebuilding
                completed += 1
            elif status.state == &#34;in_progress&#34;:
                assert status.isRebuilding
            else:
                assert status.state == &#34;error&#34;
                assert status.error != &#34;&#34;
                assert not status.isRebuilding
        if completed == len(rebuild_statuses):
            break
        time.sleep(RETRY_INTERVAL)
    assert completed == len(rebuild_statuses)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_rebuild_start"><code class="name flex">
<span>def <span class="ident">wait_for_rebuild_start</span></span>(<span>client, volume_name, retry_count=150, retry_interval=1)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_rebuild_start(client, volume_name,
                           retry_count=RETRY_COUNTS,
                           retry_interval=RETRY_INTERVAL):
    started = False
    for i in range(retry_count):
        v = client.by_id_volume(volume_name)
        rebuild_statuses = v.rebuildStatus
        for status in rebuild_statuses:
            if status.state == &#34;in_progress&#34;:
                started = True
                break
        if started:
            break
        time.sleep(retry_interval)
    assert started
    return status.fromReplica, status.replica</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_recurring_jobs_cleanup"><code class="name flex">
<span>def <span class="ident">wait_for_recurring_jobs_cleanup</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_recurring_jobs_cleanup(client):
    for _ in range(RETRY_COUNTS):
        policies = client.list_recurring_job()
        if len(policies) == 0:
            break
        time.sleep(RETRY_INTERVAL)
    assert len(client.list_recurring_job()) == 0</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_replica_count"><code class="name flex">
<span>def <span class="ident">wait_for_replica_count</span></span>(<span>client, volume_name, replica_count)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_replica_count(client, volume_name, replica_count):
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(volume_name)
        if len(volume.replicas) == replica_count:
            break
        time.sleep(RETRY_INTERVAL)

    volume = client.by_id_volume(volume_name)
    assert len(volume.replicas) == replica_count</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_replica_directory"><code class="name flex">
<span>def <span class="ident">wait_for_replica_directory</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_replica_directory():
    found = False
    for i in range(RETRY_COUNTS):
        if os.path.exists(DEFAULT_REPLICA_DIRECTORY):
            found = True
            break
        time.sleep(RETRY_INTERVAL)
    assert found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_replica_failed"><code class="name flex">
<span>def <span class="ident">wait_for_replica_failed</span></span>(<span>client, volname, replica_name, retry_cnts=150, retry_ivl=1)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_replica_failed(client, volname, replica_name,
                            retry_cnts=RETRY_COUNTS, retry_ivl=RETRY_INTERVAL):
    failed = True
    debug_replica_not_failed = None
    debug_replica_in_im = None

    for i in range(retry_cnts):
        failed = True
        debug_replica_not_failed = None
        debug_replica_in_im = None
        volume = client.by_id_volume(volname)
        for r in volume.replicas:
            if r[&#39;name&#39;] != replica_name:
                continue
            if r[&#39;running&#39;] or r[&#39;failedAt&#39;] == &#34;&#34;:
                failed = False
                debug_replica_not_failed = r
                break
            if r[&#39;instanceManagerName&#39;] != &#34;&#34;:
                im = client.by_id_instance_manager(r[&#39;instanceManagerName&#39;])

                instance_dict = {}
                # We still check the &#39;instances&#39; for backward compatibility
                # with older versions (&lt;v1.5.x).
                if im[&#39;instances&#39;] is not None:
                    instance_dict.update(im[&#39;instances&#39;])
                if im[&#39;instanceReplicas&#39;] is not None:
                    instance_dict.update(im[&#39;instanceReplicas&#39;])

                if r[&#39;name&#39;] in instance_dict:
                    failed = False
                    debug_replica_in_im = im
                    break
        if failed:
            break
        time.sleep(retry_ivl)

    err_msg = &#34;Vol({}), Replica({}): {}, Instance_Manager: {}&#34;.format(
        volname, replica_name, debug_replica_not_failed, debug_replica_in_im
    )
    assert failed, err_msg</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_replica_running"><code class="name flex">
<span>def <span class="ident">wait_for_replica_running</span></span>(<span>client, volname, replica_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_replica_running(client, volname, replica_name):
    is_running = False
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(volname)
        for r in volume.replicas:
            if r[&#39;name&#39;] != replica_name:
                continue
            if r[&#39;running&#39;] and r[&#39;instanceManagerName&#39;] != &#34;&#34;:
                im = client.by_id_instance_manager(
                    r[&#39;instanceManagerName&#39;])

                instance_dict = {}
                # We still check the &#39;instances&#39; for backward compatibility
                # with older versions (&lt;v1.5.x).
                if im[&#39;instances&#39;] is not None:
                    instance_dict.update(im[&#39;instances&#39;])
                if im[&#39;instanceReplicas&#39;] is not None:
                    instance_dict.update(im[&#39;instanceReplicas&#39;])

                if r[&#39;name&#39;] in instance_dict:
                    is_running = True
                    break
        if is_running:
            break
        time.sleep(RETRY_INTERVAL)
    assert is_running</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_replica_scheduled"><code class="name flex">
<span>def <span class="ident">wait_for_replica_scheduled</span></span>(<span>client,<br>volume_name,<br>to_nodes,<br>expect_success=2,<br>expect_fail=0,<br>anti_affinity=False,<br>chk_vol_healthy=True,<br>chk_replica_running=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_replica_scheduled(client, volume_name, to_nodes,
                               expect_success=2, expect_fail=0,
                               anti_affinity=False,
                               chk_vol_healthy=True,
                               chk_replica_running=True):
    for _ in range(RETRY_COUNTS):
        volume = client.by_id_volume(volume_name)
        if chk_vol_healthy:
            assert volume.robustness == VOLUME_ROBUSTNESS_HEALTHY

        scheduled = 0
        unexpect_fail = max(0, expect_fail)

        expect_nodes = set(to_nodes)
        for r in volume.replicas:
            try:
                assert r.hostId in expect_nodes

                if chk_replica_running:
                    assert r.running is True
                    assert r.mode == &#34;RW&#34;

                if not anti_affinity:
                    expect_nodes.remove(r.hostId)

                scheduled += 1
            except AssertionError:
                if expect_fail &gt;= 0:
                    unexpect_fail -= 1

        if scheduled == expect_success and unexpect_fail == 0:
            break

        time.sleep(RETRY_INTERVAL)

    assert scheduled == expect_success, f&#34; Volume = {volume}&#34;
    assert unexpect_fail == 0, f&#34;Got {unexpect_fail} unexpected fail&#34;

    if expect_fail &gt;= 0:
        assert len(volume.replicas) == expect_success + expect_fail, \
            f&#34; Volume = {volume}&#34;

    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_restoration_start"><code class="name flex">
<span>def <span class="ident">wait_for_restoration_start</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_restoration_start(client, name):
    return wait_for_volume_status(client, name,
                                  VOLUME_FIELD_RESTOREINITIATED,
                                  True)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_running_engine_image_count"><code class="name flex">
<span>def <span class="ident">wait_for_running_engine_image_count</span></span>(<span>image_name, engine_cnt)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_running_engine_image_count(image_name, engine_cnt):
    core_api = get_core_api_client()
    for i in range(RETRY_COUNTS):
        exist_engine_cnt = 0
        longhorn_pod_list = core_api.list_namespaced_pod(&#39;longhorn-system&#39;)
        for pod in longhorn_pod_list.items:
            if &#34;engine-image-&#34; + image_name in pod.metadata.name and \
                    pod.status.phase == &#34;Running&#34;:
                exist_engine_cnt += 1
        if exist_engine_cnt == engine_cnt:
            break
        time.sleep(RETRY_INTERVAL)

    assert exist_engine_cnt == engine_cnt</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_snapshot_count"><code class="name flex">
<span>def <span class="ident">wait_for_snapshot_count</span></span>(<span>volume, number, retry_counts=120, count_removed=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_snapshot_count(volume, number,
                            retry_counts=120,
                            count_removed=False):
    for _ in range(retry_counts):
        count = 0
        for snapshot in volume.snapshotList():
            if snapshot.removed is False or count_removed:
                count += 1

        if count == number:
            return
        time.sleep(RETRY_SNAPSHOT_INTERVAL)

    assert False, \
        f&#34;failed to wait for snapshot.\n&#34; \
        f&#34;Expect count={number}\n&#34; \
        f&#34;Got count={count}&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_snapshot_purge"><code class="name flex">
<span>def <span class="ident">wait_for_snapshot_purge</span></span>(<span>client, volume_name, *snaps)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_snapshot_purge(client, volume_name, *snaps):
    completed = 0
    last_purge_progress = {}
    purge_status = {}
    for i in range(RETRY_COUNTS):
        completed = 0
        v = client.by_id_volume(volume_name)
        purge_status = v.purgeStatus
        for status in purge_status:
            assert status.error == &#34;&#34;

            progress = status.progress
            assert progress &lt;= 100
            replica = status.replica
            last = last_purge_progress.get(replica)
            assert last is None or last &lt;= status.progress
            last_purge_progress[&#34;replica&#34;] = progress

            if status.state == &#34;complete&#34;:
                assert progress == 100
                completed += 1
        if completed == len(purge_status):
            break
        time.sleep(RETRY_INTERVAL)
    assert completed == len(purge_status)

    # Now that the purge has been reported to be completed, the Snapshots
    # should be removed or &#34;marked as removed&#34; in the case of
    # the latest snapshot.
    found = False
    snapshots = v.snapshotList(volume=volume_name)

    for snap in snaps:
        for vs in snapshots.data:
            if snap == vs[&#34;name&#34;]:
                if vs[&#34;removed&#34;] is False:
                    found = True
                    break

                if &#34;volume-head&#34; not in vs[&#34;children&#34;]:
                    found = True
                    break
    assert not found
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_support_bundle_cleanup"><code class="name flex">
<span>def <span class="ident">wait_for_support_bundle_cleanup</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_support_bundle_cleanup(client):  # NOQA
    ok = False
    for _ in range(RETRY_COUNTS):
        support_bundles = client.list_support_bundle()
        if len(support_bundles) == 0:
            ok = True
            break

        time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_support_bundle_state"><code class="name flex">
<span>def <span class="ident">wait_for_support_bundle_state</span></span>(<span>state, node_id, name, client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_support_bundle_state(state, node_id, name, client):  # NOQA
    ok = False
    for _ in range(RETRY_COUNTS):
        support_bundle = get_support_bundle(node_id, name, client)
        try:
            assert support_bundle[&#39;state&#39;] == state
            ok = True
            break
        except Exception:
            time.sleep(RETRY_INTERVAL)

    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_tainted_node_engine_image_undeployed"><code class="name flex">
<span>def <span class="ident">wait_for_tainted_node_engine_image_undeployed</span></span>(<span>client, img_name, tainted_node)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_tainted_node_engine_image_undeployed(client,
                                                  img_name, tainted_node):
    for _ in range(RETRY_COUNTS):
        time.sleep(RETRY_INTERVAL)
        tainted_node_excluded = False
        img = client.by_id_engine_image(img_name)
        if img.nodeDeploymentMap is None:
            continue
        for node_name in img.nodeDeploymentMap:
            if node_name != tainted_node:
                continue
            if img.nodeDeploymentMap[node_name] is False:
                tainted_node_excluded = True
                break
        if tainted_node_excluded:
            break
    assert img.nodeDeploymentMap[tainted_node] is False</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_attached"><code class="name flex">
<span>def <span class="ident">wait_for_volume_attached</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_attached(client, name):
    return wait_for_volume_status(client, name,
                                  VOLUME_FIELD_STATE,
                                  VOLUME_STATE_ATTACHED)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_clone_status"><code class="name flex">
<span>def <span class="ident">wait_for_volume_clone_status</span></span>(<span>client, name, key, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_clone_status(client, name, key, value):
    for _ in range(RETRY_COUNTS):
        volume = client.by_id_volume(name)
        try:
            if volume[VOLUME_FIELD_CLONE_STATUS][key] == value:
                break
        except Exception as e:
            print(&#34;\nVOLUME_FIELD_CLONE_STATUS is not ready&#34;)
            print(e)
        finally:
            time.sleep(RETRY_INTERVAL)
    assert volume[VOLUME_FIELD_CLONE_STATUS][key] == value, \
        f&#34; Expected value={value}\n. &#34; \
        f&#34; Got volume[{VOLUME_FIELD_CLONE_STATUS}][{key}]= &#34; \
        f&#34;{volume[VOLUME_FIELD_CLONE_STATUS][key]}\n. volume={volume}&#34;
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_condition_restore"><code class="name flex">
<span>def <span class="ident">wait_for_volume_condition_restore</span></span>(<span>client, name, key, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_condition_restore(client, name, key, value):
    wait_for_volume_creation(client, name)
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(name)
        conditions = volume.conditions
        if conditions is not None and \
                conditions != {} and \
                VOLUME_CONDITION_RESTORE in conditions and \
                conditions[VOLUME_CONDITION_RESTORE][key] and \
                conditions[VOLUME_CONDITION_RESTORE][key] == value:
            break
        time.sleep(RETRY_INTERVAL)
    conditions = volume.conditions
    assert conditions[VOLUME_CONDITION_RESTORE][key] == value
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_condition_scheduled"><code class="name flex">
<span>def <span class="ident">wait_for_volume_condition_scheduled</span></span>(<span>client, name, key, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_condition_scheduled(client, name, key, value):
    wait_for_volume_creation(client, name)
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(name)
        conditions = volume.conditions
        if conditions is not None and \
                conditions != {} and \
                conditions[VOLUME_CONDITION_SCHEDULED] and \
                conditions[VOLUME_CONDITION_SCHEDULED][key] and \
                conditions[VOLUME_CONDITION_SCHEDULED][key] == value:
            break
        time.sleep(RETRY_INTERVAL)
    conditions = volume.conditions
    assert conditions[VOLUME_CONDITION_SCHEDULED][key] == value, \
        f&#34; Expected value = {value}, &#34; \
        f&#34; Conditions[{VOLUME_CONDITION_SCHEDULED}][{key}] = &#34; \
        f&#34;{conditions[VOLUME_CONDITION_SCHEDULED][key]}, Volume = {volume}&#34;
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_condition_toomanysnapshots"><code class="name flex">
<span>def <span class="ident">wait_for_volume_condition_toomanysnapshots</span></span>(<span>client, name, key, value, expected_message=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_condition_toomanysnapshots(client, name, key, value,
                                               expected_message=None):
    wait_for_volume_creation(client, name)
    for _ in range(RETRY_COUNTS):
        volume = client.by_id_volume(name)
        conditions = volume.conditions
        if conditions is not None and \
                conditions != {} and \
                VOLUME_CONDITION_TOOMANYSNAPSHOTS in conditions and \
                conditions[VOLUME_CONDITION_TOOMANYSNAPSHOTS][key] and \
                conditions[VOLUME_CONDITION_TOOMANYSNAPSHOTS][key] == value:
            if expected_message is not None:
                current_message = \
                    conditions[VOLUME_CONDITION_TOOMANYSNAPSHOTS][&#39;message&#39;]
                if current_message == expected_message:
                    break
            else:
                break
        time.sleep(RETRY_INTERVAL)
    conditions = volume.conditions
    assert conditions[VOLUME_CONDITION_TOOMANYSNAPSHOTS][key] == value
    if expected_message is not None:
        current_message = \
            conditions[VOLUME_CONDITION_TOOMANYSNAPSHOTS][&#39;message&#39;]
        assert current_message == expected_message, \
            f&#34;Expected message = {expected_message},\n&#34; \
            f&#34;but get &#39;{current_message}&#39;\n&#34;
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_creation"><code class="name flex">
<span>def <span class="ident">wait_for_volume_creation</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_creation(client, name):
    for i in range(RETRY_COUNTS):
        volumes = client.list_volume()
        found = False
        for volume in volumes:
            if volume.name == name:
                found = True
                break
        if found:
            break
        time.sleep(RETRY_INTERVAL)
    assert found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_current_image"><code class="name flex">
<span>def <span class="ident">wait_for_volume_current_image</span></span>(<span>client, name, image)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_current_image(client, name, image):
    wait_for_volume_creation(client, name)
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(name)
        if volume.currentImage == image:
            break
        time.sleep(RETRY_INTERVAL)
    assert volume.currentImage == image
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_degraded"><code class="name flex">
<span>def <span class="ident">wait_for_volume_degraded</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_degraded(client, name):
    wait_for_volume_status(client, name,
                           VOLUME_FIELD_STATE,
                           VOLUME_STATE_ATTACHED)
    return wait_for_volume_status(client, name,
                                  VOLUME_FIELD_ROBUSTNESS,
                                  VOLUME_ROBUSTNESS_DEGRADED)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_delete"><code class="name flex">
<span>def <span class="ident">wait_for_volume_delete</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_delete(client, name):
    for i in range(RETRY_COUNTS):
        volumes = client.list_volume()
        found = False
        for volume in volumes:
            if volume.name == name:
                found = True
                break
        if not found:
            break
        time.sleep(RETRY_INTERVAL)
    assert not found</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_detached"><code class="name flex">
<span>def <span class="ident">wait_for_volume_detached</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_detached(client, name):
    return wait_for_volume_status(client, name,
                                  VOLUME_FIELD_STATE,
                                  VOLUME_STATE_DETACHED)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_detached_unknown"><code class="name flex">
<span>def <span class="ident">wait_for_volume_detached_unknown</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_detached_unknown(client, name):
    wait_for_volume_status(client, name,
                           VOLUME_FIELD_ROBUSTNESS,
                           VOLUME_ROBUSTNESS_UNKNOWN)
    return wait_for_volume_detached(client, name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_endpoint"><code class="name flex">
<span>def <span class="ident">wait_for_volume_endpoint</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_endpoint(client, name):
    for i in range(RETRY_COUNTS):
        v = client.by_id_volume(name)
        engine = get_volume_engine(v)
        if engine.endpoint != &#34;&#34;:
            break
        time.sleep(RETRY_INTERVAL)
    check_volume_endpoint(v)
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_expansion"><code class="name flex">
<span>def <span class="ident">wait_for_volume_expansion</span></span>(<span>longhorn_api_client, volume_name, expected_size='')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_expansion(longhorn_api_client,
                              volume_name,
                              expected_size=&#34;&#34;):
    complete = False
    for i in range(RETRY_COUNTS):
        volume = longhorn_api_client.by_id_volume(volume_name)
        engine = get_volume_engine(volume)
        if expected_size != &#34;&#34; and engine.size != expected_size:
            time.sleep(RETRY_INTERVAL)
            continue
        if engine.size == volume.size:
            complete = True
            break
        time.sleep(RETRY_INTERVAL)
    assert complete</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_faulted"><code class="name flex">
<span>def <span class="ident">wait_for_volume_faulted</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_faulted(client, name):
    # Comment out detach status check because status transition
    # were too fast recently
    # wait_for_volume_status(client, name,
    #                       VOLUME_FIELD_STATE,
    #                       VOLUME_STATE_DETACHED)
    return wait_for_volume_status(client, name,
                                  VOLUME_FIELD_ROBUSTNESS,
                                  VOLUME_ROBUSTNESS_FAULTED)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_frontend_disabled"><code class="name flex">
<span>def <span class="ident">wait_for_volume_frontend_disabled</span></span>(<span>client, volume_name, state=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_frontend_disabled(client, volume_name, state=True):
    for _ in range(RETRY_COUNTS):
        vol = client.by_id_volume(volume_name)
        try:
            assert vol.disableFrontend is state
            break
        except AssertionError:
            time.sleep(RETRY_INTERVAL)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_healthy"><code class="name flex">
<span>def <span class="ident">wait_for_volume_healthy</span></span>(<span>client, name, retry_count=150)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_healthy(client, name, retry_count=RETRY_COUNTS):
    wait_for_volume_status(client, name,
                           VOLUME_FIELD_STATE,
                           VOLUME_STATE_ATTACHED, retry_count)
    wait_for_volume_status(client, name,
                           VOLUME_FIELD_ROBUSTNESS,
                           VOLUME_ROBUSTNESS_HEALTHY, retry_count)
    return wait_for_volume_endpoint(client, name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_healthy_no_frontend"><code class="name flex">
<span>def <span class="ident">wait_for_volume_healthy_no_frontend</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_healthy_no_frontend(client, name):
    wait_for_volume_status(client, name,
                           VOLUME_FIELD_STATE,
                           VOLUME_STATE_ATTACHED)
    return wait_for_volume_status(client, name,
                                  VOLUME_FIELD_ROBUSTNESS,
                                  VOLUME_ROBUSTNESS_HEALTHY)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_migration_node"><code class="name flex">
<span>def <span class="ident">wait_for_volume_migration_node</span></span>(<span>client, volume_name, node_id, expected_replica_count=-1)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_migration_node(client, volume_name, node_id,
                                   expected_replica_count=-1):
    ready = False
    for i in range(RETRY_COUNTS):
        v = client.by_id_volume(volume_name)

        if expected_replica_count == -1:
            expected_replica_count = v.numberOfReplicas
        assert expected_replica_count &gt;= 0

        engines = v.controllers
        replicas = v.replicas
        if len(engines) == 1 and len(replicas) == expected_replica_count:
            e = engines[0]
            if e.endpoint != &#34;&#34;:
                assert e.hostId == node_id
                ready = True
                break
        time.sleep(RETRY_INTERVAL)
    assert ready
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_migration_ready"><code class="name flex">
<span>def <span class="ident">wait_for_volume_migration_ready</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_migration_ready(client, volume_name):
    ready = False
    for i in range(RETRY_COUNTS):
        v = client.by_id_volume(volume_name)
        engines = v.controllers
        ready = len(engines) == 2
        for e in engines:
            ready = ready and e.endpoint != &#34;&#34;
        if ready:
            break
        time.sleep(RETRY_INTERVAL)
    assert ready
    return v</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_option_trim_auto_removing_snapshots"><code class="name flex">
<span>def <span class="ident">wait_for_volume_option_trim_auto_removing_snapshots</span></span>(<span>client, volume_name, enabled)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_option_trim_auto_removing_snapshots(client, volume_name, enabled):  # NOQA
    for i in range(RETRY_COUNTS_SHORT):
        volume = client.by_id_volume(volume_name)
        if volume.controllers[0].unmapMarkSnapChainRemovedEnabled == enabled:
            break
        time.sleep(RETRY_INTERVAL)
    assert volume.controllers[0].unmapMarkSnapChainRemovedEnabled == enabled
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_recurring_job_update"><code class="name flex">
<span>def <span class="ident">wait_for_volume_recurring_job_update</span></span>(<span>volume, jobs=[], groups=[])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_recurring_job_update(volume, jobs=[], groups=[]):
    ok = False
    for _ in range(RETRY_COUNTS):
        volumeJobs, volumeGroups = get_volume_recurring_jobs_and_groups(volume)
        try:
            assert len(volumeGroups) == len(groups)
            for group in groups:
                assert group in volumeGroups

            assert len(volumeJobs) == len(jobs)
            for job in jobs:
                assert job in volumeJobs

            ok = True
            break
        except AssertionError:
            time.sleep(RETRY_INTERVAL)
    assert ok</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_replica_auto_balance_update"><code class="name flex">
<span>def <span class="ident">wait_for_volume_replica_auto_balance_update</span></span>(<span>client, volume_name, value)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_replica_auto_balance_update(client, volume_name, value):
    wait_for_volume_creation(client, volume_name)
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(volume_name)
        if volume.replicaAutoBalance == value:
            break
        time.sleep(RETRY_INTERVAL)
    assert volume.replicaAutoBalance == value
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_replica_count"><code class="name flex">
<span>def <span class="ident">wait_for_volume_replica_count</span></span>(<span>client, name, count)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_replica_count(client, name, count):
    wait_for_volume_creation(client, name)
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(name)
        if len(volume.replicas) == count:
            break
        time.sleep(RETRY_INTERVAL)
    assert len(volume.replicas) == count
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_replica_rebuilt_on_same_node_different_disk"><code class="name flex">
<span>def <span class="ident">wait_for_volume_replica_rebuilt_on_same_node_different_disk</span></span>(<span>client, node_name, volume_name, old_disk_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_replica_rebuilt_on_same_node_different_disk(client, node_name, volume_name, old_disk_name):  # NOQA
    new_disk_name = &#34;&#34;
    for _ in range(RETRY_COUNTS_SHORT):
        time.sleep(RETRY_INTERVAL_LONG)

        node = client.by_id_node(node_name)
        disks = node.disks
        new_disk_name = &#34;&#34;
        for name, disk in disks.items():
            # if scheduledReplica has prefix of volume-name
            for scheduledReplica, _ in disk.scheduledReplica.items():
                if scheduledReplica.startswith(volume_name):
                    new_disk_name = name
                    break
        if new_disk_name != old_disk_name:
            break

    assert new_disk_name != old_disk_name, \
        &#34;Failed to rebuild replica disk to another disk&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_replicas_mode"><code class="name flex">
<span>def <span class="ident">wait_for_volume_replicas_mode</span></span>(<span>client, volname, mode, replica_names=None, replica_count=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_replicas_mode(client, volname, mode,
                                  replica_names=None, replica_count=None):
    verified = False
    for _ in range(RETRY_COUNTS):
        replicas = []
        volume = client.by_id_volume(volname)
        if replica_names is None:
            replicas = volume.replicas
        else:
            for r_name in replica_names:
                found = False
                for r in volume.replicas:
                    if r.name == r_name:
                        replicas.append(r)
                        found = True
                assert found

        count = 0
        wo_count = 0
        for r in replicas:
            if r.mode == mode:
                count += 1
            if r.mode == &#39;WO&#39;:
                wo_count += 1
        assert wo_count &lt;= VOLUME_REPLICA_WO_LIMIT

        r_count = len(replicas) if replica_count is None else replica_count
        if count == r_count:
            verified = True
            break
        time.sleep(RETRY_INTERVAL)

    assert verified
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_replicas_running_on_hosts"><code class="name flex">
<span>def <span class="ident">wait_for_volume_replicas_running_on_hosts</span></span>(<span>client, volume_name, host_ids, replica_balanced)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_replicas_running_on_hosts(client, volume_name, host_ids,
                                              replica_balanced):
    hosts = list(host_ids)
    for i in range(RETRY_COUNTS):
        hosts = list(host_ids)
        num_running = 0
        volume = client.by_id_volume(volume_name)
        for replica in volume.replicas:
            if not replica.running:
                continue

            if replica.hostId not in hosts:
                continue

            if replica_balanced:
                hosts.remove(replica.hostId)

            num_running += 1
        if num_running == volume.numberOfReplicas:
            break

        time.sleep(RETRY_INTERVAL)
    assert num_running == volume.numberOfReplicas
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_restoration_completed"><code class="name flex">
<span>def <span class="ident">wait_for_volume_restoration_completed</span></span>(<span>client, name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_restoration_completed(client, name):
    wait_for_volume_creation(client, name)
    wait_for_restoration_start(client, name)
    monitor_restore_progress(client, name)
    return wait_for_volume_status(client, name,
                                  VOLUME_FIELD_RESTOREREQUIRED,
                                  False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_restoration_start"><code class="name flex">
<span>def <span class="ident">wait_for_volume_restoration_start</span></span>(<span>client, volume_name, backup_name, progress=0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_restoration_start(client, volume_name, backup_name,
                                      progress=0):
    wait_for_volume_status(client, volume_name,
                           VOLUME_FIELD_STATE, VOLUME_STATE_ATTACHED)
    started = False
    for i in range(RETRY_COUNTS):
        volume = client.by_id_volume(volume_name)
        for status in volume.restoreStatus:
            if status.state == &#34;in_progress&#34; and \
                    status.progress &gt; progress:
                started = True
                break
        #  Sometime the restore time is pretty short
        #  and the test may not be able to catch the intermediate status.
        if volume.controllers[0].lastRestoredBackup == backup_name:
            started = True
        if started:
            break
        time.sleep(RETRY_INTERVAL_SHORT)
    assert started
    return status.replica</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_for_volume_status"><code class="name flex">
<span>def <span class="ident">wait_for_volume_status</span></span>(<span>client, name, key, value, retry_count=360)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_volume_status(client, name, key, value,
                           retry_count=RETRY_COUNTS_LONG):
    wait_for_volume_creation(client, name)
    for i in range(retry_count):
        volume = client.by_id_volume(name)
        if volume[key] == value:
            break
        time.sleep(RETRY_INTERVAL)
    assert volume[key] == value, f&#34; value={value}\n. \
            volume[key]={volume[key]}\n. volume={volume}&#34;
    return volume</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_longhorn_node_zone_reset"><code class="name flex">
<span>def <span class="ident">wait_longhorn_node_zone_reset</span></span>(<span>client)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_longhorn_node_zone_reset(client):
    lh_nodes = client.list_node()
    node_names = map(lambda node: node.name, lh_nodes)

    for node_name in node_names:
        for j in range(RETRY_COUNTS):
            lh_node = client.by_id_node(node_name)
            if lh_node.zone == &#39;&#39;:
                break
            time.sleep(RETRY_INTERVAL)

        assert lh_node.zone == &#39;&#39;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_pod"><code class="name flex">
<span>def <span class="ident">wait_pod</span></span>(<span>pod_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_pod(pod_name):
    api = get_core_api_client()

    pod = None
    for i in range(DEFAULT_POD_TIMEOUT):
        try:
            pod = api.read_namespaced_pod(
                name=pod_name,
                namespace=&#39;default&#39;)
            if pod is not None and pod.status.phase != &#39;Pending&#39;:
                break
        except Exception as e:
            print(f&#34;Waiting for pod {pod_name} failed: {e}&#34;)
        time.sleep(DEFAULT_POD_INTERVAL)
    assert pod is not None and pod.status.phase == &#39;Running&#39;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_pod_attach_after_first_backup_completion"><code class="name flex">
<span>def <span class="ident">wait_pod_attach_after_first_backup_completion</span></span>(<span>client, core_api, volume_name, label_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_pod_attach_after_first_backup_completion(
        client, core_api, volume_name, label_name):
    completed = False
    for _ in range(RETRY_BACKUP_COUNTS):
        vol = client.by_id_volume(volume_name)
        for b in vol.backupStatus:
            if b.state == &#39;Completed&#39;:
                assert b.progress == 100
                assert b.error == &#39;&#39;
                completed = True
                break
        if completed:
            wait_for_volume_frontend_disabled(client, vol.name, False)
            wait_for_volume_attached(client, vol.name)
            break

        label_selector = &#34;name=&#34; + label_name
        pods = core_api.list_namespaced_pod(namespace=&#34;default&#34;,
                                            label_selector=label_selector)
        for pod in pods.items:
            assert pod.status.phase != &#39;Running&#39;
        assert vol.disableFrontend is True

        time.sleep(RETRY_BACKUP_INTERVAL)
    assert completed is True
    return vol</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_scheduling_failure"><code class="name flex">
<span>def <span class="ident">wait_scheduling_failure</span></span>(<span>client, volume_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_scheduling_failure(client, volume_name):
    &#34;&#34;&#34;
    Wait and make sure no new replicas are running on the specified
    volume. Trigger a failed assertion of one is detected.
    :param client: The Longhorn client to use in the request.
    :param volume_name: The name of the volume.
    &#34;&#34;&#34;
    scheduling_failure = False
    for i in range(RETRY_COUNTS):
        v = client.by_id_volume(volume_name)
        if v.conditions.Scheduled.status == &#34;False&#34; and \
                v.conditions.Scheduled.reason == \
                &#34;ReplicaSchedulingFailure&#34;:
            scheduling_failure = True
        if scheduling_failure:
            break
        time.sleep(RETRY_INTERVAL)
    assert scheduling_failure, f&#34; Scheduled Status = &#34; \
        f&#34;{v.conditions.Scheduled.status}, Scheduled reason = &#34; \
        f&#34;{v.conditions.Scheduled.reason}, volume = {v}&#34;</code></pre>
</details>
<div class="desc"><p>Wait and make sure no new replicas are running on the specified
volume. Trigger a failed assertion of one is detected.
:param client: The Longhorn client to use in the request.
:param volume_name: The name of the volume.</p></div>
</dd>
<dt id="tests.common.wait_statefulset"><code class="name flex">
<span>def <span class="ident">wait_statefulset</span></span>(<span>statefulset_manifest)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_statefulset(statefulset_manifest):
    api = get_apps_api_client()
    replicas = statefulset_manifest[&#39;spec&#39;][&#39;replicas&#39;]
    for i in range(DEFAULT_STATEFULSET_TIMEOUT):
        s_set = api.read_namespaced_stateful_set(
            name=statefulset_manifest[&#39;metadata&#39;][&#39;name&#39;],
            namespace=&#39;default&#39;)
        # s_set is none if statefulset is not yet created
        if s_set is not None and s_set.status.ready_replicas == replicas:
            break
        time.sleep(DEFAULT_STATEFULSET_INTERVAL)
    assert s_set.status.ready_replicas == replicas</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.wait_volume_kubernetes_status"><code class="name flex">
<span>def <span class="ident">wait_volume_kubernetes_status</span></span>(<span>client, volume_name, expect_ks)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_volume_kubernetes_status(client, volume_name, expect_ks):
    for i in range(RETRY_COUNTS):
        expected = True
        volume = client.by_id_volume(volume_name)
        ks = volume.kubernetesStatus
        ks = json.loads(json.dumps(ks, default=lambda o: o.__dict__))

        for k, v in expect_ks.items():
            if k in (&#39;lastPVCRefAt&#39;, &#39;lastPodRefAt&#39;):
                if (v != &#39;&#39; and ks[k] == &#39;&#39;) or \
                   (v == &#39;&#39; and ks[k] != &#39;&#39;):
                    expected = False
                    break
            else:
                if ks[k] != v:
                    expected = False
                    break
        if expected:
            break
        time.sleep(RETRY_INTERVAL)
    assert expected</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.write_device_random_data"><code class="name flex">
<span>def <span class="ident">write_device_random_data</span></span>(<span>dev, position={})</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_device_random_data(dev, position={}):
    data = generate_random_data(VOLUME_RWTEST_SIZE)
    data_pos = generate_random_pos(VOLUME_RWTEST_SIZE, position)
    data_len = dev_write(dev, data_pos, data)
    checksum = get_device_checksum(dev)

    return {
        &#39;content&#39;: data,
        &#39;pos&#39;: data_pos,
        &#39;len&#39;: data_len,
        &#39;checksum&#39;: checksum
    }</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.write_pod_block_volume_data"><code class="name flex">
<span>def <span class="ident">write_pod_block_volume_data</span></span>(<span>api, pod_name, test_data, offset, device_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_pod_block_volume_data(api, pod_name, test_data, offset, device_path):
    tmp_file = &#39;/var/test_data&#39;
    pre_write_cmd = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;echo -ne &#39; + test_data + &#39; &gt; &#39; + tmp_file
    ]
    write_cmd = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;dd if=&#39; + tmp_file + &#39; of=&#39; + device_path +
        &#39; bs=&#39; + str(len(test_data)) + &#39; count=1 seek=&#39; + str(offset)
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream write&#39;):
        stream(api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
               command=pre_write_cmd, stderr=True, stdin=False, stdout=True,
               tty=False)
        return stream(
            api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
            command=write_cmd, stderr=True, stdin=False, stdout=True,
            tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.write_pod_volume_data"><code class="name flex">
<span>def <span class="ident">write_pod_volume_data</span></span>(<span>api, pod_name, test_data, filename='test')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_pod_volume_data(api, pod_name, test_data, filename=&#39;test&#39;):
    &#34;&#34;&#34;
    Write data into a Pod&#39;s volume.

    Args:
        api: An instance of CoreV1API.
        pod_name: The name of the Pod.
        test_data: The data to be written.
    &#34;&#34;&#34;
    write_command = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;echo -ne &#39; + test_data + &#39; &gt; /data/&#39; + filename
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT,
                 error_message=&#39;Timeout on executing stream write&#39;):
        return stream(
            api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
            command=write_command, stderr=True, stdin=False, stdout=True,
            tty=False)</code></pre>
</details>
<div class="desc"><p>Write data into a Pod's volume.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>api</code></strong></dt>
<dd>An instance of CoreV1API.</dd>
<dt><strong><code>pod_name</code></strong></dt>
<dd>The name of the Pod.</dd>
<dt><strong><code>test_data</code></strong></dt>
<dd>The data to be written.</dd>
</dl></div>
</dd>
<dt id="tests.common.write_pod_volume_random_data"><code class="name flex">
<span>def <span class="ident">write_pod_volume_random_data</span></span>(<span>api, pod_name, path, size_in_mb)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_pod_volume_random_data(api, pod_name, path, size_in_mb):
    write_cmd = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;dd if=/dev/urandom of=&#39; + path +
        &#39; bs=1M&#39; + &#39; count=&#39; + str(size_in_mb) +
        &#39;; sync&#39;
    ]
    return stream(
        api.connect_get_namespaced_pod_exec, pod_name, &#39;default&#39;,
        command=write_cmd, stderr=True, stdin=False, stdout=True,
        tty=False)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.write_volume_data"><code class="name flex">
<span>def <span class="ident">write_volume_data</span></span>(<span>volume, data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_volume_data(volume, data):
    dev = get_volume_endpoint(volume)
    data_len = dev_write(dev, data[&#39;pos&#39;], data[&#39;content&#39;])
    checksum = get_device_checksum(dev)

    return {
        &#39;content&#39;: data[&#39;content&#39;],
        &#39;pos&#39;: data[&#39;pos&#39;],
        &#39;len&#39;: data_len,
        &#39;checksum&#39;: checksum
    }</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.write_volume_dev_random_mb_data"><code class="name flex">
<span>def <span class="ident">write_volume_dev_random_mb_data</span></span>(<span>path, offset_in_mb, length_in_mb, timeout_cnt=3)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_volume_dev_random_mb_data(path, offset_in_mb, length_in_mb,
                                    timeout_cnt=3):
    write_cmd = [
        &#39;/bin/sh&#39;,
        &#39;-c&#39;,
        &#39;dd if=/dev/urandom of=%s bs=1M seek=%d count=%d&#39; %
        (path, offset_in_mb, length_in_mb)
    ]
    with timeout(seconds=STREAM_EXEC_TIMEOUT * timeout_cnt,
                 error_message=&#39;Timeout on writing dev&#39;):
        subprocess.check_call(write_cmd)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tests.common.write_volume_random_data"><code class="name flex">
<span>def <span class="ident">write_volume_random_data</span></span>(<span>volume, position={})</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_volume_random_data(volume, position={}):
    dev = get_volume_endpoint(volume)
    return write_device_random_data(dev, position=position)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tests.common.AssertErrorCheckThread"><code class="flex name class">
<span>class <span class="ident">AssertErrorCheckThread</span></span>
<span>(</span><span>target, args)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AssertErrorCheckThread(threading.Thread):
    &#34;&#34;&#34;
        This class is used for catching exception caused in threads,
        especially for AssertionError now.

        Parameters:
            target  :       The threading function.
            args    :       Arguments of the target function.
    &#34;&#34;&#34;
    def __init__(self, target, args):
        threading.Thread.__init__(self)
        self.target = target
        self.args = args
        self.asserted = None

    def run(self):
        try:
            self.target(*self.args)
        except AssertionError as e:
            self.asserted = e

    def join(self):
        threading.Thread.join(self)
        if self.asserted:
            raise self.asserted</code></pre>
</details>
<div class="desc"><p>This class is used for catching exception caused in threads,
especially for AssertionError now.</p>
<h2 id="parameters">Parameters</h2>
<p>target
:
The threading function.
args
:
Arguments of the target function.</p>
<p>This constructor should always be called with keyword arguments. Arguments are:</p>
<p><em>group</em> should be None; reserved for future extension when a ThreadGroup
class is implemented.</p>
<p><em>target</em> is the callable object to be invoked by the run()
method. Defaults to None, meaning nothing is called.</p>
<p><em>name</em> is the thread name. By default, a unique name is constructed of
the form "Thread-N" where N is a small decimal number.</p>
<p><em>args</em> is a list or tuple of arguments for the target invocation. Defaults to ().</p>
<p><em>kwargs</em> is a dictionary of keyword arguments for the target
invocation. Defaults to {}.</p>
<p>If a subclass overrides the constructor, it must make sure to invoke
the base class constructor (Thread.<strong>init</strong>()) before doing anything
else to the thread.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>threading.Thread</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tests.common.AssertErrorCheckThread.join"><code class="name flex">
<span>def <span class="ident">join</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def join(self):
    threading.Thread.join(self)
    if self.asserted:
        raise self.asserted</code></pre>
</details>
<div class="desc"><p>Wait until the thread terminates.</p>
<p>This blocks the calling thread until the thread whose join() method is
called terminates &ndash; either normally or through an unhandled exception
or until the optional timeout occurs.</p>
<p>When the timeout argument is present and not None, it should be a
floating-point number specifying a timeout for the operation in seconds
(or fractions thereof). As join() always returns None, you must call
is_alive() after join() to decide whether a timeout happened &ndash; if the
thread is still alive, the join() call timed out.</p>
<p>When the timeout argument is not present or None, the operation will
block until the thread terminates.</p>
<p>A thread can be join()ed many times.</p>
<p>join() raises a RuntimeError if an attempt is made to join the current
thread as that would cause a deadlock. It is also an error to join() a
thread before it has been started and attempts to do so raises the same
exception.</p></div>
</dd>
<dt id="tests.common.AssertErrorCheckThread.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    try:
        self.target(*self.args)
    except AssertionError as e:
        self.asserted = e</code></pre>
</details>
<div class="desc"><p>Method representing the thread's activity.</p>
<p>You may override this method in a subclass. The standard run() method
invokes the callable object passed to the object's constructor as the
target argument, if any, with sequential and keyword arguments taken
from the args and kwargs arguments, respectively.</p></div>
</dd>
</dl>
</dd>
<dt id="tests.common.timeout"><code class="flex name class">
<span>class <span class="ident">timeout</span></span>
<span>(</span><span>seconds=1, error_message='Timeout')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class timeout:

    def __init__(self, seconds=1, error_message=&#39;Timeout&#39;):
        self.seconds = seconds
        self.error_message = error_message

    def handle_timeout(self, signum, frame):
        raise Exception(self.error_message)

    def __enter__(self):
        signal.signal(signal.SIGALRM, self.handle_timeout)
        signal.alarm(self.seconds)

    def __exit__(self, type, value, traceback):
        signal.alarm(0)</code></pre>
</details>
<div class="desc"></div>
<h3>Methods</h3>
<dl>
<dt id="tests.common.timeout.handle_timeout"><code class="name flex">
<span>def <span class="ident">handle_timeout</span></span>(<span>self, signum, frame)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def handle_timeout(self, signum, frame):
    raise Exception(self.error_message)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tests" href="index.html">tests</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tests.common.activate_standby_volume" href="#tests.common.activate_standby_volume">activate_standby_volume</a></code></li>
<li><code><a title="tests.common.apps_api" href="#tests.common.apps_api">apps_api</a></code></li>
<li><code><a title="tests.common.assert_backup_state" href="#tests.common.assert_backup_state">assert_backup_state</a></code></li>
<li><code><a title="tests.common.assert_from_assert_error_check_threads" href="#tests.common.assert_from_assert_error_check_threads">assert_from_assert_error_check_threads</a></code></li>
<li><code><a title="tests.common.backing_image_feature_supported" href="#tests.common.backing_image_feature_supported">backing_image_feature_supported</a></code></li>
<li><code><a title="tests.common.batch_v1_api" href="#tests.common.batch_v1_api">batch_v1_api</a></code></li>
<li><code><a title="tests.common.check_all_support_bundle_managers_deleted" href="#tests.common.check_all_support_bundle_managers_deleted">check_all_support_bundle_managers_deleted</a></code></li>
<li><code><a title="tests.common.check_backing_image_disk_map_status" href="#tests.common.check_backing_image_disk_map_status">check_backing_image_disk_map_status</a></code></li>
<li><code><a title="tests.common.check_backing_image_eviction_failed" href="#tests.common.check_backing_image_eviction_failed">check_backing_image_eviction_failed</a></code></li>
<li><code><a title="tests.common.check_backing_image_single_copy_disk_eviction" href="#tests.common.check_backing_image_single_copy_disk_eviction">check_backing_image_single_copy_disk_eviction</a></code></li>
<li><code><a title="tests.common.check_backing_image_single_copy_node_eviction" href="#tests.common.check_backing_image_single_copy_node_eviction">check_backing_image_single_copy_node_eviction</a></code></li>
<li><code><a title="tests.common.check_block_device_size" href="#tests.common.check_block_device_size">check_block_device_size</a></code></li>
<li><code><a title="tests.common.check_csi" href="#tests.common.check_csi">check_csi</a></code></li>
<li><code><a title="tests.common.check_csi_expansion" href="#tests.common.check_csi_expansion">check_csi_expansion</a></code></li>
<li><code><a title="tests.common.check_device_data" href="#tests.common.check_device_data">check_device_data</a></code></li>
<li><code><a title="tests.common.check_longhorn" href="#tests.common.check_longhorn">check_longhorn</a></code></li>
<li><code><a title="tests.common.check_pod_existence" href="#tests.common.check_pod_existence">check_pod_existence</a></code></li>
<li><code><a title="tests.common.check_pv_existence" href="#tests.common.check_pv_existence">check_pv_existence</a></code></li>
<li><code><a title="tests.common.check_pvc_existence" href="#tests.common.check_pvc_existence">check_pvc_existence</a></code></li>
<li><code><a title="tests.common.check_pvc_in_specific_status" href="#tests.common.check_pvc_in_specific_status">check_pvc_in_specific_status</a></code></li>
<li><code><a title="tests.common.check_recurring_jobs" href="#tests.common.check_recurring_jobs">check_recurring_jobs</a></code></li>
<li><code><a title="tests.common.check_statefulset_existence" href="#tests.common.check_statefulset_existence">check_statefulset_existence</a></code></li>
<li><code><a title="tests.common.check_volume_data" href="#tests.common.check_volume_data">check_volume_data</a></code></li>
<li><code><a title="tests.common.check_volume_endpoint" href="#tests.common.check_volume_endpoint">check_volume_endpoint</a></code></li>
<li><code><a title="tests.common.check_volume_existence" href="#tests.common.check_volume_existence">check_volume_existence</a></code></li>
<li><code><a title="tests.common.check_volume_last_backup" href="#tests.common.check_volume_last_backup">check_volume_last_backup</a></code></li>
<li><code><a title="tests.common.check_volume_replicas" href="#tests.common.check_volume_replicas">check_volume_replicas</a></code></li>
<li><code><a title="tests.common.cleanup_all_backing_images" href="#tests.common.cleanup_all_backing_images">cleanup_all_backing_images</a></code></li>
<li><code><a title="tests.common.cleanup_all_recurring_jobs" href="#tests.common.cleanup_all_recurring_jobs">cleanup_all_recurring_jobs</a></code></li>
<li><code><a title="tests.common.cleanup_all_support_bundles" href="#tests.common.cleanup_all_support_bundles">cleanup_all_support_bundles</a></code></li>
<li><code><a title="tests.common.cleanup_all_volumes" href="#tests.common.cleanup_all_volumes">cleanup_all_volumes</a></code></li>
<li><code><a title="tests.common.cleanup_client" href="#tests.common.cleanup_client">cleanup_client</a></code></li>
<li><code><a title="tests.common.cleanup_crypto_secret" href="#tests.common.cleanup_crypto_secret">cleanup_crypto_secret</a></code></li>
<li><code><a title="tests.common.cleanup_disks_on_node" href="#tests.common.cleanup_disks_on_node">cleanup_disks_on_node</a></code></li>
<li><code><a title="tests.common.cleanup_host_disk" href="#tests.common.cleanup_host_disk">cleanup_host_disk</a></code></li>
<li><code><a title="tests.common.cleanup_host_disks" href="#tests.common.cleanup_host_disks">cleanup_host_disks</a></code></li>
<li><code><a title="tests.common.cleanup_node_disks" href="#tests.common.cleanup_node_disks">cleanup_node_disks</a></code></li>
<li><code><a title="tests.common.cleanup_storage_class" href="#tests.common.cleanup_storage_class">cleanup_storage_class</a></code></li>
<li><code><a title="tests.common.cleanup_test_disks" href="#tests.common.cleanup_test_disks">cleanup_test_disks</a></code></li>
<li><code><a title="tests.common.cleanup_volume" href="#tests.common.cleanup_volume">cleanup_volume</a></code></li>
<li><code><a title="tests.common.cleanup_volume_by_name" href="#tests.common.cleanup_volume_by_name">cleanup_volume_by_name</a></code></li>
<li><code><a title="tests.common.client" href="#tests.common.client">client</a></code></li>
<li><code><a title="tests.common.clients" href="#tests.common.clients">clients</a></code></li>
<li><code><a title="tests.common.copy_file_to_volume_dev_mb_data" href="#tests.common.copy_file_to_volume_dev_mb_data">copy_file_to_volume_dev_mb_data</a></code></li>
<li><code><a title="tests.common.copy_pod_volume_data" href="#tests.common.copy_pod_volume_data">copy_pod_volume_data</a></code></li>
<li><code><a title="tests.common.core_api" href="#tests.common.core_api">core_api</a></code></li>
<li><code><a title="tests.common.crash_engine_process_with_sigkill" href="#tests.common.crash_engine_process_with_sigkill">crash_engine_process_with_sigkill</a></code></li>
<li><code><a title="tests.common.crash_replica_processes" href="#tests.common.crash_replica_processes">crash_replica_processes</a></code></li>
<li><code><a title="tests.common.create_and_check_volume" href="#tests.common.create_and_check_volume">create_and_check_volume</a></code></li>
<li><code><a title="tests.common.create_and_wait_deployment" href="#tests.common.create_and_wait_deployment">create_and_wait_deployment</a></code></li>
<li><code><a title="tests.common.create_and_wait_pod" href="#tests.common.create_and_wait_pod">create_and_wait_pod</a></code></li>
<li><code><a title="tests.common.create_and_wait_statefulset" href="#tests.common.create_and_wait_statefulset">create_and_wait_statefulset</a></code></li>
<li><code><a title="tests.common.create_assert_error_check_thread" href="#tests.common.create_assert_error_check_thread">create_assert_error_check_thread</a></code></li>
<li><code><a title="tests.common.create_backing_image_with_matching_url" href="#tests.common.create_backing_image_with_matching_url">create_backing_image_with_matching_url</a></code></li>
<li><code><a title="tests.common.create_backup" href="#tests.common.create_backup">create_backup</a></code></li>
<li><code><a title="tests.common.create_backup_from_volume_attached_to_pod" href="#tests.common.create_backup_from_volume_attached_to_pod">create_backup_from_volume_attached_to_pod</a></code></li>
<li><code><a title="tests.common.create_crypto_secret" href="#tests.common.create_crypto_secret">create_crypto_secret</a></code></li>
<li><code><a title="tests.common.create_deployment_and_write_data" href="#tests.common.create_deployment_and_write_data">create_deployment_and_write_data</a></code></li>
<li><code><a title="tests.common.create_host_disk" href="#tests.common.create_host_disk">create_host_disk</a></code></li>
<li><code><a title="tests.common.create_pv_for_volume" href="#tests.common.create_pv_for_volume">create_pv_for_volume</a></code></li>
<li><code><a title="tests.common.create_pvc" href="#tests.common.create_pvc">create_pvc</a></code></li>
<li><code><a title="tests.common.create_pvc_for_volume" href="#tests.common.create_pvc_for_volume">create_pvc_for_volume</a></code></li>
<li><code><a title="tests.common.create_pvc_spec" href="#tests.common.create_pvc_spec">create_pvc_spec</a></code></li>
<li><code><a title="tests.common.create_recurring_jobs" href="#tests.common.create_recurring_jobs">create_recurring_jobs</a></code></li>
<li><code><a title="tests.common.create_rwx_volume_with_storageclass" href="#tests.common.create_rwx_volume_with_storageclass">create_rwx_volume_with_storageclass</a></code></li>
<li><code><a title="tests.common.create_snapshot" href="#tests.common.create_snapshot">create_snapshot</a></code></li>
<li><code><a title="tests.common.create_statefulset" href="#tests.common.create_statefulset">create_statefulset</a></code></li>
<li><code><a title="tests.common.create_storage_class" href="#tests.common.create_storage_class">create_storage_class</a></code></li>
<li><code><a title="tests.common.create_support_bundle" href="#tests.common.create_support_bundle">create_support_bundle</a></code></li>
<li><code><a title="tests.common.create_volume" href="#tests.common.create_volume">create_volume</a></code></li>
<li><code><a title="tests.common.create_volume_and_backup" href="#tests.common.create_volume_and_backup">create_volume_and_backup</a></code></li>
<li><code><a title="tests.common.create_volume_and_write_data" href="#tests.common.create_volume_and_write_data">create_volume_and_write_data</a></code></li>
<li><code><a title="tests.common.crypto_secret" href="#tests.common.crypto_secret">crypto_secret</a></code></li>
<li><code><a title="tests.common.csi_pv" href="#tests.common.csi_pv">csi_pv</a></code></li>
<li><code><a title="tests.common.csi_pv_backingimage" href="#tests.common.csi_pv_backingimage">csi_pv_backingimage</a></code></li>
<li><code><a title="tests.common.csi_pvc_name" href="#tests.common.csi_pvc_name">csi_pvc_name</a></code></li>
<li><code><a title="tests.common.delete_and_wait_deployment" href="#tests.common.delete_and_wait_deployment">delete_and_wait_deployment</a></code></li>
<li><code><a title="tests.common.delete_and_wait_longhorn" href="#tests.common.delete_and_wait_longhorn">delete_and_wait_longhorn</a></code></li>
<li><code><a title="tests.common.delete_and_wait_pod" href="#tests.common.delete_and_wait_pod">delete_and_wait_pod</a></code></li>
<li><code><a title="tests.common.delete_and_wait_pv" href="#tests.common.delete_and_wait_pv">delete_and_wait_pv</a></code></li>
<li><code><a title="tests.common.delete_and_wait_pvc" href="#tests.common.delete_and_wait_pvc">delete_and_wait_pvc</a></code></li>
<li><code><a title="tests.common.delete_and_wait_statefulset" href="#tests.common.delete_and_wait_statefulset">delete_and_wait_statefulset</a></code></li>
<li><code><a title="tests.common.delete_and_wait_volume_attachment" href="#tests.common.delete_and_wait_volume_attachment">delete_and_wait_volume_attachment</a></code></li>
<li><code><a title="tests.common.delete_backup" href="#tests.common.delete_backup">delete_backup</a></code></li>
<li><code><a title="tests.common.delete_backup_backing_image" href="#tests.common.delete_backup_backing_image">delete_backup_backing_image</a></code></li>
<li><code><a title="tests.common.delete_backup_volume" href="#tests.common.delete_backup_volume">delete_backup_volume</a></code></li>
<li><code><a title="tests.common.delete_crypto_secret" href="#tests.common.delete_crypto_secret">delete_crypto_secret</a></code></li>
<li><code><a title="tests.common.delete_replica_on_test_node" href="#tests.common.delete_replica_on_test_node">delete_replica_on_test_node</a></code></li>
<li><code><a title="tests.common.delete_replica_processes" href="#tests.common.delete_replica_processes">delete_replica_processes</a></code></li>
<li><code><a title="tests.common.delete_statefulset" href="#tests.common.delete_statefulset">delete_statefulset</a></code></li>
<li><code><a title="tests.common.delete_storage_class" href="#tests.common.delete_storage_class">delete_storage_class</a></code></li>
<li><code><a title="tests.common.delete_support_bundle" href="#tests.common.delete_support_bundle">delete_support_bundle</a></code></li>
<li><code><a title="tests.common.dev_read" href="#tests.common.dev_read">dev_read</a></code></li>
<li><code><a title="tests.common.dev_write" href="#tests.common.dev_write">dev_write</a></code></li>
<li><code><a title="tests.common.disable_auto_salvage" href="#tests.common.disable_auto_salvage">disable_auto_salvage</a></code></li>
<li><code><a title="tests.common.download_support_bundle" href="#tests.common.download_support_bundle">download_support_bundle</a></code></li>
<li><code><a title="tests.common.enable_default_disk" href="#tests.common.enable_default_disk">enable_default_disk</a></code></li>
<li><code><a title="tests.common.exec_command_in_pod" href="#tests.common.exec_command_in_pod">exec_command_in_pod</a></code></li>
<li><code><a title="tests.common.exec_instance_manager" href="#tests.common.exec_instance_manager">exec_instance_manager</a></code></li>
<li><code><a title="tests.common.exec_local" href="#tests.common.exec_local">exec_local</a></code></li>
<li><code><a title="tests.common.exec_nsenter" href="#tests.common.exec_nsenter">exec_nsenter</a></code></li>
<li><code><a title="tests.common.expand_and_wait_for_pvc" href="#tests.common.expand_and_wait_for_pvc">expand_and_wait_for_pvc</a></code></li>
<li><code><a title="tests.common.fail_replica_expansion" href="#tests.common.fail_replica_expansion">fail_replica_expansion</a></code></li>
<li><code><a title="tests.common.find_ancestor_process_by_name" href="#tests.common.find_ancestor_process_by_name">find_ancestor_process_by_name</a></code></li>
<li><code><a title="tests.common.find_backup" href="#tests.common.find_backup">find_backup</a></code></li>
<li><code><a title="tests.common.find_backup_volume" href="#tests.common.find_backup_volume">find_backup_volume</a></code></li>
<li><code><a title="tests.common.find_dockerd_pid" href="#tests.common.find_dockerd_pid">find_dockerd_pid</a></code></li>
<li><code><a title="tests.common.find_process_pid" href="#tests.common.find_process_pid">find_process_pid</a></code></li>
<li><code><a title="tests.common.find_replica_for_backup" href="#tests.common.find_replica_for_backup">find_replica_for_backup</a></code></li>
<li><code><a title="tests.common.find_self" href="#tests.common.find_self">find_self</a></code></li>
<li><code><a title="tests.common.fix_replica_expansion_failure" href="#tests.common.fix_replica_expansion_failure">fix_replica_expansion_failure</a></code></li>
<li><code><a title="tests.common.generate_attachment_ticket_id" href="#tests.common.generate_attachment_ticket_id">generate_attachment_ticket_id</a></code></li>
<li><code><a title="tests.common.generate_pod_with_pvc_manifest" href="#tests.common.generate_pod_with_pvc_manifest">generate_pod_with_pvc_manifest</a></code></li>
<li><code><a title="tests.common.generate_random_data" href="#tests.common.generate_random_data">generate_random_data</a></code></li>
<li><code><a title="tests.common.generate_random_pos" href="#tests.common.generate_random_pos">generate_random_pos</a></code></li>
<li><code><a title="tests.common.generate_random_suffix" href="#tests.common.generate_random_suffix">generate_random_suffix</a></code></li>
<li><code><a title="tests.common.generate_sts_name" href="#tests.common.generate_sts_name">generate_sts_name</a></code></li>
<li><code><a title="tests.common.generate_support_bundle" href="#tests.common.generate_support_bundle">generate_support_bundle</a></code></li>
<li><code><a title="tests.common.generate_volume_name" href="#tests.common.generate_volume_name">generate_volume_name</a></code></li>
<li><code><a title="tests.common.get_all_support_bundle_manager_deployments" href="#tests.common.get_all_support_bundle_manager_deployments">get_all_support_bundle_manager_deployments</a></code></li>
<li><code><a title="tests.common.get_apps_api_client" href="#tests.common.get_apps_api_client">get_apps_api_client</a></code></li>
<li><code><a title="tests.common.get_backupstore_poll_interval" href="#tests.common.get_backupstore_poll_interval">get_backupstore_poll_interval</a></code></li>
<li><code><a title="tests.common.get_backupstore_url" href="#tests.common.get_backupstore_url">get_backupstore_url</a></code></li>
<li><code><a title="tests.common.get_backupstores" href="#tests.common.get_backupstores">get_backupstores</a></code></li>
<li><code><a title="tests.common.get_client" href="#tests.common.get_client">get_client</a></code></li>
<li><code><a title="tests.common.get_clients" href="#tests.common.get_clients">get_clients</a></code></li>
<li><code><a title="tests.common.get_clone_volume_name" href="#tests.common.get_clone_volume_name">get_clone_volume_name</a></code></li>
<li><code><a title="tests.common.get_compatibility_test_image" href="#tests.common.get_compatibility_test_image">get_compatibility_test_image</a></code></li>
<li><code><a title="tests.common.get_core_api_client" href="#tests.common.get_core_api_client">get_core_api_client</a></code></li>
<li><code><a title="tests.common.get_custom_object_api_client" href="#tests.common.get_custom_object_api_client">get_custom_object_api_client</a></code></li>
<li><code><a title="tests.common.get_default_engine_image" href="#tests.common.get_default_engine_image">get_default_engine_image</a></code></li>
<li><code><a title="tests.common.get_deployment_pod_names" href="#tests.common.get_deployment_pod_names">get_deployment_pod_names</a></code></li>
<li><code><a title="tests.common.get_device_checksum" href="#tests.common.get_device_checksum">get_device_checksum</a></code></li>
<li><code><a title="tests.common.get_disk_uuid" href="#tests.common.get_disk_uuid">get_disk_uuid</a></code></li>
<li><code><a title="tests.common.get_engine_host_id" href="#tests.common.get_engine_host_id">get_engine_host_id</a></code></li>
<li><code><a title="tests.common.get_engine_image_status_value" href="#tests.common.get_engine_image_status_value">get_engine_image_status_value</a></code></li>
<li><code><a title="tests.common.get_host_disk_size" href="#tests.common.get_host_disk_size">get_host_disk_size</a></code></li>
<li><code><a title="tests.common.get_host_replica_count" href="#tests.common.get_host_replica_count">get_host_replica_count</a></code></li>
<li><code><a title="tests.common.get_instance_manager_names" href="#tests.common.get_instance_manager_names">get_instance_manager_names</a></code></li>
<li><code><a title="tests.common.get_iscsi_ip" href="#tests.common.get_iscsi_ip">get_iscsi_ip</a></code></li>
<li><code><a title="tests.common.get_iscsi_lun" href="#tests.common.get_iscsi_lun">get_iscsi_lun</a></code></li>
<li><code><a title="tests.common.get_iscsi_port" href="#tests.common.get_iscsi_port">get_iscsi_port</a></code></li>
<li><code><a title="tests.common.get_iscsi_target" href="#tests.common.get_iscsi_target">get_iscsi_target</a></code></li>
<li><code><a title="tests.common.get_k8s_zone_label" href="#tests.common.get_k8s_zone_label">get_k8s_zone_label</a></code></li>
<li><code><a title="tests.common.get_liveness_probe_spec" href="#tests.common.get_liveness_probe_spec">get_liveness_probe_spec</a></code></li>
<li><code><a title="tests.common.get_longhorn_api_client" href="#tests.common.get_longhorn_api_client">get_longhorn_api_client</a></code></li>
<li><code><a title="tests.common.get_mgr_ips" href="#tests.common.get_mgr_ips">get_mgr_ips</a></code></li>
<li><code><a title="tests.common.get_node_by_disk_id" href="#tests.common.get_node_by_disk_id">get_node_by_disk_id</a></code></li>
<li><code><a title="tests.common.get_nvmf_ip" href="#tests.common.get_nvmf_ip">get_nvmf_ip</a></code></li>
<li><code><a title="tests.common.get_nvmf_nqn" href="#tests.common.get_nvmf_nqn">get_nvmf_nqn</a></code></li>
<li><code><a title="tests.common.get_nvmf_port" href="#tests.common.get_nvmf_port">get_nvmf_port</a></code></li>
<li><code><a title="tests.common.get_pod_data_md5sum" href="#tests.common.get_pod_data_md5sum">get_pod_data_md5sum</a></code></li>
<li><code><a title="tests.common.get_process_info" href="#tests.common.get_process_info">get_process_info</a></code></li>
<li><code><a title="tests.common.get_pv_manifest" href="#tests.common.get_pv_manifest">get_pv_manifest</a></code></li>
<li><code><a title="tests.common.get_pvc_manifest" href="#tests.common.get_pvc_manifest">get_pvc_manifest</a></code></li>
<li><code><a title="tests.common.get_random_client" href="#tests.common.get_random_client">get_random_client</a></code></li>
<li><code><a title="tests.common.get_scheduling_api_client" href="#tests.common.get_scheduling_api_client">get_scheduling_api_client</a></code></li>
<li><code><a title="tests.common.get_self_host_id" href="#tests.common.get_self_host_id">get_self_host_id</a></code></li>
<li><code><a title="tests.common.get_statefulset_pod_info" href="#tests.common.get_statefulset_pod_info">get_statefulset_pod_info</a></code></li>
<li><code><a title="tests.common.get_storage_api_client" href="#tests.common.get_storage_api_client">get_storage_api_client</a></code></li>
<li><code><a title="tests.common.get_support_bundle" href="#tests.common.get_support_bundle">get_support_bundle</a></code></li>
<li><code><a title="tests.common.get_support_bundle_url" href="#tests.common.get_support_bundle_url">get_support_bundle_url</a></code></li>
<li><code><a title="tests.common.get_update_disks" href="#tests.common.get_update_disks">get_update_disks</a></code></li>
<li><code><a title="tests.common.get_upgrade_test_image" href="#tests.common.get_upgrade_test_image">get_upgrade_test_image</a></code></li>
<li><code><a title="tests.common.get_version_api_client" href="#tests.common.get_version_api_client">get_version_api_client</a></code></li>
<li><code><a title="tests.common.get_volume_dev_mb_data_md5sum" href="#tests.common.get_volume_dev_mb_data_md5sum">get_volume_dev_mb_data_md5sum</a></code></li>
<li><code><a title="tests.common.get_volume_endpoint" href="#tests.common.get_volume_endpoint">get_volume_endpoint</a></code></li>
<li><code><a title="tests.common.get_volume_engine" href="#tests.common.get_volume_engine">get_volume_engine</a></code></li>
<li><code><a title="tests.common.get_volume_name" href="#tests.common.get_volume_name">get_volume_name</a></code></li>
<li><code><a title="tests.common.get_volume_recurring_jobs_and_groups" href="#tests.common.get_volume_recurring_jobs_and_groups">get_volume_recurring_jobs_and_groups</a></code></li>
<li><code><a title="tests.common.get_volume_running_replica_cnt" href="#tests.common.get_volume_running_replica_cnt">get_volume_running_replica_cnt</a></code></li>
<li><code><a title="tests.common.is_backupTarget_azurite" href="#tests.common.is_backupTarget_azurite">is_backupTarget_azurite</a></code></li>
<li><code><a title="tests.common.is_backupTarget_cifs" href="#tests.common.is_backupTarget_cifs">is_backupTarget_cifs</a></code></li>
<li><code><a title="tests.common.is_backupTarget_nfs" href="#tests.common.is_backupTarget_nfs">is_backupTarget_nfs</a></code></li>
<li><code><a title="tests.common.is_backupTarget_s3" href="#tests.common.is_backupTarget_s3">is_backupTarget_s3</a></code></li>
<li><code><a title="tests.common.is_k8s_node_gke_cos" href="#tests.common.is_k8s_node_gke_cos">is_k8s_node_gke_cos</a></code></li>
<li><code><a title="tests.common.is_k8s_node_label" href="#tests.common.is_k8s_node_label">is_k8s_node_label</a></code></li>
<li><code><a title="tests.common.is_replica_available" href="#tests.common.is_replica_available">is_replica_available</a></code></li>
<li><code><a title="tests.common.iscsi_login" href="#tests.common.iscsi_login">iscsi_login</a></code></li>
<li><code><a title="tests.common.iscsi_logout" href="#tests.common.iscsi_logout">iscsi_logout</a></code></li>
<li><code><a title="tests.common.json_string_go_to_python" href="#tests.common.json_string_go_to_python">json_string_go_to_python</a></code></li>
<li><code><a title="tests.common.lazy_umount_disk" href="#tests.common.lazy_umount_disk">lazy_umount_disk</a></code></li>
<li><code><a title="tests.common.load_k8s_config" href="#tests.common.load_k8s_config">load_k8s_config</a></code></li>
<li><code><a title="tests.common.make_deployment_cpu_request" href="#tests.common.make_deployment_cpu_request">make_deployment_cpu_request</a></code></li>
<li><code><a title="tests.common.make_deployment_with_pvc" href="#tests.common.make_deployment_with_pvc">make_deployment_with_pvc</a></code></li>
<li><code><a title="tests.common.monitor_restore_progress" href="#tests.common.monitor_restore_progress">monitor_restore_progress</a></code></li>
<li><code><a title="tests.common.mount_disk" href="#tests.common.mount_disk">mount_disk</a></code></li>
<li><code><a title="tests.common.node_default_tags" href="#tests.common.node_default_tags">node_default_tags</a></code></li>
<li><code><a title="tests.common.nvmf_login" href="#tests.common.nvmf_login">nvmf_login</a></code></li>
<li><code><a title="tests.common.nvmf_logout" href="#tests.common.nvmf_logout">nvmf_logout</a></code></li>
<li><code><a title="tests.common.offline_expand_attached_volume" href="#tests.common.offline_expand_attached_volume">offline_expand_attached_volume</a></code></li>
<li><code><a title="tests.common.parse_iscsi_endpoint" href="#tests.common.parse_iscsi_endpoint">parse_iscsi_endpoint</a></code></li>
<li><code><a title="tests.common.parse_nvmf_endpoint" href="#tests.common.parse_nvmf_endpoint">parse_nvmf_endpoint</a></code></li>
<li><code><a title="tests.common.pod" href="#tests.common.pod">pod</a></code></li>
<li><code><a title="tests.common.pod_make" href="#tests.common.pod_make">pod_make</a></code></li>
<li><code><a title="tests.common.prepare_host_disk" href="#tests.common.prepare_host_disk">prepare_host_disk</a></code></li>
<li><code><a title="tests.common.prepare_pod_with_data_in_mb" href="#tests.common.prepare_pod_with_data_in_mb">prepare_pod_with_data_in_mb</a></code></li>
<li><code><a title="tests.common.prepare_statefulset_with_data_in_mb" href="#tests.common.prepare_statefulset_with_data_in_mb">prepare_statefulset_with_data_in_mb</a></code></li>
<li><code><a title="tests.common.priority_class" href="#tests.common.priority_class">priority_class</a></code></li>
<li><code><a title="tests.common.pvc" href="#tests.common.pvc">pvc</a></code></li>
<li><code><a title="tests.common.pvc_backingimage" href="#tests.common.pvc_backingimage">pvc_backingimage</a></code></li>
<li><code><a title="tests.common.pvc_name" href="#tests.common.pvc_name">pvc_name</a></code></li>
<li><code><a title="tests.common.random_labels" href="#tests.common.random_labels">random_labels</a></code></li>
<li><code><a title="tests.common.read_pod_block_volume_data" href="#tests.common.read_pod_block_volume_data">read_pod_block_volume_data</a></code></li>
<li><code><a title="tests.common.read_volume_data" href="#tests.common.read_volume_data">read_volume_data</a></code></li>
<li><code><a title="tests.common.recurring_job_feature_supported" href="#tests.common.recurring_job_feature_supported">recurring_job_feature_supported</a></code></li>
<li><code><a title="tests.common.remount_volume_read_only" href="#tests.common.remount_volume_read_only">remount_volume_read_only</a></code></li>
<li><code><a title="tests.common.reset_disks_for_all_nodes" href="#tests.common.reset_disks_for_all_nodes">reset_disks_for_all_nodes</a></code></li>
<li><code><a title="tests.common.reset_engine_image" href="#tests.common.reset_engine_image">reset_engine_image</a></code></li>
<li><code><a title="tests.common.reset_longhorn_node_zone" href="#tests.common.reset_longhorn_node_zone">reset_longhorn_node_zone</a></code></li>
<li><code><a title="tests.common.reset_node" href="#tests.common.reset_node">reset_node</a></code></li>
<li><code><a title="tests.common.reset_nodes_taint" href="#tests.common.reset_nodes_taint">reset_nodes_taint</a></code></li>
<li><code><a title="tests.common.reset_settings" href="#tests.common.reset_settings">reset_settings</a></code></li>
<li><code><a title="tests.common.restart_and_wait_ready_engine_count" href="#tests.common.restart_and_wait_ready_engine_count">restart_and_wait_ready_engine_count</a></code></li>
<li><code><a title="tests.common.restore_backup_and_get_data_checksum" href="#tests.common.restore_backup_and_get_data_checksum">restore_backup_and_get_data_checksum</a></code></li>
<li><code><a title="tests.common.rwx_statefulset" href="#tests.common.rwx_statefulset">rwx_statefulset</a></code></li>
<li><code><a title="tests.common.scale_up_engine_image_daemonset" href="#tests.common.scale_up_engine_image_daemonset">scale_up_engine_image_daemonset</a></code></li>
<li><code><a title="tests.common.scheduling_api" href="#tests.common.scheduling_api">scheduling_api</a></code></li>
<li><code><a title="tests.common.set_and_wait_k8s_nodes_zone_label" href="#tests.common.set_and_wait_k8s_nodes_zone_label">set_and_wait_k8s_nodes_zone_label</a></code></li>
<li><code><a title="tests.common.set_k8s_node_label" href="#tests.common.set_k8s_node_label">set_k8s_node_label</a></code></li>
<li><code><a title="tests.common.set_k8s_node_zone_label" href="#tests.common.set_k8s_node_zone_label">set_k8s_node_zone_label</a></code></li>
<li><code><a title="tests.common.set_node_cordon" href="#tests.common.set_node_cordon">set_node_cordon</a></code></li>
<li><code><a title="tests.common.set_node_scheduling" href="#tests.common.set_node_scheduling">set_node_scheduling</a></code></li>
<li><code><a title="tests.common.set_node_scheduling_eviction" href="#tests.common.set_node_scheduling_eviction">set_node_scheduling_eviction</a></code></li>
<li><code><a title="tests.common.set_node_tags" href="#tests.common.set_node_tags">set_node_tags</a></code></li>
<li><code><a title="tests.common.set_tags_for_node_and_its_disks" href="#tests.common.set_tags_for_node_and_its_disks">set_tags_for_node_and_its_disks</a></code></li>
<li><code><a title="tests.common.settings_reset" href="#tests.common.settings_reset">settings_reset</a></code></li>
<li><code><a title="tests.common.size_to_string" href="#tests.common.size_to_string">size_to_string</a></code></li>
<li><code><a title="tests.common.statefulset" href="#tests.common.statefulset">statefulset</a></code></li>
<li><code><a title="tests.common.storage_class" href="#tests.common.storage_class">storage_class</a></code></li>
<li><code><a title="tests.common.sts_name" href="#tests.common.sts_name">sts_name</a></code></li>
<li><code><a title="tests.common.system_backup_feature_supported" href="#tests.common.system_backup_feature_supported">system_backup_feature_supported</a></code></li>
<li><code><a title="tests.common.system_backup_random_name" href="#tests.common.system_backup_random_name">system_backup_random_name</a></code></li>
<li><code><a title="tests.common.system_backup_wait_for_state" href="#tests.common.system_backup_wait_for_state">system_backup_wait_for_state</a></code></li>
<li><code><a title="tests.common.system_backups_cleanup" href="#tests.common.system_backups_cleanup">system_backups_cleanup</a></code></li>
<li><code><a title="tests.common.system_restore_random_name" href="#tests.common.system_restore_random_name">system_restore_random_name</a></code></li>
<li><code><a title="tests.common.system_restore_wait_for_state" href="#tests.common.system_restore_wait_for_state">system_restore_wait_for_state</a></code></li>
<li><code><a title="tests.common.system_restores_cleanup" href="#tests.common.system_restores_cleanup">system_restores_cleanup</a></code></li>
<li><code><a title="tests.common.umount_disk" href="#tests.common.umount_disk">umount_disk</a></code></li>
<li><code><a title="tests.common.update_node_disks" href="#tests.common.update_node_disks">update_node_disks</a></code></li>
<li><code><a title="tests.common.update_persistent_volume_claim" href="#tests.common.update_persistent_volume_claim">update_persistent_volume_claim</a></code></li>
<li><code><a title="tests.common.update_recurring_job" href="#tests.common.update_recurring_job">update_recurring_job</a></code></li>
<li><code><a title="tests.common.update_setting" href="#tests.common.update_setting">update_setting</a></code></li>
<li><code><a title="tests.common.update_statefulset_manifests" href="#tests.common.update_statefulset_manifests">update_statefulset_manifests</a></code></li>
<li><code><a title="tests.common.v2_data_engine_cr_supported" href="#tests.common.v2_data_engine_cr_supported">v2_data_engine_cr_supported</a></code></li>
<li><code><a title="tests.common.volume_name" href="#tests.common.volume_name">volume_name</a></code></li>
<li><code><a title="tests.common.volume_read" href="#tests.common.volume_read">volume_read</a></code></li>
<li><code><a title="tests.common.volume_valid" href="#tests.common.volume_valid">volume_valid</a></code></li>
<li><code><a title="tests.common.volume_write" href="#tests.common.volume_write">volume_write</a></code></li>
<li><code><a title="tests.common.wait_and_get_any_deployment_pod" href="#tests.common.wait_and_get_any_deployment_pod">wait_and_get_any_deployment_pod</a></code></li>
<li><code><a title="tests.common.wait_and_get_pv_for_pvc" href="#tests.common.wait_and_get_pv_for_pvc">wait_and_get_pv_for_pvc</a></code></li>
<li><code><a title="tests.common.wait_delete_deployment" href="#tests.common.wait_delete_deployment">wait_delete_deployment</a></code></li>
<li><code><a title="tests.common.wait_delete_dm_device" href="#tests.common.wait_delete_dm_device">wait_delete_dm_device</a></code></li>
<li><code><a title="tests.common.wait_delete_pod" href="#tests.common.wait_delete_pod">wait_delete_pod</a></code></li>
<li><code><a title="tests.common.wait_delete_pv" href="#tests.common.wait_delete_pv">wait_delete_pv</a></code></li>
<li><code><a title="tests.common.wait_delete_pvc" href="#tests.common.wait_delete_pvc">wait_delete_pvc</a></code></li>
<li><code><a title="tests.common.wait_delete_volume_attachment" href="#tests.common.wait_delete_volume_attachment">wait_delete_volume_attachment</a></code></li>
<li><code><a title="tests.common.wait_deployment_replica_ready" href="#tests.common.wait_deployment_replica_ready">wait_deployment_replica_ready</a></code></li>
<li><code><a title="tests.common.wait_for_all_instance_manager_running" href="#tests.common.wait_for_all_instance_manager_running">wait_for_all_instance_manager_running</a></code></li>
<li><code><a title="tests.common.wait_for_backing_image_delete" href="#tests.common.wait_for_backing_image_delete">wait_for_backing_image_delete</a></code></li>
<li><code><a title="tests.common.wait_for_backing_image_disk_cleanup" href="#tests.common.wait_for_backing_image_disk_cleanup">wait_for_backing_image_disk_cleanup</a></code></li>
<li><code><a title="tests.common.wait_for_backing_image_in_disk_fail" href="#tests.common.wait_for_backing_image_in_disk_fail">wait_for_backing_image_in_disk_fail</a></code></li>
<li><code><a title="tests.common.wait_for_backing_image_status" href="#tests.common.wait_for_backing_image_status">wait_for_backing_image_status</a></code></li>
<li><code><a title="tests.common.wait_for_backup_backing_image_delete" href="#tests.common.wait_for_backup_backing_image_delete">wait_for_backup_backing_image_delete</a></code></li>
<li><code><a title="tests.common.wait_for_backup_completion" href="#tests.common.wait_for_backup_completion">wait_for_backup_completion</a></code></li>
<li><code><a title="tests.common.wait_for_backup_count" href="#tests.common.wait_for_backup_count">wait_for_backup_count</a></code></li>
<li><code><a title="tests.common.wait_for_backup_delete" href="#tests.common.wait_for_backup_delete">wait_for_backup_delete</a></code></li>
<li><code><a title="tests.common.wait_for_backup_failed" href="#tests.common.wait_for_backup_failed">wait_for_backup_failed</a></code></li>
<li><code><a title="tests.common.wait_for_backup_restore_completed" href="#tests.common.wait_for_backup_restore_completed">wait_for_backup_restore_completed</a></code></li>
<li><code><a title="tests.common.wait_for_backup_state" href="#tests.common.wait_for_backup_state">wait_for_backup_state</a></code></li>
<li><code><a title="tests.common.wait_for_backup_target_available" href="#tests.common.wait_for_backup_target_available">wait_for_backup_target_available</a></code></li>
<li><code><a title="tests.common.wait_for_backup_to_start" href="#tests.common.wait_for_backup_to_start">wait_for_backup_to_start</a></code></li>
<li><code><a title="tests.common.wait_for_backup_volume" href="#tests.common.wait_for_backup_volume">wait_for_backup_volume</a></code></li>
<li><code><a title="tests.common.wait_for_backup_volume_backing_image_synced" href="#tests.common.wait_for_backup_volume_backing_image_synced">wait_for_backup_volume_backing_image_synced</a></code></li>
<li><code><a title="tests.common.wait_for_backup_volume_delete" href="#tests.common.wait_for_backup_volume_delete">wait_for_backup_volume_delete</a></code></li>
<li><code><a title="tests.common.wait_for_cron_job_count" href="#tests.common.wait_for_cron_job_count">wait_for_cron_job_count</a></code></li>
<li><code><a title="tests.common.wait_for_cron_job_create" href="#tests.common.wait_for_cron_job_create">wait_for_cron_job_create</a></code></li>
<li><code><a title="tests.common.wait_for_cron_job_delete" href="#tests.common.wait_for_cron_job_delete">wait_for_cron_job_delete</a></code></li>
<li><code><a title="tests.common.wait_for_deployed_engine_image_count" href="#tests.common.wait_for_deployed_engine_image_count">wait_for_deployed_engine_image_count</a></code></li>
<li><code><a title="tests.common.wait_for_device_login" href="#tests.common.wait_for_device_login">wait_for_device_login</a></code></li>
<li><code><a title="tests.common.wait_for_disk_conditions" href="#tests.common.wait_for_disk_conditions">wait_for_disk_conditions</a></code></li>
<li><code><a title="tests.common.wait_for_disk_status" href="#tests.common.wait_for_disk_status">wait_for_disk_status</a></code></li>
<li><code><a title="tests.common.wait_for_disk_storage_available" href="#tests.common.wait_for_disk_storage_available">wait_for_disk_storage_available</a></code></li>
<li><code><a title="tests.common.wait_for_disk_update" href="#tests.common.wait_for_disk_update">wait_for_disk_update</a></code></li>
<li><code><a title="tests.common.wait_for_disk_uuid" href="#tests.common.wait_for_disk_uuid">wait_for_disk_uuid</a></code></li>
<li><code><a title="tests.common.wait_for_dr_volume_expansion" href="#tests.common.wait_for_dr_volume_expansion">wait_for_dr_volume_expansion</a></code></li>
<li><code><a title="tests.common.wait_for_engine_image_condition" href="#tests.common.wait_for_engine_image_condition">wait_for_engine_image_condition</a></code></li>
<li><code><a title="tests.common.wait_for_engine_image_creation" href="#tests.common.wait_for_engine_image_creation">wait_for_engine_image_creation</a></code></li>
<li><code><a title="tests.common.wait_for_engine_image_deletion" href="#tests.common.wait_for_engine_image_deletion">wait_for_engine_image_deletion</a></code></li>
<li><code><a title="tests.common.wait_for_engine_image_incompatible" href="#tests.common.wait_for_engine_image_incompatible">wait_for_engine_image_incompatible</a></code></li>
<li><code><a title="tests.common.wait_for_engine_image_ref_count" href="#tests.common.wait_for_engine_image_ref_count">wait_for_engine_image_ref_count</a></code></li>
<li><code><a title="tests.common.wait_for_engine_image_state" href="#tests.common.wait_for_engine_image_state">wait_for_engine_image_state</a></code></li>
<li><code><a title="tests.common.wait_for_expansion_error_clear" href="#tests.common.wait_for_expansion_error_clear">wait_for_expansion_error_clear</a></code></li>
<li><code><a title="tests.common.wait_for_expansion_failure" href="#tests.common.wait_for_expansion_failure">wait_for_expansion_failure</a></code></li>
<li><code><a title="tests.common.wait_for_instance_manager_count" href="#tests.common.wait_for_instance_manager_count">wait_for_instance_manager_count</a></code></li>
<li><code><a title="tests.common.wait_for_instance_manager_desire_state" href="#tests.common.wait_for_instance_manager_desire_state">wait_for_instance_manager_desire_state</a></code></li>
<li><code><a title="tests.common.wait_for_node_mountpropagation_condition" href="#tests.common.wait_for_node_mountpropagation_condition">wait_for_node_mountpropagation_condition</a></code></li>
<li><code><a title="tests.common.wait_for_node_schedulable_condition" href="#tests.common.wait_for_node_schedulable_condition">wait_for_node_schedulable_condition</a></code></li>
<li><code><a title="tests.common.wait_for_node_tag_update" href="#tests.common.wait_for_node_tag_update">wait_for_node_tag_update</a></code></li>
<li><code><a title="tests.common.wait_for_node_update" href="#tests.common.wait_for_node_update">wait_for_node_update</a></code></li>
<li><code><a title="tests.common.wait_for_nvme_device" href="#tests.common.wait_for_nvme_device">wait_for_nvme_device</a></code></li>
<li><code><a title="tests.common.wait_for_pod_annotation" href="#tests.common.wait_for_pod_annotation">wait_for_pod_annotation</a></code></li>
<li><code><a title="tests.common.wait_for_pod_phase" href="#tests.common.wait_for_pod_phase">wait_for_pod_phase</a></code></li>
<li><code><a title="tests.common.wait_for_pod_remount" href="#tests.common.wait_for_pod_remount">wait_for_pod_remount</a></code></li>
<li><code><a title="tests.common.wait_for_pod_restart" href="#tests.common.wait_for_pod_restart">wait_for_pod_restart</a></code></li>
<li><code><a title="tests.common.wait_for_pods_volume_delete" href="#tests.common.wait_for_pods_volume_delete">wait_for_pods_volume_delete</a></code></li>
<li><code><a title="tests.common.wait_for_pods_volume_state" href="#tests.common.wait_for_pods_volume_state">wait_for_pods_volume_state</a></code></li>
<li><code><a title="tests.common.wait_for_pvc_phase" href="#tests.common.wait_for_pvc_phase">wait_for_pvc_phase</a></code></li>
<li><code><a title="tests.common.wait_for_rebuild_complete" href="#tests.common.wait_for_rebuild_complete">wait_for_rebuild_complete</a></code></li>
<li><code><a title="tests.common.wait_for_rebuild_start" href="#tests.common.wait_for_rebuild_start">wait_for_rebuild_start</a></code></li>
<li><code><a title="tests.common.wait_for_recurring_jobs_cleanup" href="#tests.common.wait_for_recurring_jobs_cleanup">wait_for_recurring_jobs_cleanup</a></code></li>
<li><code><a title="tests.common.wait_for_replica_count" href="#tests.common.wait_for_replica_count">wait_for_replica_count</a></code></li>
<li><code><a title="tests.common.wait_for_replica_directory" href="#tests.common.wait_for_replica_directory">wait_for_replica_directory</a></code></li>
<li><code><a title="tests.common.wait_for_replica_failed" href="#tests.common.wait_for_replica_failed">wait_for_replica_failed</a></code></li>
<li><code><a title="tests.common.wait_for_replica_running" href="#tests.common.wait_for_replica_running">wait_for_replica_running</a></code></li>
<li><code><a title="tests.common.wait_for_replica_scheduled" href="#tests.common.wait_for_replica_scheduled">wait_for_replica_scheduled</a></code></li>
<li><code><a title="tests.common.wait_for_restoration_start" href="#tests.common.wait_for_restoration_start">wait_for_restoration_start</a></code></li>
<li><code><a title="tests.common.wait_for_running_engine_image_count" href="#tests.common.wait_for_running_engine_image_count">wait_for_running_engine_image_count</a></code></li>
<li><code><a title="tests.common.wait_for_snapshot_count" href="#tests.common.wait_for_snapshot_count">wait_for_snapshot_count</a></code></li>
<li><code><a title="tests.common.wait_for_snapshot_purge" href="#tests.common.wait_for_snapshot_purge">wait_for_snapshot_purge</a></code></li>
<li><code><a title="tests.common.wait_for_support_bundle_cleanup" href="#tests.common.wait_for_support_bundle_cleanup">wait_for_support_bundle_cleanup</a></code></li>
<li><code><a title="tests.common.wait_for_support_bundle_state" href="#tests.common.wait_for_support_bundle_state">wait_for_support_bundle_state</a></code></li>
<li><code><a title="tests.common.wait_for_tainted_node_engine_image_undeployed" href="#tests.common.wait_for_tainted_node_engine_image_undeployed">wait_for_tainted_node_engine_image_undeployed</a></code></li>
<li><code><a title="tests.common.wait_for_volume_attached" href="#tests.common.wait_for_volume_attached">wait_for_volume_attached</a></code></li>
<li><code><a title="tests.common.wait_for_volume_clone_status" href="#tests.common.wait_for_volume_clone_status">wait_for_volume_clone_status</a></code></li>
<li><code><a title="tests.common.wait_for_volume_condition_restore" href="#tests.common.wait_for_volume_condition_restore">wait_for_volume_condition_restore</a></code></li>
<li><code><a title="tests.common.wait_for_volume_condition_scheduled" href="#tests.common.wait_for_volume_condition_scheduled">wait_for_volume_condition_scheduled</a></code></li>
<li><code><a title="tests.common.wait_for_volume_condition_toomanysnapshots" href="#tests.common.wait_for_volume_condition_toomanysnapshots">wait_for_volume_condition_toomanysnapshots</a></code></li>
<li><code><a title="tests.common.wait_for_volume_creation" href="#tests.common.wait_for_volume_creation">wait_for_volume_creation</a></code></li>
<li><code><a title="tests.common.wait_for_volume_current_image" href="#tests.common.wait_for_volume_current_image">wait_for_volume_current_image</a></code></li>
<li><code><a title="tests.common.wait_for_volume_degraded" href="#tests.common.wait_for_volume_degraded">wait_for_volume_degraded</a></code></li>
<li><code><a title="tests.common.wait_for_volume_delete" href="#tests.common.wait_for_volume_delete">wait_for_volume_delete</a></code></li>
<li><code><a title="tests.common.wait_for_volume_detached" href="#tests.common.wait_for_volume_detached">wait_for_volume_detached</a></code></li>
<li><code><a title="tests.common.wait_for_volume_detached_unknown" href="#tests.common.wait_for_volume_detached_unknown">wait_for_volume_detached_unknown</a></code></li>
<li><code><a title="tests.common.wait_for_volume_endpoint" href="#tests.common.wait_for_volume_endpoint">wait_for_volume_endpoint</a></code></li>
<li><code><a title="tests.common.wait_for_volume_expansion" href="#tests.common.wait_for_volume_expansion">wait_for_volume_expansion</a></code></li>
<li><code><a title="tests.common.wait_for_volume_faulted" href="#tests.common.wait_for_volume_faulted">wait_for_volume_faulted</a></code></li>
<li><code><a title="tests.common.wait_for_volume_frontend_disabled" href="#tests.common.wait_for_volume_frontend_disabled">wait_for_volume_frontend_disabled</a></code></li>
<li><code><a title="tests.common.wait_for_volume_healthy" href="#tests.common.wait_for_volume_healthy">wait_for_volume_healthy</a></code></li>
<li><code><a title="tests.common.wait_for_volume_healthy_no_frontend" href="#tests.common.wait_for_volume_healthy_no_frontend">wait_for_volume_healthy_no_frontend</a></code></li>
<li><code><a title="tests.common.wait_for_volume_migration_node" href="#tests.common.wait_for_volume_migration_node">wait_for_volume_migration_node</a></code></li>
<li><code><a title="tests.common.wait_for_volume_migration_ready" href="#tests.common.wait_for_volume_migration_ready">wait_for_volume_migration_ready</a></code></li>
<li><code><a title="tests.common.wait_for_volume_option_trim_auto_removing_snapshots" href="#tests.common.wait_for_volume_option_trim_auto_removing_snapshots">wait_for_volume_option_trim_auto_removing_snapshots</a></code></li>
<li><code><a title="tests.common.wait_for_volume_recurring_job_update" href="#tests.common.wait_for_volume_recurring_job_update">wait_for_volume_recurring_job_update</a></code></li>
<li><code><a title="tests.common.wait_for_volume_replica_auto_balance_update" href="#tests.common.wait_for_volume_replica_auto_balance_update">wait_for_volume_replica_auto_balance_update</a></code></li>
<li><code><a title="tests.common.wait_for_volume_replica_count" href="#tests.common.wait_for_volume_replica_count">wait_for_volume_replica_count</a></code></li>
<li><code><a title="tests.common.wait_for_volume_replica_rebuilt_on_same_node_different_disk" href="#tests.common.wait_for_volume_replica_rebuilt_on_same_node_different_disk">wait_for_volume_replica_rebuilt_on_same_node_different_disk</a></code></li>
<li><code><a title="tests.common.wait_for_volume_replicas_mode" href="#tests.common.wait_for_volume_replicas_mode">wait_for_volume_replicas_mode</a></code></li>
<li><code><a title="tests.common.wait_for_volume_replicas_running_on_hosts" href="#tests.common.wait_for_volume_replicas_running_on_hosts">wait_for_volume_replicas_running_on_hosts</a></code></li>
<li><code><a title="tests.common.wait_for_volume_restoration_completed" href="#tests.common.wait_for_volume_restoration_completed">wait_for_volume_restoration_completed</a></code></li>
<li><code><a title="tests.common.wait_for_volume_restoration_start" href="#tests.common.wait_for_volume_restoration_start">wait_for_volume_restoration_start</a></code></li>
<li><code><a title="tests.common.wait_for_volume_status" href="#tests.common.wait_for_volume_status">wait_for_volume_status</a></code></li>
<li><code><a title="tests.common.wait_longhorn_node_zone_reset" href="#tests.common.wait_longhorn_node_zone_reset">wait_longhorn_node_zone_reset</a></code></li>
<li><code><a title="tests.common.wait_pod" href="#tests.common.wait_pod">wait_pod</a></code></li>
<li><code><a title="tests.common.wait_pod_attach_after_first_backup_completion" href="#tests.common.wait_pod_attach_after_first_backup_completion">wait_pod_attach_after_first_backup_completion</a></code></li>
<li><code><a title="tests.common.wait_scheduling_failure" href="#tests.common.wait_scheduling_failure">wait_scheduling_failure</a></code></li>
<li><code><a title="tests.common.wait_statefulset" href="#tests.common.wait_statefulset">wait_statefulset</a></code></li>
<li><code><a title="tests.common.wait_volume_kubernetes_status" href="#tests.common.wait_volume_kubernetes_status">wait_volume_kubernetes_status</a></code></li>
<li><code><a title="tests.common.write_device_random_data" href="#tests.common.write_device_random_data">write_device_random_data</a></code></li>
<li><code><a title="tests.common.write_pod_block_volume_data" href="#tests.common.write_pod_block_volume_data">write_pod_block_volume_data</a></code></li>
<li><code><a title="tests.common.write_pod_volume_data" href="#tests.common.write_pod_volume_data">write_pod_volume_data</a></code></li>
<li><code><a title="tests.common.write_pod_volume_random_data" href="#tests.common.write_pod_volume_random_data">write_pod_volume_random_data</a></code></li>
<li><code><a title="tests.common.write_volume_data" href="#tests.common.write_volume_data">write_volume_data</a></code></li>
<li><code><a title="tests.common.write_volume_dev_random_mb_data" href="#tests.common.write_volume_dev_random_mb_data">write_volume_dev_random_mb_data</a></code></li>
<li><code><a title="tests.common.write_volume_random_data" href="#tests.common.write_volume_random_data">write_volume_random_data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tests.common.AssertErrorCheckThread" href="#tests.common.AssertErrorCheckThread">AssertErrorCheckThread</a></code></h4>
<ul class="">
<li><code><a title="tests.common.AssertErrorCheckThread.join" href="#tests.common.AssertErrorCheckThread.join">join</a></code></li>
<li><code><a title="tests.common.AssertErrorCheckThread.run" href="#tests.common.AssertErrorCheckThread.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tests.common.timeout" href="#tests.common.timeout">timeout</a></code></h4>
<ul class="">
<li><code><a title="tests.common.timeout.handle_timeout" href="#tests.common.timeout.handle_timeout">handle_timeout</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
