<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.0">
<title>tests.test_settings API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tests.test_settings</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tests.test_settings.check_priority_class"><code class="name flex">
<span>def <span class="ident">check_priority_class</span></span>(<span>pod, priority_class=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.check_tolerations_set"><code class="name flex">
<span>def <span class="ident">check_tolerations_set</span></span>(<span>current_toleration_list, expected_tolerations, chk_removed_tolerations=[])</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.check_workload_update"><code class="name flex">
<span>def <span class="ident">check_workload_update</span></span>(<span>core_api, apps_api, count)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.config_map_with_value"><code class="name flex">
<span>def <span class="ident">config_map_with_value</span></span>(<span>configmap_name, setting_names, setting_values)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.guaranteed_instance_manager_cpu_setting_check"><code class="name flex">
<span>def <span class="ident">guaranteed_instance_manager_cpu_setting_check</span></span>(<span>client, core_api, instance_managers, state, desire, cpu_val)</span>
</code></dt>
<dd>
<div class="desc"><p>We check if instance managers are in the desired state with
correct setting
desire is for reflect the state we are looking for.
If desire is True, meanning we need the state to be the same.
Otherwise, we are looking for the state to be different.
e.g. 'Pending', 'OutofCPU', 'Terminating' they are all 'Not Running'.</p></div>
</dd>
<dt id="tests.test_settings.init_longhorn_default_setting_configmap"><code class="name flex">
<span>def <span class="ident">init_longhorn_default_setting_configmap</span></span>(<span>core_api, client)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.retry_setting_update"><code class="name flex">
<span>def <span class="ident">retry_setting_update</span></span>(<span>client, setting_name, setting_value)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.setting_concurrent_volume_backup_restore_limit_concurrent_restoring_test"><code class="name flex">
<span>def <span class="ident">setting_concurrent_volume_backup_restore_limit_concurrent_restoring_test</span></span>(<span>client, volname, is_DR_volumes=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Given Setting concurrent-volume-backup-restore-per-node-limit is 2.
And Volume (for backup) created.
And Volume (for backup) has backup with some data.</p>
<p>When Create some volumes (num_node * setting value * 3) from backup.</p>
<p>Then Number of restoring volumes per node should be expected based on
if they are normal volumes or DR volumes.</p></div>
</dd>
<dt id="tests.test_settings.test_instance_manager_cpu_reservation"><code class="name flex">
<span>def <span class="ident">test_instance_manager_cpu_reservation</span></span>(<span>client, core_api)</span>
</code></dt>
<dd>
<div class="desc"><p>Test if the CPU requests of instance manager pods are controlled by
the settings and the node specs correctly.</p>
<ol>
<li>On node 1, set <code>node.instanceManagerCPURequest</code> to 150.
&ndash;&gt; The IM pods on this node will be restarted. And the CPU requests
of these IM pods matches the above milli value.</li>
<li>Change the new setting <code>Guaranteed Instance Manager CPU</code> to 10,
Then wait for all IM pods except for the pods on node 1 restarting.
&ndash;&gt; The CPU requests of the restarted IM pods equals to
the new setting value multiply the kube node allocatable CPU.</li>
<li>Set the new settings to 0.
&ndash;&gt; All IM pods except for the pod on node 1 will be restarted without
CPU requests.</li>
<li>Set the fields on node 1 to 0.
&ndash;&gt; The IM pods on node 1 will be restarted without CPU requests.</li>
<li>Set the new setting to a values smaller than 40.
Then wait for all IM pods restarting.
&ndash;&gt; The CPU requests of all IM pods equals to
the new setting value multiply the kube node allocatable CPU.</li>
<li>Set the new setting to a value greater than 40.
&ndash;&gt; The setting update should fail.</li>
<li>Create a volume, verify everything works as normal</li>
</ol>
<p>Note: use fixture to restore the setting into the original state</p></div>
</dd>
<dt id="tests.test_settings.test_setting_backing_image_auto_cleanup"><code class="name flex">
<span>def <span class="ident">test_setting_backing_image_auto_cleanup</span></span>(<span>client, core_api, volume_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Test that the Backing Image Cleanup Wait Interval setting works correctly.</p>
<p>The default value of setting <code>BackingImageCleanupWaitInterval</code> is 60.</p>
<ol>
<li>Clean up the backing image work directory so that the current case
won't be intervened by previous tests.</li>
<li>Create a backing image.</li>
<li>Create multiple volumes using the backing image.</li>
<li>Attach all volumes, Then:<ol>
<li>Wait for all volumes can become running.</li>
<li>Verify the correct in all volumes.</li>
<li>Verify the backing image disk status map.</li>
<li>Verify the only backing image file in each disk is reused by
multiple replicas. The backing image file path is
<code>&lt;Data path&gt;/&lt;The backing image name&gt;/backing</code></li>
</ol>
</li>
<li>Unschedule test node to guarantee when replica removed from test node,
no new replica can be rebuilt on the test node.</li>
<li>Remove all replicas in one disk.
Wait for 50 seconds.
Then verify nothing changes in the backing image disk state map
(before the cleanup wait interval is passed).</li>
<li>Modify <code>BackingImageCleanupWaitInterval</code> to a small value. Then verify:<ol>
<li>The download state of the disk containing no replica becomes
terminating first, and the entry will be removed from the map later.</li>
<li>The related backing image file is removed.</li>
<li>The download state of other disks keep unchanged.
All volumes still work fine.</li>
</ol>
</li>
<li>Delete all volumes. Verify that there will only remain 1 entry in the
backing image disk map</li>
<li>Delete the backing image.</li>
</ol></div>
</dd>
<dt id="tests.test_settings.test_setting_backup_target_update_via_configmap"><code class="name flex">
<span>def <span class="ident">test_setting_backup_target_update_via_configmap</span></span>(<span>core_api, request)</span>
</code></dt>
<dd>
<div class="desc"><p>Test the backup target setting via configmap
1. Initialize longhorn-default-setting configmap
2. Update longhorn-default-setting configmap with a new backup-target
value
3. Verify the updated settings</p></div>
</dd>
<dt id="tests.test_settings.test_setting_concurrent_rebuild_limit"><code class="name flex">
<span>def <span class="ident">test_setting_concurrent_rebuild_limit</span></span>(<span>client, core_api, volume_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Test if setting Concurrent Replica Rebuild Per Node Limit works correctly.</p>
<p>The default setting value is 0, which means no limit.</p>
<p>Case 1 - the setting will limit the rebuilding correctly:
1. Set <code>ConcurrentReplicaRebuildPerNodeLimit</code> to 1.
2. Create 2 volumes then attach both volumes.
3. Write a large amount of data into both volumes,
so that the rebuilding will take a while.
4. Delete one replica for volume 1 then the replica on the same node for
volume 2 to trigger (concurrent) rebuilding.
5. Verify the new replica of volume 2 won't be started until volume 1
rebuilding complete.
And the new replica of volume 2 will be started immediately once
the 1st rebuilding is done.
6. Wait for rebuilding complete then repeat step 4.
7. Set <code>ConcurrentReplicaRebuildPerNodeLimit</code> to 0 or 2 while the volume 1
rebuilding is still in progress.
Then the new replica of volume 2 will be started immediately before
the 1st rebuilding is done.
8. Wait for rebuilding complete then repeat step 4.
9. Set <code>ConcurrentReplicaRebuildPerNodeLimit</code> to 1
10. Crash the replica process of volume 1 while the rebuilding is
in progress.
Then the rebuilding of volume 2 will be started, and the rebuilding of
volume 1 will wait for the volume 2 becoming healthy.</p>
<p>(There is no need to clean up the above 2 volumes.)</p>
<p>Case 2 - the setting won't intervene normal attachment:
1. Set <code>ConcurrentReplicaRebuildPerNodeLimit</code> to 1.
2. Make volume 1 state attached and healthy while volume 2 is detached.
3. Delete one replica for volume 1 to trigger the rebuilding.
4. Attach then detach volume 2. The attachment/detachment should succeed
even if the rebuilding in volume 1 is still in progress.</p></div>
</dd>
<dt id="tests.test_settings.test_setting_concurrent_volume_backup_restore_limit"><code class="name flex">
<span>def <span class="ident">test_setting_concurrent_volume_backup_restore_limit</span></span>(<span>set_random_backupstore, client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Scenario: setting Concurrent Volume Backup Restore Limit
should limit the concurrent volume backup restoring</p>
<p>Issue: <a href="https://github.com/longhorn/longhorn/issues/4558">https://github.com/longhorn/longhorn/issues/4558</a></p>
<p>Given/When see:
setting_concurrent_volume_backup_restore_limit_concurrent_restoring_test</p>
<p>Then Number of restoring volumes per node not exceed the setting value.</p></div>
</dd>
<dt id="tests.test_settings.test_setting_concurrent_volume_backup_restore_limit_should_not_effect_dr_volumes"><code class="name flex">
<span>def <span class="ident">test_setting_concurrent_volume_backup_restore_limit_should_not_effect_dr_volumes</span></span>(<span>set_random_backupstore, client, volume_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Scenario: setting Concurrent Volume Backup Restore Limit
should not effect DR volumes</p>
<p>Issue: <a href="https://github.com/longhorn/longhorn/issues/4558">https://github.com/longhorn/longhorn/issues/4558</a></p>
<p>Given/When see:
setting_concurrent_volume_backup_restore_limit_concurrent_restoring_test</p>
<p>Then Number of restoring volumes can exceed the setting value.</p></div>
</dd>
<dt id="tests.test_settings.test_setting_priority_class"><code class="name flex">
<span>def <span class="ident">test_setting_priority_class</span></span>(<span>core_api, apps_api, scheduling_api, priority_class, volume_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Test that the Priority Class setting is validated and utilized correctly.</p>
<ol>
<li>Verify that the name of a non-existent Priority Class cannot be used
for the Setting.</li>
<li>Create a new Priority Class in Kubernetes.</li>
<li>Create and attach a Volume.</li>
<li>Verify that the Priority Class Setting can be updated with an attached
volume.</li>
<li>Generate and write <code>data1</code>.</li>
<li>Detach the Volume.</li>
<li>Update the Priority Class Setting to the new Priority Class.</li>
<li>Wait for all the Longhorn system components to restart with the new
Priority Class.</li>
<li>Verify that UI, manager, and drive deployer don't have Priority Class</li>
<li>Attach the Volume and verify <code>data1</code>.</li>
<li>Generate and write <code>data2</code>.</li>
<li>Unset the Priority Class Setting.</li>
<li>Wait for all the Longhorn system components to restart with the new
Priority Class.</li>
<li>Verify that UI, manager, and drive deployer don't have Priority Class</li>
<li>Attach the Volume and verify <code>data2</code>.</li>
<li>Generate and write <code>data3</code>.</li>
</ol>
<p>Note: system components are workloads other than UI, manager, driver
deployer</p></div>
</dd>
<dt id="tests.test_settings.test_setting_replica_count_update_via_configmap"><code class="name flex">
<span>def <span class="ident">test_setting_replica_count_update_via_configmap</span></span>(<span>core_api, request)</span>
</code></dt>
<dd>
<div class="desc"><p>Test the default-replica-count setting via configmap
1. Get default-replica-count value
2. Initialize longhorn-default-setting configmap
3. Verify default-replica-count is not changed
4. Update longhorn-default-setting configmap with a new
default-replica-count value
5. Verify the updated settings
6. Update default-replica-count setting CR with the old value</p></div>
</dd>
<dt id="tests.test_settings.test_setting_toleration"><code class="name flex">
<span>def <span class="ident">test_setting_toleration</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Test toleration setting</p>
<ol>
<li>Set <code>taint-toleration</code> to "key1=value1:NoSchedule; key2:InvalidEffect".</li>
<li>Verify the request fails.</li>
<li>Create a volume and attach it.</li>
<li>Set <code>taint-toleration</code> to "key1=value1:NoSchedule; key2:NoExecute".</li>
<li>Verify that can update toleration setting when any volume is attached.</li>
<li>Generate and write <code>data1</code> into the volume.</li>
<li>Detach the volume.</li>
<li>Set <code>taint-toleration</code> to "key1=value1:NoSchedule; key2:NoExecute".</li>
<li>Wait for all the Longhorn system components to restart with new
toleration.</li>
<li>Verify that UI, manager, and drive deployer don't restart and
don't have new toleration.</li>
<li>Attach the volume again and verify the volume <code>data1</code>.</li>
<li>Generate and write <code>data2</code> to the volume.</li>
<li>Detach the volume.</li>
<li>Clean the <code>toleration</code> setting.</li>
<li>Wait for all the Longhorn system components to restart with no
toleration.</li>
<li>Attach the volume and validate <code>data2</code>.</li>
<li>Generate and write <code>data3</code> to the volume.</li>
</ol></div>
</dd>
<dt id="tests.test_settings.test_setting_toleration_extra"><code class="name flex">
<span>def <span class="ident">test_setting_toleration_extra</span></span>(<span>core_api, apps_api)</span>
</code></dt>
<dd>
<div class="desc"><p>Steps:
1. Set Kubernetes Taint Toleration to:
<code>ex.com/foobar:NoExecute;ex.com/foobar:NoSchedule</code>.
2. Verify that all system components have the 2 tolerations
<code>ex.com/foobar:NoExecute; ex.com/foobar:NoSchedule</code>.
Verify that UI, manager, and drive deployer don't restart and
don't have toleration.
3. Set Kubernetes Taint Toleration to:
<code>node-role.kubernetes.io/controlplane=true:NoSchedule</code>.
4. Verify that all system components have the the toleration
<code>node-role.kubernetes.io/controlplane=true:NoSchedule</code>,
and don't have the 2 tolerations
<code>ex.com/foobar:NoExecute;ex.com/foobar:NoSchedule</code>.
Verify that UI, manager, and drive deployer don't restart and
don't have toleration.
5. Set Kubernetes Taint Toleration to special value:
<code>:</code>.
6. Verify that all system components have the toleration with
<code>operator: Exists</code> and other field of the toleration are empty.
Verify that all system components don't have the toleration
<code>node-role.kubernetes.io/controlplane=true:NoSchedule</code>.
Verify that UI, manager, and drive deployer don't restart and
don't have toleration.
7. Clear Kubernetes Taint Toleration</p>
<p>Note: system components are workloads other than UI, manager, driver
deployer</p></div>
</dd>
<dt id="tests.test_settings.test_setting_update_with_invalid_value_via_configmap"><code class="name flex">
<span>def <span class="ident">test_setting_update_with_invalid_value_via_configmap</span></span>(<span>core_api, request)</span>
</code></dt>
<dd>
<div class="desc"><p>Test the default settings update with invalid value via configmap
1. Create an attached volume
2. Initialize longhorn-default-setting configmap containing
valid and invalid settings
3. Update longhorn-default-setting configmap with invalid settings.
The invalid settings SETTING_TAINT_TOLERATION will be ignored
when there is an attached volume.
4. Validate the default settings values.</p></div>
</dd>
<dt id="tests.test_settings.test_setting_v1_data_engine"><code class="name flex">
<span>def <span class="ident">test_setting_v1_data_engine</span></span>(<span>client, request)</span>
</code></dt>
<dd>
<div class="desc"><p>Test that the v1 data engine setting works correctly.
1. Create a volume and attach it.
2. Set v1 data engine setting to false. The setting should be rejected.
3. Detach the volume.
4. Set v1 data engine setting to false again. The setting should be
accepted. Then, attach the volume. The volume is unable to attach.
5. set v1 data engine setting to true. The setting should be accepted.
6. Attach the volume.</p></div>
</dd>
<dt id="tests.test_settings.update_settings_via_configmap"><code class="name flex">
<span>def <span class="ident">update_settings_via_configmap</span></span>(<span>core_api, client, setting_names, setting_values, request)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.validate_settings"><code class="name flex">
<span>def <span class="ident">validate_settings</span></span>(<span>core_api, client, setting_names, setting_values)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.wait_for_longhorn_node_ready"><code class="name flex">
<span>def <span class="ident">wait_for_longhorn_node_ready</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.wait_for_priority_class_update"><code class="name flex">
<span>def <span class="ident">wait_for_priority_class_update</span></span>(<span>core_api, apps_api, count, priority_class=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.wait_for_setting_updated"><code class="name flex">
<span>def <span class="ident">wait_for_setting_updated</span></span>(<span>client, name, expected_value)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tests.test_settings.wait_for_toleration_update"><code class="name flex">
<span>def <span class="ident">wait_for_toleration_update</span></span>(<span>core_api, apps_api, count, expected_tolerations, chk_removed_tolerations=[])</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tests" href="index.html">tests</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tests.test_settings.check_priority_class" href="#tests.test_settings.check_priority_class">check_priority_class</a></code></li>
<li><code><a title="tests.test_settings.check_tolerations_set" href="#tests.test_settings.check_tolerations_set">check_tolerations_set</a></code></li>
<li><code><a title="tests.test_settings.check_workload_update" href="#tests.test_settings.check_workload_update">check_workload_update</a></code></li>
<li><code><a title="tests.test_settings.config_map_with_value" href="#tests.test_settings.config_map_with_value">config_map_with_value</a></code></li>
<li><code><a title="tests.test_settings.guaranteed_instance_manager_cpu_setting_check" href="#tests.test_settings.guaranteed_instance_manager_cpu_setting_check">guaranteed_instance_manager_cpu_setting_check</a></code></li>
<li><code><a title="tests.test_settings.init_longhorn_default_setting_configmap" href="#tests.test_settings.init_longhorn_default_setting_configmap">init_longhorn_default_setting_configmap</a></code></li>
<li><code><a title="tests.test_settings.retry_setting_update" href="#tests.test_settings.retry_setting_update">retry_setting_update</a></code></li>
<li><code><a title="tests.test_settings.setting_concurrent_volume_backup_restore_limit_concurrent_restoring_test" href="#tests.test_settings.setting_concurrent_volume_backup_restore_limit_concurrent_restoring_test">setting_concurrent_volume_backup_restore_limit_concurrent_restoring_test</a></code></li>
<li><code><a title="tests.test_settings.test_instance_manager_cpu_reservation" href="#tests.test_settings.test_instance_manager_cpu_reservation">test_instance_manager_cpu_reservation</a></code></li>
<li><code><a title="tests.test_settings.test_setting_backing_image_auto_cleanup" href="#tests.test_settings.test_setting_backing_image_auto_cleanup">test_setting_backing_image_auto_cleanup</a></code></li>
<li><code><a title="tests.test_settings.test_setting_backup_target_update_via_configmap" href="#tests.test_settings.test_setting_backup_target_update_via_configmap">test_setting_backup_target_update_via_configmap</a></code></li>
<li><code><a title="tests.test_settings.test_setting_concurrent_rebuild_limit" href="#tests.test_settings.test_setting_concurrent_rebuild_limit">test_setting_concurrent_rebuild_limit</a></code></li>
<li><code><a title="tests.test_settings.test_setting_concurrent_volume_backup_restore_limit" href="#tests.test_settings.test_setting_concurrent_volume_backup_restore_limit">test_setting_concurrent_volume_backup_restore_limit</a></code></li>
<li><code><a title="tests.test_settings.test_setting_concurrent_volume_backup_restore_limit_should_not_effect_dr_volumes" href="#tests.test_settings.test_setting_concurrent_volume_backup_restore_limit_should_not_effect_dr_volumes">test_setting_concurrent_volume_backup_restore_limit_should_not_effect_dr_volumes</a></code></li>
<li><code><a title="tests.test_settings.test_setting_priority_class" href="#tests.test_settings.test_setting_priority_class">test_setting_priority_class</a></code></li>
<li><code><a title="tests.test_settings.test_setting_replica_count_update_via_configmap" href="#tests.test_settings.test_setting_replica_count_update_via_configmap">test_setting_replica_count_update_via_configmap</a></code></li>
<li><code><a title="tests.test_settings.test_setting_toleration" href="#tests.test_settings.test_setting_toleration">test_setting_toleration</a></code></li>
<li><code><a title="tests.test_settings.test_setting_toleration_extra" href="#tests.test_settings.test_setting_toleration_extra">test_setting_toleration_extra</a></code></li>
<li><code><a title="tests.test_settings.test_setting_update_with_invalid_value_via_configmap" href="#tests.test_settings.test_setting_update_with_invalid_value_via_configmap">test_setting_update_with_invalid_value_via_configmap</a></code></li>
<li><code><a title="tests.test_settings.test_setting_v1_data_engine" href="#tests.test_settings.test_setting_v1_data_engine">test_setting_v1_data_engine</a></code></li>
<li><code><a title="tests.test_settings.update_settings_via_configmap" href="#tests.test_settings.update_settings_via_configmap">update_settings_via_configmap</a></code></li>
<li><code><a title="tests.test_settings.validate_settings" href="#tests.test_settings.validate_settings">validate_settings</a></code></li>
<li><code><a title="tests.test_settings.wait_for_longhorn_node_ready" href="#tests.test_settings.wait_for_longhorn_node_ready">wait_for_longhorn_node_ready</a></code></li>
<li><code><a title="tests.test_settings.wait_for_priority_class_update" href="#tests.test_settings.wait_for_priority_class_update">wait_for_priority_class_update</a></code></li>
<li><code><a title="tests.test_settings.wait_for_setting_updated" href="#tests.test_settings.wait_for_setting_updated">wait_for_setting_updated</a></code></li>
<li><code><a title="tests.test_settings.wait_for_toleration_update" href="#tests.test_settings.wait_for_toleration_update">wait_for_toleration_update</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.0</a>.</p>
</footer>
</body>
</html>
